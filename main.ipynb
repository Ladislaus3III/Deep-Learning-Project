{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autorzy: Jakub Henyk, Sebastian Piotrowski, Yevhenii Poliakov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder: Roberta-base   ----    head modification in custom_model.py\n",
    "\n",
    "### Decoder: GPT2   ----    hidden states usage in custom_model.py\n",
    "\n",
    "### Encoder-Decoder: T5-large   ----    freeze even weights in run_translation.py\n",
    "\n",
    "### few-shot/zero-shot learning/prompting: Zephyr-7b-beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_model import RobertaForSequenceClassificationCustom, GPT2ForSequenceClassificationCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/26/2024 01:07:17 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/26/2024 01:07:17 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=1000,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/roberta_modified_emotion\\runs\\Jan26_01-07-17_GIGA_PC,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=output/roberta_modified_emotion,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/roberta_modified_emotion,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=1000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/26/2024 01:07:17 - INFO - __main__ - load a local file for train: data/train.json\n",
      "01/26/2024 01:07:17 - INFO - __main__ - load a local file for validation: data/validation.json\n",
      "01/26/2024 01:07:18 - INFO - datasets.builder - Using custom data configuration default-019d6cd006d41b2b\n",
      "01/26/2024 01:07:18 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "01/26/2024 01:07:18 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "01/26/2024 01:07:18 - INFO - datasets.info - Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:07:18 - INFO - datasets.builder - Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/26/2024 01:07:18 - INFO - datasets.info - Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:07:19 - INFO - __main__ - Using hidden states in model: False\n",
      "01/26/2024 01:07:19 - INFO - __main__ - Using implementation from class: RobertaForSequenceClassificationCustom\n",
      "01/26/2024 01:07:20 - INFO - datasets.arrow_dataset - Loading cached processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-31a5bbbff78bd7d5.arrow\n",
      "01/26/2024 01:07:20 - INFO - datasets.arrow_dataset - Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-e6d15e97d08181cd.arrow\n",
      "01/26/2024 01:07:20 - INFO - __main__ - Sample 10476 of the training set: {'text': 'i do find new friends i m going to try extra hard to make them stay and if i decide that i don t want to feel hurt again and just ride out the last year of school on my own i m going to have to try extra hard not to care what people think of me being a loner', 'label': 0, 'input_ids': [0, 118, 109, 465, 92, 964, 939, 475, 164, 7, 860, 1823, 543, 7, 146, 106, 1095, 8, 114, 939, 2845, 14, 939, 218, 326, 236, 7, 619, 2581, 456, 8, 95, 3068, 66, 5, 94, 76, 9, 334, 15, 127, 308, 939, 475, 164, 7, 33, 7, 860, 1823, 543, 45, 7, 575, 99, 82, 206, 9, 162, 145, 10, 784, 9604, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "01/26/2024 01:07:20 - INFO - __main__ - Sample 1824 of the training set: {'text': 'i asked them to join me in creating a world where all year old girls could grow up feeling hopeful and powerful', 'label': 1, 'input_ids': [0, 118, 553, 106, 7, 1962, 162, 11, 2351, 10, 232, 147, 70, 76, 793, 1972, 115, 1733, 62, 2157, 7917, 8, 2247, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "01/26/2024 01:07:20 - INFO - __main__ - Sample 409 of the training set: {'text': 'i feel when you are a caring person you attract other caring people into your life', 'label': 2, 'input_ids': [0, 118, 619, 77, 47, 32, 10, 10837, 621, 47, 5696, 97, 10837, 82, 88, 110, 301, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "{'loss': 1.6932, 'learning_rate': 1.95e-05, 'epoch': 0.03}\n",
      "{'loss': 1.4622, 'learning_rate': 1.9e-05, 'epoch': 0.05}\n",
      "{'loss': 1.4447, 'learning_rate': 1.8500000000000002e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1496, 'learning_rate': 1.8e-05, 'epoch': 0.1}\n",
      "{'loss': 1.0627, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8235, 'learning_rate': 1.7e-05, 'epoch': 0.15}\n",
      "{'loss': 0.8183, 'learning_rate': 1.65e-05, 'epoch': 0.17}\n",
      "{'loss': 0.7016, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "{'loss': 0.7372, 'learning_rate': 1.55e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6548, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5999, 'learning_rate': 1.45e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5802, 'learning_rate': 1.4e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3855, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5433, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.35}\n",
      "{'loss': 0.488, 'learning_rate': 1.25e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3585, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4887, 'learning_rate': 1.15e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3446, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3832, 'learning_rate': 1.0500000000000001e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4031, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'eval_loss': 0.3246804177761078, 'eval_accuracy': 0.905, 'eval_runtime': 3.376, 'eval_samples_per_second': 592.42, 'eval_steps_per_second': 74.053, 'epoch': 0.5}\n",
      "{'loss': 0.2763, 'learning_rate': 9.5e-06, 'epoch': 0.53}\n",
      "{'loss': 0.25, 'learning_rate': 9e-06, 'epoch': 0.55}\n",
      "{'loss': 0.3734, 'learning_rate': 8.5e-06, 'epoch': 0.57}\n",
      "{'loss': 0.2661, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 0.4323, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 0.4459, 'learning_rate': 7e-06, 'epoch': 0.65}\n",
      "{'loss': 0.2998, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.68}\n",
      "{'loss': 0.4434, 'learning_rate': 6e-06, 'epoch': 0.7}\n",
      "{'loss': 0.2476, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 0.3701, 'learning_rate': 5e-06, 'epoch': 0.75}\n",
      "{'loss': 0.2847, 'learning_rate': 4.5e-06, 'epoch': 0.78}\n",
      "{'loss': 0.2689, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 0.2924, 'learning_rate': 3.5e-06, 'epoch': 0.82}\n",
      "{'loss': 0.3497, 'learning_rate': 3e-06, 'epoch': 0.85}\n",
      "{'loss': 0.3617, 'learning_rate': 2.5e-06, 'epoch': 0.88}\n",
      "{'loss': 0.3668, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.9}\n",
      "{'loss': 0.4464, 'learning_rate': 1.5e-06, 'epoch': 0.93}\n",
      "{'loss': 0.2555, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 0.4185, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.97}\n",
      "{'loss': 0.3794, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'eval_loss': 0.2711745500564575, 'eval_accuracy': 0.914, 'eval_runtime': 3.3798, 'eval_samples_per_second': 591.743, 'eval_steps_per_second': 73.968, 'epoch': 1.0}\n",
      "{'train_runtime': 145.6835, 'train_samples_per_second': 109.827, 'train_steps_per_second': 13.728, 'train_loss': 0.5487928781509399, 'epoch': 1.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     0.5488\n",
      "  train_runtime            = 0:02:25.68\n",
      "  train_samples            =      16000\n",
      "  train_samples_per_second =    109.827\n",
      "  train_steps_per_second   =     13.728\n",
      "01/26/2024 01:09:53 - INFO - __main__ - *** Evaluate ***\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =      0.914\n",
      "  eval_loss               =     0.2712\n",
      "  eval_runtime            = 0:00:03.59\n",
      "  eval_samples            =       2000\n",
      "  eval_samples_per_second =    555.951\n",
      "  eval_steps_per_second   =     69.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-019d6cd006d41b2b\n",
      "Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:07:18,565 >> loading configuration file config.json from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:07:18,566 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:550] 2024-01-26 01:07:18,936 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:07:19,120 >> loading configuration file config.json from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:07:19,120 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file vocab.json from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\vocab.json\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file merges.txt from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\merges.txt\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file tokenizer.json from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:07:19,463 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:07:19,463 >> loading configuration file config.json from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:07:19,464 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2993] 2024-01-26 01:07:19,496 >> loading weights file model.safetensors from cache at .cache_training\\models--roberta-base\\snapshots\\bc2764f8af2e92b6eb5679868df33e224075ca68\\model.safetensors\n",
      "[INFO|modeling_utils.py:3765] 2024-01-26 01:07:20,283 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassificationCustom: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3777] 2024-01-26 01:07:20,283 >> Some weights of RobertaForSequenceClassificationCustom were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense_1.bias', 'classifier.dense_3.bias', 'classifier.out_proj.weight', 'classifier.dense_1.weight', 'classifier.out_proj.bias', 'classifier.dense_2.weight', 'classifier.dense_3.weight', 'classifier.dense_2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-31a5bbbff78bd7d5.arrow\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-e6d15e97d08181cd.arrow\n",
      "\n",
      "Running tokenizer on dataset: 100%|██████████| 2000/2000 [00:00<00:00, 26811.63 examples/s]\n",
      "[INFO|trainer.py:761] 2024-01-26 01:07:22,066 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:1760] 2024-01-26 01:07:22,070 >> ***** Running training *****\n",
      "[INFO|trainer.py:1761] 2024-01-26 01:07:22,070 >>   Num examples = 16,000\n",
      "[INFO|trainer.py:1762] 2024-01-26 01:07:22,070 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1763] 2024-01-26 01:07:22,070 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1766] 2024-01-26 01:07:22,070 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1767] 2024-01-26 01:07:22,070 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1768] 2024-01-26 01:07:22,070 >>   Total optimization steps = 2,000\n",
      "[INFO|trainer.py:1769] 2024-01-26 01:07:22,071 >>   Number of trainable parameters = 130,552,326\n",
      "\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/2000 [00:01<37:55,  1.14s/it]\n",
      "  0%|          | 3/2000 [00:01<11:38,  2.86it/s]\n",
      "  0%|          | 5/2000 [00:01<06:44,  4.93it/s]\n",
      "  0%|          | 7/2000 [00:01<04:45,  6.97it/s]\n",
      "  0%|          | 9/2000 [00:01<03:44,  8.86it/s]\n",
      "  1%|          | 11/2000 [00:01<03:09, 10.48it/s]\n",
      "  1%|          | 13/2000 [00:01<02:47, 11.85it/s]\n",
      "  1%|          | 15/2000 [00:02<02:32, 12.98it/s]\n",
      "  1%|          | 17/2000 [00:02<02:24, 13.75it/s]\n",
      "  1%|          | 19/2000 [00:02<02:17, 14.39it/s]\n",
      "  1%|          | 21/2000 [00:02<02:13, 14.80it/s]\n",
      "  1%|          | 23/2000 [00:02<02:09, 15.23it/s]\n",
      "  1%|▏         | 25/2000 [00:02<02:07, 15.45it/s]\n",
      "  1%|▏         | 27/2000 [00:02<02:05, 15.71it/s]\n",
      "  1%|▏         | 29/2000 [00:02<02:05, 15.65it/s]\n",
      "  2%|▏         | 31/2000 [00:03<02:05, 15.66it/s]\n",
      "  2%|▏         | 33/2000 [00:03<02:03, 15.89it/s]\n",
      "  2%|▏         | 35/2000 [00:03<02:03, 15.92it/s]\n",
      "  2%|▏         | 37/2000 [00:03<02:02, 16.00it/s]\n",
      "  2%|▏         | 39/2000 [00:03<02:02, 16.06it/s]\n",
      "  2%|▏         | 41/2000 [00:03<02:02, 15.96it/s]\n",
      "  2%|▏         | 43/2000 [00:03<02:01, 16.10it/s]\n",
      "  2%|▏         | 45/2000 [00:03<02:02, 15.98it/s]\n",
      "  2%|▏         | 47/2000 [00:04<02:01, 16.03it/s]\n",
      "  2%|▏         | 49/2000 [00:04<02:01, 16.09it/s]\n",
      "                                                 \n",
      "\n",
      "  2%|▎         | 50/2000 [00:04<02:01, 16.09it/s]\n",
      "  3%|▎         | 51/2000 [00:04<02:01, 15.99it/s]\n",
      "  3%|▎         | 53/2000 [00:04<02:02, 15.95it/s]\n",
      "  3%|▎         | 55/2000 [00:04<02:01, 15.94it/s]\n",
      "  3%|▎         | 57/2000 [00:04<02:00, 16.07it/s]\n",
      "  3%|▎         | 59/2000 [00:04<02:02, 15.89it/s]\n",
      "  3%|▎         | 61/2000 [00:04<02:06, 15.38it/s]\n",
      "  3%|▎         | 63/2000 [00:05<02:06, 15.30it/s]\n",
      "  3%|▎         | 65/2000 [00:05<02:05, 15.44it/s]\n",
      "  3%|▎         | 67/2000 [00:05<02:03, 15.64it/s]\n",
      "  3%|▎         | 69/2000 [00:05<02:02, 15.81it/s]\n",
      "  4%|▎         | 71/2000 [00:05<02:01, 15.88it/s]\n",
      "  4%|▎         | 73/2000 [00:05<02:00, 15.94it/s]\n",
      "  4%|▍         | 75/2000 [00:05<02:02, 15.75it/s]\n",
      "  4%|▍         | 77/2000 [00:05<02:04, 15.41it/s]\n",
      "  4%|▍         | 79/2000 [00:06<02:03, 15.54it/s]\n",
      "  4%|▍         | 81/2000 [00:06<02:02, 15.69it/s]\n",
      "  4%|▍         | 83/2000 [00:06<02:01, 15.75it/s]\n",
      "  4%|▍         | 85/2000 [00:06<02:00, 15.93it/s]\n",
      "  4%|▍         | 87/2000 [00:06<01:59, 16.02it/s]\n",
      "  4%|▍         | 89/2000 [00:06<01:58, 16.09it/s]\n",
      "  5%|▍         | 91/2000 [00:06<01:59, 15.99it/s]\n",
      "  5%|▍         | 93/2000 [00:06<01:58, 16.05it/s]\n",
      "  5%|▍         | 95/2000 [00:07<01:59, 16.00it/s]\n",
      "  5%|▍         | 97/2000 [00:07<01:58, 16.02it/s]\n",
      "  5%|▍         | 99/2000 [00:07<01:58, 16.08it/s]\n",
      "                                                 \n",
      "\n",
      "  5%|▌         | 100/2000 [00:07<01:58, 16.08it/s]\n",
      "  5%|▌         | 101/2000 [00:07<01:58, 15.99it/s]\n",
      "  5%|▌         | 103/2000 [00:07<01:58, 16.03it/s]\n",
      "  5%|▌         | 105/2000 [00:07<01:58, 16.02it/s]\n",
      "  5%|▌         | 107/2000 [00:07<01:58, 15.95it/s]\n",
      "  5%|▌         | 109/2000 [00:07<01:57, 16.03it/s]\n",
      "  6%|▌         | 111/2000 [00:08<01:58, 15.98it/s]\n",
      "  6%|▌         | 113/2000 [00:08<01:58, 15.89it/s]\n",
      "  6%|▌         | 115/2000 [00:08<01:58, 15.97it/s]\n",
      "  6%|▌         | 117/2000 [00:08<01:57, 16.04it/s]\n",
      "  6%|▌         | 119/2000 [00:08<01:56, 16.09it/s]\n",
      "  6%|▌         | 121/2000 [00:08<01:56, 16.10it/s]\n",
      "  6%|▌         | 123/2000 [00:08<01:56, 16.09it/s]\n",
      "  6%|▋         | 125/2000 [00:08<01:56, 16.07it/s]\n",
      "  6%|▋         | 127/2000 [00:09<01:56, 16.07it/s]\n",
      "  6%|▋         | 129/2000 [00:09<01:56, 16.01it/s]\n",
      "  7%|▋         | 131/2000 [00:09<01:57, 15.84it/s]\n",
      "  7%|▋         | 133/2000 [00:09<01:57, 15.95it/s]\n",
      "  7%|▋         | 135/2000 [00:09<01:56, 16.00it/s]\n",
      "  7%|▋         | 137/2000 [00:09<01:56, 16.05it/s]\n",
      "  7%|▋         | 139/2000 [00:09<01:56, 16.02it/s]\n",
      "  7%|▋         | 141/2000 [00:09<01:57, 15.85it/s]\n",
      "  7%|▋         | 143/2000 [00:10<01:56, 15.98it/s]\n",
      "  7%|▋         | 145/2000 [00:10<01:55, 16.05it/s]\n",
      "  7%|▋         | 147/2000 [00:10<01:55, 16.00it/s]\n",
      "  7%|▋         | 149/2000 [00:10<01:56, 15.95it/s]\n",
      "                                                  \n",
      "\n",
      "  8%|▊         | 150/2000 [00:10<01:55, 15.95it/s]\n",
      "  8%|▊         | 151/2000 [00:10<01:55, 16.06it/s]\n",
      "  8%|▊         | 153/2000 [00:10<01:55, 15.97it/s]\n",
      "  8%|▊         | 155/2000 [00:10<01:54, 16.05it/s]\n",
      "  8%|▊         | 157/2000 [00:10<01:54, 16.04it/s]\n",
      "  8%|▊         | 159/2000 [00:11<01:54, 16.10it/s]\n",
      "  8%|▊         | 161/2000 [00:11<01:54, 16.11it/s]\n",
      "  8%|▊         | 163/2000 [00:11<01:54, 16.09it/s]\n",
      "  8%|▊         | 165/2000 [00:11<01:54, 16.04it/s]\n",
      "  8%|▊         | 167/2000 [00:11<01:53, 16.08it/s]\n",
      "  8%|▊         | 169/2000 [00:11<01:54, 16.05it/s]\n",
      "  9%|▊         | 171/2000 [00:11<01:54, 15.97it/s]\n",
      "  9%|▊         | 173/2000 [00:11<01:54, 15.90it/s]\n",
      "  9%|▉         | 175/2000 [00:12<01:53, 16.04it/s]\n",
      "  9%|▉         | 177/2000 [00:12<01:55, 15.72it/s]\n",
      "  9%|▉         | 179/2000 [00:12<01:54, 15.91it/s]\n",
      "  9%|▉         | 181/2000 [00:12<01:53, 15.98it/s]\n",
      "  9%|▉         | 183/2000 [00:12<01:53, 15.95it/s]\n",
      "  9%|▉         | 185/2000 [00:12<01:53, 16.01it/s]\n",
      "  9%|▉         | 187/2000 [00:12<01:53, 16.02it/s]\n",
      "  9%|▉         | 189/2000 [00:12<01:52, 16.15it/s]\n",
      " 10%|▉         | 191/2000 [00:13<01:53, 15.92it/s]\n",
      " 10%|▉         | 193/2000 [00:13<01:57, 15.43it/s]\n",
      " 10%|▉         | 195/2000 [00:13<01:56, 15.47it/s]\n",
      " 10%|▉         | 197/2000 [00:13<01:54, 15.72it/s]\n",
      " 10%|▉         | 199/2000 [00:13<01:53, 15.86it/s]\n",
      "                                                  \n",
      "\n",
      " 10%|█         | 200/2000 [00:13<01:53, 15.86it/s]\n",
      " 10%|█         | 201/2000 [00:13<01:53, 15.90it/s]\n",
      " 10%|█         | 203/2000 [00:13<01:52, 16.03it/s]\n",
      " 10%|█         | 205/2000 [00:13<01:52, 15.96it/s]\n",
      " 10%|█         | 207/2000 [00:14<01:52, 15.95it/s]\n",
      " 10%|█         | 209/2000 [00:14<01:51, 16.06it/s]\n",
      " 11%|█         | 211/2000 [00:14<01:51, 16.03it/s]\n",
      " 11%|█         | 213/2000 [00:14<01:51, 15.99it/s]\n",
      " 11%|█         | 215/2000 [00:14<01:51, 16.01it/s]\n",
      " 11%|█         | 217/2000 [00:14<01:51, 15.98it/s]\n",
      " 11%|█         | 219/2000 [00:14<01:50, 16.05it/s]\n",
      " 11%|█         | 221/2000 [00:14<01:51, 16.02it/s]\n",
      " 11%|█         | 223/2000 [00:15<01:51, 15.98it/s]\n",
      " 11%|█▏        | 225/2000 [00:15<01:50, 16.07it/s]\n",
      " 11%|█▏        | 227/2000 [00:15<01:50, 16.08it/s]\n",
      " 11%|█▏        | 229/2000 [00:15<01:53, 15.58it/s]\n",
      " 12%|█▏        | 231/2000 [00:15<01:53, 15.55it/s]\n",
      " 12%|█▏        | 233/2000 [00:15<01:53, 15.61it/s]\n",
      " 12%|█▏        | 235/2000 [00:15<01:51, 15.78it/s]\n",
      " 12%|█▏        | 237/2000 [00:15<01:51, 15.85it/s]\n",
      " 12%|█▏        | 239/2000 [00:16<01:50, 15.95it/s]\n",
      " 12%|█▏        | 241/2000 [00:16<01:51, 15.71it/s]\n",
      " 12%|█▏        | 243/2000 [00:16<01:50, 15.90it/s]\n",
      " 12%|█▏        | 245/2000 [00:16<01:49, 16.01it/s]\n",
      " 12%|█▏        | 247/2000 [00:16<01:48, 16.08it/s]\n",
      " 12%|█▏        | 249/2000 [00:16<01:49, 16.06it/s]\n",
      "                                                  \n",
      "\n",
      " 12%|█▎        | 250/2000 [00:16<01:48, 16.06it/s]\n",
      " 13%|█▎        | 251/2000 [00:16<01:48, 16.09it/s]\n",
      " 13%|█▎        | 253/2000 [00:16<01:48, 16.10it/s]\n",
      " 13%|█▎        | 255/2000 [00:17<01:48, 16.09it/s]\n",
      " 13%|█▎        | 257/2000 [00:17<01:48, 16.03it/s]\n",
      " 13%|█▎        | 259/2000 [00:17<01:49, 15.94it/s]\n",
      " 13%|█▎        | 261/2000 [00:17<01:47, 16.16it/s]\n",
      " 13%|█▎        | 263/2000 [00:17<01:48, 16.07it/s]\n",
      " 13%|█▎        | 265/2000 [00:17<01:47, 16.08it/s]\n",
      " 13%|█▎        | 267/2000 [00:17<01:48, 16.02it/s]\n",
      " 13%|█▎        | 269/2000 [00:17<01:51, 15.56it/s]\n",
      " 14%|█▎        | 271/2000 [00:18<01:51, 15.48it/s]\n",
      " 14%|█▎        | 273/2000 [00:18<01:49, 15.73it/s]\n",
      " 14%|█▍        | 275/2000 [00:18<01:50, 15.55it/s]\n",
      " 14%|█▍        | 277/2000 [00:18<01:51, 15.41it/s]\n",
      " 14%|█▍        | 279/2000 [00:18<01:50, 15.52it/s]\n",
      " 14%|█▍        | 281/2000 [00:18<01:49, 15.70it/s]\n",
      " 14%|█▍        | 283/2000 [00:18<01:48, 15.80it/s]\n",
      " 14%|█▍        | 285/2000 [00:18<01:47, 15.92it/s]\n",
      " 14%|█▍        | 287/2000 [00:19<01:47, 15.92it/s]\n",
      " 14%|█▍        | 289/2000 [00:19<01:47, 15.88it/s]\n",
      " 15%|█▍        | 291/2000 [00:19<01:47, 15.97it/s]\n",
      " 15%|█▍        | 293/2000 [00:19<01:46, 15.97it/s]\n",
      " 15%|█▍        | 295/2000 [00:19<01:46, 16.02it/s]\n",
      " 15%|█▍        | 297/2000 [00:19<01:47, 15.89it/s]\n",
      " 15%|█▍        | 299/2000 [00:19<01:47, 15.88it/s]\n",
      "                                                  \n",
      "\n",
      " 15%|█▌        | 300/2000 [00:19<01:47, 15.88it/s]\n",
      " 15%|█▌        | 301/2000 [00:19<01:46, 15.96it/s]\n",
      " 15%|█▌        | 303/2000 [00:20<01:46, 15.97it/s]\n",
      " 15%|█▌        | 305/2000 [00:20<01:45, 16.03it/s]\n",
      " 15%|█▌        | 307/2000 [00:20<01:45, 16.05it/s]\n",
      " 15%|█▌        | 309/2000 [00:20<01:45, 16.08it/s]\n",
      " 16%|█▌        | 311/2000 [00:20<01:45, 15.98it/s]\n",
      " 16%|█▌        | 313/2000 [00:20<01:45, 16.05it/s]\n",
      " 16%|█▌        | 315/2000 [00:20<01:45, 16.04it/s]\n",
      " 16%|█▌        | 317/2000 [00:20<01:44, 16.06it/s]\n",
      " 16%|█▌        | 319/2000 [00:21<01:44, 16.04it/s]\n",
      " 16%|█▌        | 321/2000 [00:21<01:44, 16.00it/s]\n",
      " 16%|█▌        | 323/2000 [00:21<01:44, 16.06it/s]\n",
      " 16%|█▋        | 325/2000 [00:21<01:44, 16.06it/s]\n",
      " 16%|█▋        | 327/2000 [00:21<01:44, 15.95it/s]\n",
      " 16%|█▋        | 329/2000 [00:21<01:44, 15.94it/s]\n",
      " 17%|█▋        | 331/2000 [00:21<01:44, 15.96it/s]\n",
      " 17%|█▋        | 333/2000 [00:21<01:44, 15.95it/s]\n",
      " 17%|█▋        | 335/2000 [00:22<01:43, 16.06it/s]\n",
      " 17%|█▋        | 337/2000 [00:22<01:43, 16.00it/s]\n",
      " 17%|█▋        | 339/2000 [00:22<01:43, 16.04it/s]\n",
      " 17%|█▋        | 341/2000 [00:22<01:43, 16.10it/s]\n",
      " 17%|█▋        | 343/2000 [00:22<01:43, 16.05it/s]\n",
      " 17%|█▋        | 345/2000 [00:22<01:43, 16.05it/s]\n",
      " 17%|█▋        | 347/2000 [00:22<01:43, 15.92it/s]\n",
      " 17%|█▋        | 349/2000 [00:22<01:42, 16.11it/s]\n",
      "                                                  \n",
      "\n",
      " 18%|█▊        | 350/2000 [00:23<01:42, 16.11it/s]\n",
      " 18%|█▊        | 351/2000 [00:23<01:42, 16.11it/s]\n",
      " 18%|█▊        | 353/2000 [00:23<01:42, 16.03it/s]\n",
      " 18%|█▊        | 355/2000 [00:23<01:42, 16.11it/s]\n",
      " 18%|█▊        | 357/2000 [00:23<01:45, 15.53it/s]\n",
      " 18%|█▊        | 359/2000 [00:23<01:44, 15.69it/s]\n",
      " 18%|█▊        | 361/2000 [00:23<01:43, 15.85it/s]\n",
      " 18%|█▊        | 363/2000 [00:23<01:43, 15.79it/s]\n",
      " 18%|█▊        | 365/2000 [00:24<01:42, 15.89it/s]\n",
      " 18%|█▊        | 367/2000 [00:24<01:43, 15.81it/s]\n",
      " 18%|█▊        | 369/2000 [00:24<01:42, 15.93it/s]\n",
      " 19%|█▊        | 371/2000 [00:24<01:45, 15.45it/s]\n",
      " 19%|█▊        | 373/2000 [00:24<01:44, 15.60it/s]\n",
      " 19%|█▉        | 375/2000 [00:24<01:43, 15.73it/s]\n",
      " 19%|█▉        | 377/2000 [00:24<01:42, 15.81it/s]\n",
      " 19%|█▉        | 379/2000 [00:24<01:41, 15.98it/s]\n",
      " 19%|█▉        | 381/2000 [00:25<01:42, 15.76it/s]\n",
      " 19%|█▉        | 383/2000 [00:25<01:41, 15.87it/s]\n",
      " 19%|█▉        | 385/2000 [00:25<01:41, 15.88it/s]\n",
      " 19%|█▉        | 387/2000 [00:25<01:41, 15.97it/s]\n",
      " 19%|█▉        | 389/2000 [00:25<01:40, 16.05it/s]\n",
      " 20%|█▉        | 391/2000 [00:25<01:40, 16.02it/s]\n",
      " 20%|█▉        | 393/2000 [00:25<01:39, 16.12it/s]\n",
      " 20%|█▉        | 395/2000 [00:25<01:39, 16.05it/s]\n",
      " 20%|█▉        | 397/2000 [00:26<01:40, 16.02it/s]\n",
      " 20%|█▉        | 399/2000 [00:26<01:39, 16.05it/s]\n",
      "                                                  \n",
      "\n",
      " 20%|██        | 400/2000 [00:26<01:39, 16.05it/s]\n",
      " 20%|██        | 401/2000 [00:26<01:40, 15.97it/s]\n",
      " 20%|██        | 403/2000 [00:26<01:39, 16.06it/s]\n",
      " 20%|██        | 405/2000 [00:26<01:39, 16.03it/s]\n",
      " 20%|██        | 407/2000 [00:26<01:39, 15.98it/s]\n",
      " 20%|██        | 409/2000 [00:26<01:39, 16.06it/s]\n",
      " 21%|██        | 411/2000 [00:26<01:38, 16.08it/s]\n",
      " 21%|██        | 413/2000 [00:27<01:39, 15.94it/s]\n",
      " 21%|██        | 415/2000 [00:27<01:39, 15.92it/s]\n",
      " 21%|██        | 417/2000 [00:27<01:39, 15.99it/s]\n",
      " 21%|██        | 419/2000 [00:27<01:39, 15.89it/s]\n",
      " 21%|██        | 421/2000 [00:27<01:38, 15.99it/s]\n",
      " 21%|██        | 423/2000 [00:27<01:39, 15.88it/s]\n",
      " 21%|██▏       | 425/2000 [00:27<01:41, 15.48it/s]\n",
      " 21%|██▏       | 427/2000 [00:27<01:40, 15.58it/s]\n",
      " 21%|██▏       | 429/2000 [00:28<01:39, 15.76it/s]\n",
      " 22%|██▏       | 431/2000 [00:28<01:38, 15.93it/s]\n",
      " 22%|██▏       | 433/2000 [00:28<01:38, 15.88it/s]\n",
      " 22%|██▏       | 435/2000 [00:28<01:38, 15.96it/s]\n",
      " 22%|██▏       | 437/2000 [00:28<01:37, 15.97it/s]\n",
      " 22%|██▏       | 439/2000 [00:28<01:37, 16.09it/s]\n",
      " 22%|██▏       | 441/2000 [00:28<01:37, 15.94it/s]\n",
      " 22%|██▏       | 443/2000 [00:28<01:37, 16.03it/s]\n",
      " 22%|██▏       | 445/2000 [00:29<01:36, 16.07it/s]\n",
      " 22%|██▏       | 447/2000 [00:29<01:36, 16.08it/s]\n",
      " 22%|██▏       | 449/2000 [00:29<01:36, 16.03it/s]\n",
      "                                                  \n",
      "\n",
      " 22%|██▎       | 450/2000 [00:29<01:36, 16.03it/s]\n",
      " 23%|██▎       | 451/2000 [00:29<01:36, 15.97it/s]\n",
      " 23%|██▎       | 453/2000 [00:29<01:36, 16.03it/s]\n",
      " 23%|██▎       | 455/2000 [00:29<01:36, 15.94it/s]\n",
      " 23%|██▎       | 457/2000 [00:29<01:36, 15.96it/s]\n",
      " 23%|██▎       | 459/2000 [00:29<01:36, 16.05it/s]\n",
      " 23%|██▎       | 461/2000 [00:30<01:35, 16.06it/s]\n",
      " 23%|██▎       | 463/2000 [00:30<01:35, 16.05it/s]\n",
      " 23%|██▎       | 465/2000 [00:30<01:36, 15.96it/s]\n",
      " 23%|██▎       | 467/2000 [00:30<01:35, 16.05it/s]\n",
      " 23%|██▎       | 469/2000 [00:30<01:35, 16.04it/s]\n",
      " 24%|██▎       | 471/2000 [00:30<01:36, 15.79it/s]\n",
      " 24%|██▎       | 473/2000 [00:30<01:35, 16.05it/s]\n",
      " 24%|██▍       | 475/2000 [00:30<01:34, 16.12it/s]\n",
      " 24%|██▍       | 477/2000 [00:31<01:34, 16.07it/s]\n",
      " 24%|██▍       | 479/2000 [00:31<01:34, 16.06it/s]\n",
      " 24%|██▍       | 481/2000 [00:31<01:35, 15.97it/s]\n",
      " 24%|██▍       | 483/2000 [00:31<01:34, 16.08it/s]\n",
      " 24%|██▍       | 485/2000 [00:31<01:34, 16.07it/s]\n",
      " 24%|██▍       | 487/2000 [00:31<01:34, 16.04it/s]\n",
      " 24%|██▍       | 489/2000 [00:31<01:33, 16.13it/s]\n",
      " 25%|██▍       | 491/2000 [00:31<01:33, 16.06it/s]\n",
      " 25%|██▍       | 493/2000 [00:32<01:34, 15.94it/s]\n",
      " 25%|██▍       | 495/2000 [00:32<01:35, 15.83it/s]\n",
      " 25%|██▍       | 497/2000 [00:32<01:34, 15.85it/s]\n",
      " 25%|██▍       | 499/2000 [00:32<01:34, 15.93it/s]\n",
      "                                                  \n",
      "\n",
      " 25%|██▌       | 500/2000 [00:32<01:34, 15.93it/s]\n",
      " 25%|██▌       | 501/2000 [00:32<01:34, 15.94it/s]\n",
      " 25%|██▌       | 503/2000 [00:32<01:33, 15.97it/s]\n",
      " 25%|██▌       | 505/2000 [00:32<01:34, 15.90it/s]\n",
      " 25%|██▌       | 507/2000 [00:32<01:32, 16.06it/s]\n",
      " 25%|██▌       | 509/2000 [00:33<01:32, 16.10it/s]\n",
      " 26%|██▌       | 511/2000 [00:33<01:32, 16.04it/s]\n",
      " 26%|██▌       | 513/2000 [00:33<01:32, 16.03it/s]\n",
      " 26%|██▌       | 515/2000 [00:33<01:32, 16.07it/s]\n",
      " 26%|██▌       | 517/2000 [00:33<01:32, 16.09it/s]\n",
      " 26%|██▌       | 519/2000 [00:33<01:32, 16.06it/s]\n",
      " 26%|██▌       | 521/2000 [00:33<01:32, 15.95it/s]\n",
      " 26%|██▌       | 523/2000 [00:33<01:31, 16.10it/s]\n",
      " 26%|██▋       | 525/2000 [00:34<01:31, 16.07it/s]\n",
      " 26%|██▋       | 527/2000 [00:34<01:32, 16.00it/s]\n",
      " 26%|██▋       | 529/2000 [00:34<01:31, 16.09it/s]\n",
      " 27%|██▋       | 531/2000 [00:34<01:31, 16.08it/s]\n",
      " 27%|██▋       | 533/2000 [00:34<01:32, 15.94it/s]\n",
      " 27%|██▋       | 535/2000 [00:34<01:31, 15.93it/s]\n",
      " 27%|██▋       | 537/2000 [00:34<01:31, 16.01it/s]\n",
      " 27%|██▋       | 539/2000 [00:34<01:31, 15.99it/s]\n",
      " 27%|██▋       | 541/2000 [00:35<01:31, 16.02it/s]\n",
      " 27%|██▋       | 543/2000 [00:35<01:31, 15.95it/s]\n",
      " 27%|██▋       | 545/2000 [00:35<01:30, 16.00it/s]\n",
      " 27%|██▋       | 547/2000 [00:35<01:30, 16.04it/s]\n",
      " 27%|██▋       | 549/2000 [00:35<01:30, 16.06it/s]\n",
      "                                                  \n",
      "\n",
      " 28%|██▊       | 550/2000 [00:35<01:30, 16.06it/s]\n",
      " 28%|██▊       | 551/2000 [00:35<01:33, 15.55it/s]\n",
      " 28%|██▊       | 553/2000 [00:35<01:33, 15.47it/s]\n",
      " 28%|██▊       | 555/2000 [00:35<01:31, 15.74it/s]\n",
      " 28%|██▊       | 557/2000 [00:36<01:30, 15.88it/s]\n",
      " 28%|██▊       | 559/2000 [00:36<01:30, 15.97it/s]\n",
      " 28%|██▊       | 561/2000 [00:36<01:29, 16.00it/s]\n",
      " 28%|██▊       | 563/2000 [00:36<01:30, 15.95it/s]\n",
      " 28%|██▊       | 565/2000 [00:36<01:29, 16.07it/s]\n",
      " 28%|██▊       | 567/2000 [00:36<01:29, 16.01it/s]\n",
      " 28%|██▊       | 569/2000 [00:36<01:29, 16.03it/s]\n",
      " 29%|██▊       | 571/2000 [00:36<01:29, 16.00it/s]\n",
      " 29%|██▊       | 573/2000 [00:37<01:28, 16.11it/s]\n",
      " 29%|██▉       | 575/2000 [00:37<01:28, 16.06it/s]\n",
      " 29%|██▉       | 577/2000 [00:37<01:28, 16.04it/s]\n",
      " 29%|██▉       | 579/2000 [00:37<01:28, 16.08it/s]\n",
      " 29%|██▉       | 581/2000 [00:37<01:28, 16.04it/s]\n",
      " 29%|██▉       | 583/2000 [00:37<01:28, 16.05it/s]\n",
      " 29%|██▉       | 585/2000 [00:37<01:28, 15.96it/s]\n",
      " 29%|██▉       | 587/2000 [00:37<01:31, 15.48it/s]\n",
      " 29%|██▉       | 589/2000 [00:38<01:30, 15.61it/s]\n",
      " 30%|██▉       | 591/2000 [00:38<01:29, 15.72it/s]\n",
      " 30%|██▉       | 593/2000 [00:38<01:29, 15.75it/s]\n",
      " 30%|██▉       | 595/2000 [00:38<01:28, 15.82it/s]\n",
      " 30%|██▉       | 597/2000 [00:38<01:28, 15.92it/s]\n",
      " 30%|██▉       | 599/2000 [00:38<01:27, 15.95it/s]\n",
      "                                                  \n",
      "\n",
      " 30%|███       | 600/2000 [00:38<01:27, 15.95it/s]\n",
      " 30%|███       | 601/2000 [00:38<01:27, 16.08it/s]\n",
      " 30%|███       | 603/2000 [00:38<01:27, 15.98it/s]\n",
      " 30%|███       | 605/2000 [00:39<01:26, 16.14it/s]\n",
      " 30%|███       | 607/2000 [00:39<01:27, 15.98it/s]\n",
      " 30%|███       | 609/2000 [00:39<01:27, 15.96it/s]\n",
      " 31%|███       | 611/2000 [00:39<01:26, 16.01it/s]\n",
      " 31%|███       | 613/2000 [00:39<01:26, 16.03it/s]\n",
      " 31%|███       | 615/2000 [00:39<01:26, 15.99it/s]\n",
      " 31%|███       | 617/2000 [00:39<01:26, 16.02it/s]\n",
      " 31%|███       | 619/2000 [00:39<01:25, 16.06it/s]\n",
      " 31%|███       | 621/2000 [00:40<01:25, 16.08it/s]\n",
      " 31%|███       | 623/2000 [00:40<01:25, 16.09it/s]\n",
      " 31%|███▏      | 625/2000 [00:40<01:26, 15.99it/s]\n",
      " 31%|███▏      | 627/2000 [00:40<01:25, 15.99it/s]\n",
      " 31%|███▏      | 629/2000 [00:40<01:26, 15.77it/s]\n",
      " 32%|███▏      | 631/2000 [00:40<01:27, 15.56it/s]\n",
      " 32%|███▏      | 633/2000 [00:40<01:27, 15.68it/s]\n",
      " 32%|███▏      | 635/2000 [00:40<01:26, 15.80it/s]\n",
      " 32%|███▏      | 637/2000 [00:41<01:25, 15.87it/s]\n",
      " 32%|███▏      | 639/2000 [00:41<01:25, 15.86it/s]\n",
      " 32%|███▏      | 641/2000 [00:41<01:25, 15.98it/s]\n",
      " 32%|███▏      | 643/2000 [00:41<01:24, 16.00it/s]\n",
      " 32%|███▏      | 645/2000 [00:41<01:24, 15.99it/s]\n",
      " 32%|███▏      | 647/2000 [00:41<01:24, 15.97it/s]\n",
      " 32%|███▏      | 649/2000 [00:41<01:24, 15.92it/s]\n",
      "                                                  \n",
      "\n",
      " 32%|███▎      | 650/2000 [00:41<01:24, 15.92it/s]\n",
      " 33%|███▎      | 651/2000 [00:41<01:24, 15.99it/s]\n",
      " 33%|███▎      | 653/2000 [00:42<01:24, 16.03it/s]\n",
      " 33%|███▎      | 655/2000 [00:42<01:23, 16.01it/s]\n",
      " 33%|███▎      | 657/2000 [00:42<01:23, 16.10it/s]\n",
      " 33%|███▎      | 659/2000 [00:42<01:23, 16.06it/s]\n",
      " 33%|███▎      | 661/2000 [00:42<01:23, 16.07it/s]\n",
      " 33%|███▎      | 663/2000 [00:42<01:23, 15.99it/s]\n",
      " 33%|███▎      | 665/2000 [00:42<01:23, 15.95it/s]\n",
      " 33%|███▎      | 667/2000 [00:42<01:23, 15.92it/s]\n",
      " 33%|███▎      | 669/2000 [00:43<01:23, 15.94it/s]\n",
      " 34%|███▎      | 671/2000 [00:43<01:23, 15.84it/s]\n",
      " 34%|███▎      | 673/2000 [00:43<01:23, 15.94it/s]\n",
      " 34%|███▍      | 675/2000 [00:43<01:25, 15.46it/s]\n",
      " 34%|███▍      | 677/2000 [00:43<01:24, 15.63it/s]\n",
      " 34%|███▍      | 679/2000 [00:43<01:24, 15.63it/s]\n",
      " 34%|███▍      | 681/2000 [00:43<01:23, 15.88it/s]\n",
      " 34%|███▍      | 683/2000 [00:43<01:25, 15.45it/s]\n",
      " 34%|███▍      | 685/2000 [00:44<01:24, 15.59it/s]\n",
      " 34%|███▍      | 687/2000 [00:44<01:23, 15.71it/s]\n",
      " 34%|███▍      | 689/2000 [00:44<01:22, 15.85it/s]\n",
      " 35%|███▍      | 691/2000 [00:44<01:22, 15.79it/s]\n",
      " 35%|███▍      | 693/2000 [00:44<01:22, 15.89it/s]\n",
      " 35%|███▍      | 695/2000 [00:44<01:22, 15.88it/s]\n",
      " 35%|███▍      | 697/2000 [00:44<01:22, 15.84it/s]\n",
      " 35%|███▍      | 699/2000 [00:44<01:24, 15.48it/s]\n",
      "                                                  \n",
      "\n",
      " 35%|███▌      | 700/2000 [00:45<01:23, 15.48it/s]\n",
      " 35%|███▌      | 701/2000 [00:45<01:23, 15.63it/s]\n",
      " 35%|███▌      | 703/2000 [00:45<01:22, 15.72it/s]\n",
      " 35%|███▌      | 705/2000 [00:45<01:21, 15.83it/s]\n",
      " 35%|███▌      | 707/2000 [00:45<01:21, 15.87it/s]\n",
      " 35%|███▌      | 709/2000 [00:45<01:20, 15.96it/s]\n",
      " 36%|███▌      | 711/2000 [00:45<01:20, 15.98it/s]\n",
      " 36%|███▌      | 713/2000 [00:45<01:20, 16.05it/s]\n",
      " 36%|███▌      | 715/2000 [00:45<01:20, 15.99it/s]\n",
      " 36%|███▌      | 717/2000 [00:46<01:20, 15.92it/s]\n",
      " 36%|███▌      | 719/2000 [00:46<01:20, 15.98it/s]\n",
      " 36%|███▌      | 721/2000 [00:46<01:20, 15.95it/s]\n",
      " 36%|███▌      | 723/2000 [00:46<01:19, 15.99it/s]\n",
      " 36%|███▋      | 725/2000 [00:46<01:19, 16.10it/s]\n",
      " 36%|███▋      | 727/2000 [00:46<01:19, 16.05it/s]\n",
      " 36%|███▋      | 729/2000 [00:46<01:19, 16.00it/s]\n",
      " 37%|███▋      | 731/2000 [00:46<01:19, 16.03it/s]\n",
      " 37%|███▋      | 733/2000 [00:47<01:19, 15.99it/s]\n",
      " 37%|███▋      | 735/2000 [00:47<01:18, 16.04it/s]\n",
      " 37%|███▋      | 737/2000 [00:47<01:19, 15.98it/s]\n",
      " 37%|███▋      | 739/2000 [00:47<01:18, 16.07it/s]\n",
      " 37%|███▋      | 741/2000 [00:47<01:18, 15.98it/s]\n",
      " 37%|███▋      | 743/2000 [00:47<01:18, 15.98it/s]\n",
      " 37%|███▋      | 745/2000 [00:47<01:18, 15.95it/s]\n",
      " 37%|███▋      | 747/2000 [00:47<01:18, 15.86it/s]\n",
      " 37%|███▋      | 749/2000 [00:48<01:18, 16.04it/s]\n",
      "                                                  \n",
      "\n",
      " 38%|███▊      | 750/2000 [00:48<01:17, 16.04it/s]\n",
      " 38%|███▊      | 751/2000 [00:48<01:18, 16.00it/s]\n",
      " 38%|███▊      | 753/2000 [00:48<01:17, 16.04it/s]\n",
      " 38%|███▊      | 755/2000 [00:48<01:18, 15.91it/s]\n",
      " 38%|███▊      | 757/2000 [00:48<01:17, 16.13it/s]\n",
      " 38%|███▊      | 759/2000 [00:48<01:16, 16.12it/s]\n",
      " 38%|███▊      | 761/2000 [00:48<01:17, 16.08it/s]\n",
      " 38%|███▊      | 763/2000 [00:48<01:16, 16.14it/s]\n",
      " 38%|███▊      | 765/2000 [00:49<01:16, 16.09it/s]\n",
      " 38%|███▊      | 767/2000 [00:49<01:16, 16.07it/s]\n",
      " 38%|███▊      | 769/2000 [00:49<01:16, 16.06it/s]\n",
      " 39%|███▊      | 771/2000 [00:49<01:16, 16.09it/s]\n",
      " 39%|███▊      | 773/2000 [00:49<01:16, 16.07it/s]\n",
      " 39%|███▉      | 775/2000 [00:49<01:16, 16.06it/s]\n",
      " 39%|███▉      | 777/2000 [00:49<01:16, 16.08it/s]\n",
      " 39%|███▉      | 779/2000 [00:49<01:15, 16.09it/s]\n",
      " 39%|███▉      | 781/2000 [00:50<01:15, 16.11it/s]\n",
      " 39%|███▉      | 783/2000 [00:50<01:15, 16.11it/s]\n",
      " 39%|███▉      | 785/2000 [00:50<01:15, 16.16it/s]\n",
      " 39%|███▉      | 787/2000 [00:50<01:15, 16.09it/s]\n",
      " 39%|███▉      | 789/2000 [00:50<01:15, 16.09it/s]\n",
      " 40%|███▉      | 791/2000 [00:50<01:15, 16.05it/s]\n",
      " 40%|███▉      | 793/2000 [00:50<01:15, 16.03it/s]\n",
      " 40%|███▉      | 795/2000 [00:50<01:15, 15.98it/s]\n",
      " 40%|███▉      | 797/2000 [00:51<01:16, 15.64it/s]\n",
      " 40%|███▉      | 799/2000 [00:51<01:16, 15.62it/s]\n",
      "                                                  \n",
      "\n",
      " 40%|████      | 800/2000 [00:51<01:16, 15.62it/s]\n",
      " 40%|████      | 801/2000 [00:51<01:16, 15.63it/s]\n",
      " 40%|████      | 803/2000 [00:51<01:15, 15.76it/s]\n",
      " 40%|████      | 805/2000 [00:51<01:15, 15.83it/s]\n",
      " 40%|████      | 807/2000 [00:51<01:14, 15.93it/s]\n",
      " 40%|████      | 809/2000 [00:51<01:14, 15.95it/s]\n",
      " 41%|████      | 811/2000 [00:51<01:14, 16.01it/s]\n",
      " 41%|████      | 813/2000 [00:52<01:14, 16.01it/s]\n",
      " 41%|████      | 815/2000 [00:52<01:14, 16.01it/s]\n",
      " 41%|████      | 817/2000 [00:52<01:13, 16.04it/s]\n",
      " 41%|████      | 819/2000 [00:52<01:13, 16.03it/s]\n",
      " 41%|████      | 821/2000 [00:52<01:13, 15.93it/s]\n",
      " 41%|████      | 823/2000 [00:52<01:13, 15.99it/s]\n",
      " 41%|████▏     | 825/2000 [00:52<01:13, 16.00it/s]\n",
      " 41%|████▏     | 827/2000 [00:52<01:13, 16.03it/s]\n",
      " 41%|████▏     | 829/2000 [00:53<01:12, 16.11it/s]\n",
      " 42%|████▏     | 831/2000 [00:53<01:12, 16.11it/s]\n",
      " 42%|████▏     | 833/2000 [00:53<01:12, 16.01it/s]\n",
      " 42%|████▏     | 835/2000 [00:53<01:12, 16.08it/s]\n",
      " 42%|████▏     | 837/2000 [00:53<01:12, 16.03it/s]\n",
      " 42%|████▏     | 839/2000 [00:53<01:12, 16.00it/s]\n",
      " 42%|████▏     | 841/2000 [00:53<01:12, 15.92it/s]\n",
      " 42%|████▏     | 843/2000 [00:53<01:11, 16.08it/s]\n",
      " 42%|████▏     | 845/2000 [00:54<01:11, 16.13it/s]\n",
      " 42%|████▏     | 847/2000 [00:54<01:11, 16.09it/s]\n",
      " 42%|████▏     | 849/2000 [00:54<01:11, 16.00it/s]\n",
      "                                                  \n",
      "\n",
      " 42%|████▎     | 850/2000 [00:54<01:11, 16.00it/s]\n",
      " 43%|████▎     | 851/2000 [00:54<01:11, 16.02it/s]\n",
      " 43%|████▎     | 853/2000 [00:54<01:11, 16.04it/s]\n",
      " 43%|████▎     | 855/2000 [00:54<01:11, 16.04it/s]\n",
      " 43%|████▎     | 857/2000 [00:54<01:11, 16.02it/s]\n",
      " 43%|████▎     | 859/2000 [00:54<01:10, 16.12it/s]\n",
      " 43%|████▎     | 861/2000 [00:55<01:11, 16.03it/s]\n",
      " 43%|████▎     | 863/2000 [00:55<01:10, 16.03it/s]\n",
      " 43%|████▎     | 865/2000 [00:55<01:11, 15.92it/s]\n",
      " 43%|████▎     | 867/2000 [00:55<01:10, 16.03it/s]\n",
      " 43%|████▎     | 869/2000 [00:55<01:10, 15.99it/s]\n",
      " 44%|████▎     | 871/2000 [00:55<01:10, 15.98it/s]\n",
      " 44%|████▎     | 873/2000 [00:55<01:10, 15.97it/s]\n",
      " 44%|████▍     | 875/2000 [00:55<01:10, 16.00it/s]\n",
      " 44%|████▍     | 877/2000 [00:56<01:09, 16.06it/s]\n",
      " 44%|████▍     | 879/2000 [00:56<01:09, 16.02it/s]\n",
      " 44%|████▍     | 881/2000 [00:56<01:09, 16.04it/s]\n",
      " 44%|████▍     | 883/2000 [00:56<01:09, 16.03it/s]\n",
      " 44%|████▍     | 885/2000 [00:56<01:09, 16.00it/s]\n",
      " 44%|████▍     | 887/2000 [00:56<01:09, 16.02it/s]\n",
      " 44%|████▍     | 889/2000 [00:56<01:09, 16.02it/s]\n",
      " 45%|████▍     | 891/2000 [00:56<01:09, 16.07it/s]\n",
      " 45%|████▍     | 893/2000 [00:57<01:09, 16.04it/s]\n",
      " 45%|████▍     | 895/2000 [00:57<01:08, 16.04it/s]\n",
      " 45%|████▍     | 897/2000 [00:57<01:08, 16.03it/s]\n",
      " 45%|████▍     | 899/2000 [00:57<01:08, 16.04it/s]\n",
      "                                                  \n",
      "\n",
      " 45%|████▌     | 900/2000 [00:57<01:08, 16.04it/s]\n",
      " 45%|████▌     | 901/2000 [00:57<01:08, 16.00it/s]\n",
      " 45%|████▌     | 903/2000 [00:57<01:08, 16.05it/s]\n",
      " 45%|████▌     | 905/2000 [00:57<01:08, 16.06it/s]\n",
      " 45%|████▌     | 907/2000 [00:57<01:08, 16.07it/s]\n",
      " 45%|████▌     | 909/2000 [00:58<01:08, 15.97it/s]\n",
      " 46%|████▌     | 911/2000 [00:58<01:07, 16.05it/s]\n",
      " 46%|████▌     | 913/2000 [00:58<01:07, 16.12it/s]\n",
      " 46%|████▌     | 915/2000 [00:58<01:07, 15.96it/s]\n",
      " 46%|████▌     | 917/2000 [00:58<01:07, 15.98it/s]\n",
      " 46%|████▌     | 919/2000 [00:58<01:07, 15.96it/s]\n",
      " 46%|████▌     | 921/2000 [00:58<01:07, 15.98it/s]\n",
      " 46%|████▌     | 923/2000 [00:58<01:07, 15.87it/s]\n",
      " 46%|████▋     | 925/2000 [00:59<01:07, 16.00it/s]\n",
      " 46%|████▋     | 927/2000 [00:59<01:06, 16.05it/s]\n",
      " 46%|████▋     | 929/2000 [00:59<01:06, 16.09it/s]\n",
      " 47%|████▋     | 931/2000 [00:59<01:06, 16.05it/s]\n",
      " 47%|████▋     | 933/2000 [00:59<01:06, 16.00it/s]\n",
      " 47%|████▋     | 935/2000 [00:59<01:06, 16.04it/s]\n",
      " 47%|████▋     | 937/2000 [00:59<01:05, 16.11it/s]\n",
      " 47%|████▋     | 939/2000 [00:59<01:05, 16.13it/s]\n",
      " 47%|████▋     | 941/2000 [01:00<01:05, 16.06it/s]\n",
      " 47%|████▋     | 943/2000 [01:00<01:05, 16.05it/s]\n",
      " 47%|████▋     | 945/2000 [01:00<01:06, 15.98it/s]\n",
      " 47%|████▋     | 947/2000 [01:00<01:05, 16.02it/s]\n",
      " 47%|████▋     | 949/2000 [01:00<01:05, 15.98it/s]\n",
      "                                                  \n",
      "\n",
      " 48%|████▊     | 950/2000 [01:00<01:05, 15.98it/s]\n",
      " 48%|████▊     | 951/2000 [01:00<01:05, 16.11it/s]\n",
      " 48%|████▊     | 953/2000 [01:00<01:04, 16.15it/s]\n",
      " 48%|████▊     | 955/2000 [01:00<01:04, 16.12it/s]\n",
      " 48%|████▊     | 957/2000 [01:01<01:04, 16.08it/s]\n",
      " 48%|████▊     | 959/2000 [01:01<01:04, 16.06it/s]\n",
      " 48%|████▊     | 961/2000 [01:01<01:04, 16.00it/s]\n",
      " 48%|████▊     | 963/2000 [01:01<01:04, 15.98it/s]\n",
      " 48%|████▊     | 965/2000 [01:01<01:04, 15.93it/s]\n",
      " 48%|████▊     | 967/2000 [01:01<01:04, 16.09it/s]\n",
      " 48%|████▊     | 969/2000 [01:01<01:03, 16.12it/s]\n",
      " 49%|████▊     | 971/2000 [01:01<01:04, 16.01it/s]\n",
      " 49%|████▊     | 973/2000 [01:02<01:04, 16.01it/s]\n",
      " 49%|████▉     | 975/2000 [01:02<01:03, 16.02it/s]\n",
      " 49%|████▉     | 977/2000 [01:02<01:03, 16.11it/s]\n",
      " 49%|████▉     | 979/2000 [01:02<01:03, 16.03it/s]\n",
      " 49%|████▉     | 981/2000 [01:02<01:03, 16.05it/s]\n",
      " 49%|████▉     | 983/2000 [01:02<01:03, 16.12it/s]\n",
      " 49%|████▉     | 985/2000 [01:02<01:03, 16.04it/s]\n",
      " 49%|████▉     | 987/2000 [01:02<01:03, 16.03it/s]\n",
      " 49%|████▉     | 989/2000 [01:03<01:03, 15.95it/s]\n",
      " 50%|████▉     | 991/2000 [01:03<01:03, 15.99it/s]\n",
      " 50%|████▉     | 993/2000 [01:03<01:02, 16.05it/s]\n",
      " 50%|████▉     | 995/2000 [01:03<01:02, 16.03it/s]\n",
      " 50%|████▉     | 997/2000 [01:03<01:02, 16.11it/s]\n",
      " 50%|████▉     | 999/2000 [01:03<01:02, 16.11it/s]\n",
      "                                                  \n",
      "\n",
      " 50%|█████     | 1000/2000 [01:03<01:02, 16.11it/s][INFO|trainer.py:761] 2024-01-26 01:08:25,828 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:08:25,829 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:08:25,829 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:08:25,829 >>   Batch size = 8\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  4%|▎         | 9/250 [00:00<00:02, 84.49it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 18/250 [00:00<00:02, 79.20it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 26/250 [00:00<00:02, 77.34it/s]\u001b[A\n",
      "\n",
      " 14%|█▎        | 34/250 [00:00<00:02, 75.63it/s]\u001b[A\n",
      "\n",
      " 17%|█▋        | 42/250 [00:00<00:02, 75.35it/s]\u001b[A\n",
      "\n",
      " 20%|██        | 50/250 [00:00<00:02, 74.70it/s]\u001b[A\n",
      "\n",
      " 23%|██▎       | 58/250 [00:00<00:02, 74.35it/s]\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:00<00:02, 74.46it/s]\u001b[A\n",
      "\n",
      " 30%|██▉       | 74/250 [00:00<00:02, 74.48it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 82/250 [00:01<00:02, 74.60it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 90/250 [00:01<00:02, 74.34it/s]\u001b[A\n",
      "\n",
      " 39%|███▉      | 98/250 [00:01<00:02, 74.14it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 106/250 [00:01<00:01, 74.19it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 114/250 [00:01<00:01, 73.95it/s]\u001b[A\n",
      "\n",
      " 49%|████▉     | 122/250 [00:01<00:01, 74.07it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 130/250 [00:01<00:01, 73.46it/s]\u001b[A\n",
      "\n",
      " 55%|█████▌    | 138/250 [00:01<00:01, 73.87it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 146/250 [00:01<00:01, 73.93it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 154/250 [00:02<00:01, 74.01it/s]\u001b[A\n",
      "\n",
      " 65%|██████▍   | 162/250 [00:02<00:01, 73.84it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 170/250 [00:02<00:01, 73.77it/s]\u001b[A\n",
      "\n",
      " 71%|███████   | 178/250 [00:02<00:00, 74.20it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 186/250 [00:02<00:00, 74.33it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:02<00:00, 74.38it/s]\u001b[A\n",
      "\n",
      " 81%|████████  | 202/250 [00:02<00:00, 74.37it/s]\u001b[A\n",
      "\n",
      " 84%|████████▍ | 210/250 [00:02<00:00, 74.52it/s]\u001b[A\n",
      "\n",
      " 87%|████████▋ | 218/250 [00:02<00:00, 74.23it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 226/250 [00:03<00:00, 74.11it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▎| 234/250 [00:03<00:00, 74.17it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 242/250 [00:03<00:00, 74.46it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 74.33it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      " 50%|█████     | 1000/2000 [01:07<01:02, 16.11it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 74.33it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:08:29,206 >> Saving model checkpoint to output/roberta_modified_emotion\\checkpoint-1000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:08:29,206 >> Configuration saved in output/roberta_modified_emotion\\checkpoint-1000\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:08:30,404 >> Model weights saved in output/roberta_modified_emotion\\checkpoint-1000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:08:30,405 >> tokenizer config file saved in output/roberta_modified_emotion\\checkpoint-1000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:08:30,406 >> Special tokens file saved in output/roberta_modified_emotion\\checkpoint-1000\\special_tokens_map.json\n",
      "\n",
      " 50%|█████     | 1001/2000 [01:12<23:36,  1.42s/it]\n",
      " 50%|█████     | 1003/2000 [01:12<16:48,  1.01s/it]\n",
      " 50%|█████     | 1005/2000 [01:13<12:03,  1.38it/s]\n",
      " 50%|█████     | 1007/2000 [01:13<08:43,  1.90it/s]\n",
      " 50%|█████     | 1009/2000 [01:13<06:24,  2.58it/s]\n",
      " 51%|█████     | 1011/2000 [01:13<04:47,  3.44it/s]\n",
      " 51%|█████     | 1013/2000 [01:13<03:39,  4.50it/s]\n",
      " 51%|█████     | 1015/2000 [01:13<02:51,  5.75it/s]\n",
      " 51%|█████     | 1017/2000 [01:13<02:18,  7.10it/s]\n",
      " 51%|█████     | 1019/2000 [01:13<01:55,  8.52it/s]\n",
      " 51%|█████     | 1021/2000 [01:14<01:39,  9.89it/s]\n",
      " 51%|█████     | 1023/2000 [01:14<01:27, 11.18it/s]\n",
      " 51%|█████▏    | 1025/2000 [01:14<01:19, 12.23it/s]\n",
      " 51%|█████▏    | 1027/2000 [01:14<01:14, 13.12it/s]\n",
      " 51%|█████▏    | 1029/2000 [01:14<01:10, 13.84it/s]\n",
      " 52%|█████▏    | 1031/2000 [01:14<01:07, 14.41it/s]\n",
      " 52%|█████▏    | 1033/2000 [01:14<01:04, 14.98it/s]\n",
      " 52%|█████▏    | 1035/2000 [01:14<01:03, 15.17it/s]\n",
      " 52%|█████▏    | 1037/2000 [01:15<01:02, 15.44it/s]\n",
      " 52%|█████▏    | 1039/2000 [01:15<01:01, 15.60it/s]\n",
      " 52%|█████▏    | 1041/2000 [01:15<01:00, 15.84it/s]\n",
      " 52%|█████▏    | 1043/2000 [01:15<01:00, 15.80it/s]\n",
      " 52%|█████▏    | 1045/2000 [01:15<01:00, 15.87it/s]\n",
      " 52%|█████▏    | 1047/2000 [01:15<01:00, 15.73it/s]\n",
      " 52%|█████▏    | 1049/2000 [01:15<01:01, 15.47it/s]\n",
      "                                                   \n",
      "\n",
      " 52%|█████▎    | 1050/2000 [01:15<01:01, 15.47it/s]\n",
      " 53%|█████▎    | 1051/2000 [01:16<01:00, 15.71it/s]\n",
      " 53%|█████▎    | 1053/2000 [01:16<00:59, 15.81it/s]\n",
      " 53%|█████▎    | 1055/2000 [01:16<00:59, 15.87it/s]\n",
      " 53%|█████▎    | 1057/2000 [01:16<00:59, 15.85it/s]\n",
      " 53%|█████▎    | 1059/2000 [01:16<00:59, 15.93it/s]\n",
      " 53%|█████▎    | 1061/2000 [01:16<00:59, 15.91it/s]\n",
      " 53%|█████▎    | 1063/2000 [01:16<00:58, 16.01it/s]\n",
      " 53%|█████▎    | 1065/2000 [01:16<00:58, 16.04it/s]\n",
      " 53%|█████▎    | 1067/2000 [01:17<00:58, 16.08it/s]\n",
      " 53%|█████▎    | 1069/2000 [01:17<00:58, 15.99it/s]\n",
      " 54%|█████▎    | 1071/2000 [01:17<00:57, 16.08it/s]\n",
      " 54%|█████▎    | 1073/2000 [01:17<00:57, 16.09it/s]\n",
      " 54%|█████▍    | 1075/2000 [01:17<00:57, 16.12it/s]\n",
      " 54%|█████▍    | 1077/2000 [01:17<00:57, 16.04it/s]\n",
      " 54%|█████▍    | 1079/2000 [01:17<00:59, 15.47it/s]\n",
      " 54%|█████▍    | 1081/2000 [01:17<00:58, 15.69it/s]\n",
      " 54%|█████▍    | 1083/2000 [01:18<00:58, 15.68it/s]\n",
      " 54%|█████▍    | 1085/2000 [01:18<00:58, 15.74it/s]\n",
      " 54%|█████▍    | 1087/2000 [01:18<00:57, 15.89it/s]\n",
      " 54%|█████▍    | 1089/2000 [01:18<00:56, 16.03it/s]\n",
      " 55%|█████▍    | 1091/2000 [01:18<00:56, 16.06it/s]\n",
      " 55%|█████▍    | 1093/2000 [01:18<00:56, 16.10it/s]\n",
      " 55%|█████▍    | 1095/2000 [01:18<00:56, 16.03it/s]\n",
      " 55%|█████▍    | 1097/2000 [01:18<00:56, 15.97it/s]\n",
      " 55%|█████▍    | 1099/2000 [01:19<00:56, 15.94it/s]\n",
      "                                                   \n",
      "\n",
      " 55%|█████▌    | 1100/2000 [01:19<00:56, 15.94it/s]\n",
      " 55%|█████▌    | 1101/2000 [01:19<00:56, 16.00it/s]\n",
      " 55%|█████▌    | 1103/2000 [01:19<00:55, 16.08it/s]\n",
      " 55%|█████▌    | 1105/2000 [01:19<00:56, 15.97it/s]\n",
      " 55%|█████▌    | 1107/2000 [01:19<00:55, 16.01it/s]\n",
      " 55%|█████▌    | 1109/2000 [01:19<00:55, 16.04it/s]\n",
      " 56%|█████▌    | 1111/2000 [01:19<00:55, 15.97it/s]\n",
      " 56%|█████▌    | 1113/2000 [01:19<00:55, 15.94it/s]\n",
      " 56%|█████▌    | 1115/2000 [01:20<00:55, 15.87it/s]\n",
      " 56%|█████▌    | 1117/2000 [01:20<00:55, 16.04it/s]\n",
      " 56%|█████▌    | 1119/2000 [01:20<00:54, 16.05it/s]\n",
      " 56%|█████▌    | 1121/2000 [01:20<00:54, 16.06it/s]\n",
      " 56%|█████▌    | 1123/2000 [01:20<00:54, 16.06it/s]\n",
      " 56%|█████▋    | 1125/2000 [01:20<00:54, 16.08it/s]\n",
      " 56%|█████▋    | 1127/2000 [01:20<00:54, 16.06it/s]\n",
      " 56%|█████▋    | 1129/2000 [01:20<00:54, 15.98it/s]\n",
      " 57%|█████▋    | 1131/2000 [01:21<00:54, 16.01it/s]\n",
      " 57%|█████▋    | 1133/2000 [01:21<00:53, 16.09it/s]\n",
      " 57%|█████▋    | 1135/2000 [01:21<00:53, 16.11it/s]\n",
      " 57%|█████▋    | 1137/2000 [01:21<00:53, 16.18it/s]\n",
      " 57%|█████▋    | 1139/2000 [01:21<00:53, 16.19it/s]\n",
      " 57%|█████▋    | 1141/2000 [01:21<00:53, 16.14it/s]\n",
      " 57%|█████▋    | 1143/2000 [01:21<00:53, 15.99it/s]\n",
      " 57%|█████▋    | 1145/2000 [01:21<00:53, 16.04it/s]\n",
      " 57%|█████▋    | 1147/2000 [01:21<00:52, 16.12it/s]\n",
      " 57%|█████▋    | 1149/2000 [01:22<00:52, 16.07it/s]\n",
      "                                                   \n",
      "\n",
      " 57%|█████▊    | 1150/2000 [01:22<00:52, 16.07it/s]\n",
      " 58%|█████▊    | 1151/2000 [01:22<00:52, 16.05it/s]\n",
      " 58%|█████▊    | 1153/2000 [01:22<00:52, 16.06it/s]\n",
      " 58%|█████▊    | 1155/2000 [01:22<00:52, 15.99it/s]\n",
      " 58%|█████▊    | 1157/2000 [01:22<00:52, 15.97it/s]\n",
      " 58%|█████▊    | 1159/2000 [01:22<00:52, 16.02it/s]\n",
      " 58%|█████▊    | 1161/2000 [01:22<00:52, 15.97it/s]\n",
      " 58%|█████▊    | 1163/2000 [01:22<00:51, 16.13it/s]\n",
      " 58%|█████▊    | 1165/2000 [01:23<00:51, 16.14it/s]\n",
      " 58%|█████▊    | 1167/2000 [01:23<00:52, 16.01it/s]\n",
      " 58%|█████▊    | 1169/2000 [01:23<00:52, 15.97it/s]\n",
      " 59%|█████▊    | 1171/2000 [01:23<00:51, 16.02it/s]\n",
      " 59%|█████▊    | 1173/2000 [01:23<00:51, 16.05it/s]\n",
      " 59%|█████▉    | 1175/2000 [01:23<00:51, 16.01it/s]\n",
      " 59%|█████▉    | 1177/2000 [01:23<00:51, 15.96it/s]\n",
      " 59%|█████▉    | 1179/2000 [01:24<00:51, 15.93it/s]\n",
      " 59%|█████▉    | 1181/2000 [01:24<00:51, 15.96it/s]\n",
      " 59%|█████▉    | 1183/2000 [01:24<00:51, 15.92it/s]\n",
      " 59%|█████▉    | 1185/2000 [01:24<00:50, 15.99it/s]\n",
      " 59%|█████▉    | 1187/2000 [01:24<00:50, 16.12it/s]\n",
      " 59%|█████▉    | 1189/2000 [01:24<00:51, 15.77it/s]\n",
      " 60%|█████▉    | 1191/2000 [01:24<00:52, 15.50it/s]\n",
      " 60%|█████▉    | 1193/2000 [01:24<00:52, 15.40it/s]\n",
      " 60%|█████▉    | 1195/2000 [01:25<00:51, 15.72it/s]\n",
      " 60%|█████▉    | 1197/2000 [01:25<00:50, 15.80it/s]\n",
      " 60%|█████▉    | 1199/2000 [01:25<00:50, 15.98it/s]\n",
      "                                                   \n",
      "\n",
      " 60%|██████    | 1200/2000 [01:25<00:50, 15.98it/s]\n",
      " 60%|██████    | 1201/2000 [01:25<00:50, 15.97it/s]\n",
      " 60%|██████    | 1203/2000 [01:25<00:49, 15.95it/s]\n",
      " 60%|██████    | 1205/2000 [01:25<00:49, 15.99it/s]\n",
      " 60%|██████    | 1207/2000 [01:25<00:49, 16.05it/s]\n",
      " 60%|██████    | 1209/2000 [01:25<00:49, 16.02it/s]\n",
      " 61%|██████    | 1211/2000 [01:26<00:49, 16.03it/s]\n",
      " 61%|██████    | 1213/2000 [01:26<00:49, 16.06it/s]\n",
      " 61%|██████    | 1215/2000 [01:26<00:49, 16.02it/s]\n",
      " 61%|██████    | 1217/2000 [01:26<00:48, 16.05it/s]\n",
      " 61%|██████    | 1219/2000 [01:26<00:48, 16.01it/s]\n",
      " 61%|██████    | 1221/2000 [01:26<00:48, 16.14it/s]\n",
      " 61%|██████    | 1223/2000 [01:26<00:48, 16.16it/s]\n",
      " 61%|██████▏   | 1225/2000 [01:26<00:48, 16.13it/s]\n",
      " 61%|██████▏   | 1227/2000 [01:27<00:48, 16.06it/s]\n",
      " 61%|██████▏   | 1229/2000 [01:27<00:48, 16.05it/s]\n",
      " 62%|██████▏   | 1231/2000 [01:27<00:47, 16.07it/s]\n",
      " 62%|██████▏   | 1233/2000 [01:27<00:47, 16.06it/s]\n",
      " 62%|██████▏   | 1235/2000 [01:27<00:48, 15.93it/s]\n",
      " 62%|██████▏   | 1237/2000 [01:27<00:47, 16.06it/s]\n",
      " 62%|██████▏   | 1239/2000 [01:27<00:47, 16.04it/s]\n",
      " 62%|██████▏   | 1241/2000 [01:27<00:47, 15.94it/s]\n",
      " 62%|██████▏   | 1243/2000 [01:28<00:47, 16.01it/s]\n",
      " 62%|██████▏   | 1245/2000 [01:28<00:47, 15.96it/s]\n",
      " 62%|██████▏   | 1247/2000 [01:28<00:47, 15.94it/s]\n",
      " 62%|██████▏   | 1249/2000 [01:28<00:46, 16.10it/s]\n",
      "                                                   \n",
      "\n",
      " 62%|██████▎   | 1250/2000 [01:28<00:46, 16.10it/s]\n",
      " 63%|██████▎   | 1251/2000 [01:28<00:46, 16.12it/s]\n",
      " 63%|██████▎   | 1253/2000 [01:28<00:46, 16.09it/s]\n",
      " 63%|██████▎   | 1255/2000 [01:28<00:46, 16.11it/s]\n",
      " 63%|██████▎   | 1257/2000 [01:28<00:46, 16.03it/s]\n",
      " 63%|██████▎   | 1259/2000 [01:29<00:46, 15.99it/s]\n",
      " 63%|██████▎   | 1261/2000 [01:29<00:46, 16.05it/s]\n",
      " 63%|██████▎   | 1263/2000 [01:29<00:45, 16.08it/s]\n",
      " 63%|██████▎   | 1265/2000 [01:29<00:45, 16.01it/s]\n",
      " 63%|██████▎   | 1267/2000 [01:29<00:47, 15.48it/s]\n",
      " 63%|██████▎   | 1269/2000 [01:29<00:46, 15.67it/s]\n",
      " 64%|██████▎   | 1271/2000 [01:29<00:46, 15.74it/s]\n",
      " 64%|██████▎   | 1273/2000 [01:29<00:46, 15.76it/s]\n",
      " 64%|██████▍   | 1275/2000 [01:30<00:45, 15.84it/s]\n",
      " 64%|██████▍   | 1277/2000 [01:30<00:45, 15.92it/s]\n",
      " 64%|██████▍   | 1279/2000 [01:30<00:45, 16.02it/s]\n",
      " 64%|██████▍   | 1281/2000 [01:30<00:44, 16.17it/s]\n",
      " 64%|██████▍   | 1283/2000 [01:30<00:44, 15.96it/s]\n",
      " 64%|██████▍   | 1285/2000 [01:30<00:44, 15.89it/s]\n",
      " 64%|██████▍   | 1287/2000 [01:30<00:44, 16.04it/s]\n",
      " 64%|██████▍   | 1289/2000 [01:30<00:44, 16.05it/s]\n",
      " 65%|██████▍   | 1291/2000 [01:31<00:44, 15.89it/s]\n",
      " 65%|██████▍   | 1293/2000 [01:31<00:44, 15.88it/s]\n",
      " 65%|██████▍   | 1295/2000 [01:31<00:44, 15.99it/s]\n",
      " 65%|██████▍   | 1297/2000 [01:31<00:43, 16.04it/s]\n",
      " 65%|██████▍   | 1299/2000 [01:31<00:43, 16.01it/s]\n",
      "                                                   \n",
      "\n",
      " 65%|██████▌   | 1300/2000 [01:31<00:43, 16.01it/s]\n",
      " 65%|██████▌   | 1301/2000 [01:31<00:43, 16.06it/s]\n",
      " 65%|██████▌   | 1303/2000 [01:31<00:43, 16.12it/s]\n",
      " 65%|██████▌   | 1305/2000 [01:31<00:43, 16.09it/s]\n",
      " 65%|██████▌   | 1307/2000 [01:32<00:43, 16.02it/s]\n",
      " 65%|██████▌   | 1309/2000 [01:32<00:43, 16.01it/s]\n",
      " 66%|██████▌   | 1311/2000 [01:32<00:42, 16.08it/s]\n",
      " 66%|██████▌   | 1313/2000 [01:32<00:42, 16.01it/s]\n",
      " 66%|██████▌   | 1315/2000 [01:32<00:42, 16.04it/s]\n",
      " 66%|██████▌   | 1317/2000 [01:32<00:42, 16.12it/s]\n",
      " 66%|██████▌   | 1319/2000 [01:32<00:42, 16.04it/s]\n",
      " 66%|██████▌   | 1321/2000 [01:32<00:42, 16.05it/s]\n",
      " 66%|██████▌   | 1323/2000 [01:33<00:42, 16.07it/s]\n",
      " 66%|██████▋   | 1325/2000 [01:33<00:42, 15.96it/s]\n",
      " 66%|██████▋   | 1327/2000 [01:33<00:41, 16.05it/s]\n",
      " 66%|██████▋   | 1329/2000 [01:33<00:42, 15.96it/s]\n",
      " 67%|██████▋   | 1331/2000 [01:33<00:41, 15.99it/s]\n",
      " 67%|██████▋   | 1333/2000 [01:33<00:41, 16.08it/s]\n",
      " 67%|██████▋   | 1335/2000 [01:33<00:41, 16.10it/s]\n",
      " 67%|██████▋   | 1337/2000 [01:33<00:41, 16.06it/s]\n",
      " 67%|██████▋   | 1339/2000 [01:34<00:41, 16.02it/s]\n",
      " 67%|██████▋   | 1341/2000 [01:34<00:41, 16.05it/s]\n",
      " 67%|██████▋   | 1343/2000 [01:34<00:41, 16.00it/s]\n",
      " 67%|██████▋   | 1345/2000 [01:34<00:40, 16.04it/s]\n",
      " 67%|██████▋   | 1347/2000 [01:34<00:42, 15.39it/s]\n",
      " 67%|██████▋   | 1349/2000 [01:34<00:41, 15.61it/s]\n",
      "                                                   \n",
      "\n",
      " 68%|██████▊   | 1350/2000 [01:34<00:41, 15.61it/s]\n",
      " 68%|██████▊   | 1351/2000 [01:34<00:41, 15.72it/s]\n",
      " 68%|██████▊   | 1353/2000 [01:34<00:40, 15.86it/s]\n",
      " 68%|██████▊   | 1355/2000 [01:35<00:40, 15.90it/s]\n",
      " 68%|██████▊   | 1357/2000 [01:35<00:40, 15.95it/s]\n",
      " 68%|██████▊   | 1359/2000 [01:35<00:40, 15.85it/s]\n",
      " 68%|██████▊   | 1361/2000 [01:35<00:39, 16.01it/s]\n",
      " 68%|██████▊   | 1363/2000 [01:35<00:40, 15.56it/s]\n",
      " 68%|██████▊   | 1365/2000 [01:35<00:40, 15.55it/s]\n",
      " 68%|██████▊   | 1367/2000 [01:35<00:40, 15.63it/s]\n",
      " 68%|██████▊   | 1369/2000 [01:35<00:40, 15.69it/s]\n",
      " 69%|██████▊   | 1371/2000 [01:36<00:39, 15.73it/s]\n",
      " 69%|██████▊   | 1373/2000 [01:36<00:39, 15.89it/s]\n",
      " 69%|██████▉   | 1375/2000 [01:36<00:39, 15.92it/s]\n",
      " 69%|██████▉   | 1377/2000 [01:36<00:39, 15.95it/s]\n",
      " 69%|██████▉   | 1379/2000 [01:36<00:38, 15.99it/s]\n",
      " 69%|██████▉   | 1381/2000 [01:36<00:38, 16.01it/s]\n",
      " 69%|██████▉   | 1383/2000 [01:36<00:38, 15.95it/s]\n",
      " 69%|██████▉   | 1385/2000 [01:36<00:38, 15.97it/s]\n",
      " 69%|██████▉   | 1387/2000 [01:37<00:38, 16.12it/s]\n",
      " 69%|██████▉   | 1389/2000 [01:37<00:37, 16.13it/s]\n",
      " 70%|██████▉   | 1391/2000 [01:37<00:37, 16.09it/s]\n",
      " 70%|██████▉   | 1393/2000 [01:37<00:37, 16.00it/s]\n",
      " 70%|██████▉   | 1395/2000 [01:37<00:37, 15.99it/s]\n",
      " 70%|██████▉   | 1397/2000 [01:37<00:37, 16.02it/s]\n",
      " 70%|██████▉   | 1399/2000 [01:37<00:37, 16.07it/s]\n",
      "                                                   \n",
      "\n",
      " 70%|███████   | 1400/2000 [01:37<00:37, 16.07it/s]\n",
      " 70%|███████   | 1401/2000 [01:37<00:37, 16.09it/s]\n",
      " 70%|███████   | 1403/2000 [01:38<00:37, 16.10it/s]\n",
      " 70%|███████   | 1405/2000 [01:38<00:37, 15.98it/s]\n",
      " 70%|███████   | 1407/2000 [01:38<00:37, 16.01it/s]\n",
      " 70%|███████   | 1409/2000 [01:38<00:36, 16.00it/s]\n",
      " 71%|███████   | 1411/2000 [01:38<00:36, 15.96it/s]\n",
      " 71%|███████   | 1413/2000 [01:38<00:36, 15.94it/s]\n",
      " 71%|███████   | 1415/2000 [01:38<00:36, 16.00it/s]\n",
      " 71%|███████   | 1417/2000 [01:38<00:36, 15.94it/s]\n",
      " 71%|███████   | 1419/2000 [01:39<00:36, 15.82it/s]\n",
      " 71%|███████   | 1421/2000 [01:39<00:36, 16.02it/s]\n",
      " 71%|███████   | 1423/2000 [01:39<00:35, 16.05it/s]\n",
      " 71%|███████▏  | 1425/2000 [01:39<00:36, 15.95it/s]\n",
      " 71%|███████▏  | 1427/2000 [01:39<00:36, 15.92it/s]\n",
      " 71%|███████▏  | 1429/2000 [01:39<00:35, 16.00it/s]\n",
      " 72%|███████▏  | 1431/2000 [01:39<00:35, 15.97it/s]\n",
      " 72%|███████▏  | 1433/2000 [01:39<00:35, 15.91it/s]\n",
      " 72%|███████▏  | 1435/2000 [01:40<00:35, 15.93it/s]\n",
      " 72%|███████▏  | 1437/2000 [01:40<00:35, 15.99it/s]\n",
      " 72%|███████▏  | 1439/2000 [01:40<00:34, 16.04it/s]\n",
      " 72%|███████▏  | 1441/2000 [01:40<00:34, 16.06it/s]\n",
      " 72%|███████▏  | 1443/2000 [01:40<00:34, 16.12it/s]\n",
      " 72%|███████▏  | 1445/2000 [01:40<00:34, 16.07it/s]\n",
      " 72%|███████▏  | 1447/2000 [01:40<00:34, 16.06it/s]\n",
      " 72%|███████▏  | 1449/2000 [01:40<00:34, 15.96it/s]\n",
      "                                                   \n",
      "\n",
      " 72%|███████▎  | 1450/2000 [01:40<00:34, 15.96it/s]\n",
      " 73%|███████▎  | 1451/2000 [01:41<00:34, 15.97it/s]\n",
      " 73%|███████▎  | 1453/2000 [01:41<00:34, 16.06it/s]\n",
      " 73%|███████▎  | 1455/2000 [01:41<00:33, 16.04it/s]\n",
      " 73%|███████▎  | 1457/2000 [01:41<00:33, 16.03it/s]\n",
      " 73%|███████▎  | 1459/2000 [01:41<00:33, 16.10it/s]\n",
      " 73%|███████▎  | 1461/2000 [01:41<00:33, 16.12it/s]\n",
      " 73%|███████▎  | 1463/2000 [01:41<00:33, 16.05it/s]\n",
      " 73%|███████▎  | 1465/2000 [01:41<00:33, 16.01it/s]\n",
      " 73%|███████▎  | 1467/2000 [01:42<00:33, 16.11it/s]\n",
      " 73%|███████▎  | 1469/2000 [01:42<00:32, 16.09it/s]\n",
      " 74%|███████▎  | 1471/2000 [01:42<00:32, 16.14it/s]\n",
      " 74%|███████▎  | 1473/2000 [01:42<00:32, 16.13it/s]\n",
      " 74%|███████▍  | 1475/2000 [01:42<00:32, 16.18it/s]\n",
      " 74%|███████▍  | 1477/2000 [01:42<00:32, 16.21it/s]\n",
      " 74%|███████▍  | 1479/2000 [01:42<00:32, 16.14it/s]\n",
      " 74%|███████▍  | 1481/2000 [01:42<00:32, 16.14it/s]\n",
      " 74%|███████▍  | 1483/2000 [01:43<00:32, 16.02it/s]\n",
      " 74%|███████▍  | 1485/2000 [01:43<00:32, 15.88it/s]\n",
      " 74%|███████▍  | 1487/2000 [01:43<00:31, 16.05it/s]\n",
      " 74%|███████▍  | 1489/2000 [01:43<00:31, 16.12it/s]\n",
      " 75%|███████▍  | 1491/2000 [01:43<00:31, 16.07it/s]\n",
      " 75%|███████▍  | 1493/2000 [01:43<00:31, 16.06it/s]\n",
      " 75%|███████▍  | 1495/2000 [01:43<00:31, 16.15it/s]\n",
      " 75%|███████▍  | 1497/2000 [01:43<00:31, 16.10it/s]\n",
      " 75%|███████▍  | 1499/2000 [01:44<00:31, 16.07it/s]\n",
      "                                                   \n",
      "\n",
      " 75%|███████▌  | 1500/2000 [01:44<00:31, 16.07it/s]\n",
      " 75%|███████▌  | 1501/2000 [01:44<00:31, 16.01it/s]\n",
      " 75%|███████▌  | 1503/2000 [01:44<00:30, 16.07it/s]\n",
      " 75%|███████▌  | 1505/2000 [01:44<00:30, 16.08it/s]\n",
      " 75%|███████▌  | 1507/2000 [01:44<00:30, 16.00it/s]\n",
      " 75%|███████▌  | 1509/2000 [01:44<00:30, 15.97it/s]\n",
      " 76%|███████▌  | 1511/2000 [01:44<00:30, 16.06it/s]\n",
      " 76%|███████▌  | 1513/2000 [01:44<00:30, 16.15it/s]\n",
      " 76%|███████▌  | 1515/2000 [01:45<00:30, 16.03it/s]\n",
      " 76%|███████▌  | 1517/2000 [01:45<00:30, 16.02it/s]\n",
      " 76%|███████▌  | 1519/2000 [01:45<00:29, 16.06it/s]\n",
      " 76%|███████▌  | 1521/2000 [01:45<00:30, 15.80it/s]\n",
      " 76%|███████▌  | 1523/2000 [01:45<00:29, 15.92it/s]\n",
      " 76%|███████▋  | 1525/2000 [01:45<00:29, 15.98it/s]\n",
      " 76%|███████▋  | 1527/2000 [01:45<00:29, 16.04it/s]\n",
      " 76%|███████▋  | 1529/2000 [01:45<00:30, 15.62it/s]\n",
      " 77%|███████▋  | 1531/2000 [01:46<00:30, 15.55it/s]\n",
      " 77%|███████▋  | 1533/2000 [01:46<00:29, 15.81it/s]\n",
      " 77%|███████▋  | 1535/2000 [01:46<00:29, 15.78it/s]\n",
      " 77%|███████▋  | 1537/2000 [01:46<00:29, 15.85it/s]\n",
      " 77%|███████▋  | 1539/2000 [01:46<00:28, 15.95it/s]\n",
      " 77%|███████▋  | 1541/2000 [01:46<00:28, 15.95it/s]\n",
      " 77%|███████▋  | 1543/2000 [01:46<00:28, 16.02it/s]\n",
      " 77%|███████▋  | 1545/2000 [01:46<00:29, 15.49it/s]\n",
      " 77%|███████▋  | 1547/2000 [01:47<00:29, 15.13it/s]\n",
      " 77%|███████▋  | 1549/2000 [01:47<00:29, 15.33it/s]\n",
      "                                                   \n",
      "\n",
      " 78%|███████▊  | 1550/2000 [01:47<00:29, 15.33it/s]\n",
      " 78%|███████▊  | 1551/2000 [01:47<00:28, 15.53it/s]\n",
      " 78%|███████▊  | 1553/2000 [01:47<00:28, 15.58it/s]\n",
      " 78%|███████▊  | 1555/2000 [01:47<00:28, 15.80it/s]\n",
      " 78%|███████▊  | 1557/2000 [01:47<00:27, 15.89it/s]\n",
      " 78%|███████▊  | 1559/2000 [01:47<00:27, 15.92it/s]\n",
      " 78%|███████▊  | 1561/2000 [01:47<00:27, 15.91it/s]\n",
      " 78%|███████▊  | 1563/2000 [01:48<00:27, 15.90it/s]\n",
      " 78%|███████▊  | 1565/2000 [01:48<00:27, 16.00it/s]\n",
      " 78%|███████▊  | 1567/2000 [01:48<00:27, 15.96it/s]\n",
      " 78%|███████▊  | 1569/2000 [01:48<00:26, 16.00it/s]\n",
      " 79%|███████▊  | 1571/2000 [01:48<00:26, 16.10it/s]\n",
      " 79%|███████▊  | 1573/2000 [01:48<00:26, 15.99it/s]\n",
      " 79%|███████▉  | 1575/2000 [01:48<00:26, 15.98it/s]\n",
      " 79%|███████▉  | 1577/2000 [01:48<00:26, 15.92it/s]\n",
      " 79%|███████▉  | 1579/2000 [01:49<00:26, 15.90it/s]\n",
      " 79%|███████▉  | 1581/2000 [01:49<00:26, 15.97it/s]\n",
      " 79%|███████▉  | 1583/2000 [01:49<00:26, 15.93it/s]\n",
      " 79%|███████▉  | 1585/2000 [01:49<00:26, 15.49it/s]\n",
      " 79%|███████▉  | 1587/2000 [01:49<00:26, 15.66it/s]\n",
      " 79%|███████▉  | 1589/2000 [01:49<00:26, 15.72it/s]\n",
      " 80%|███████▉  | 1591/2000 [01:49<00:25, 15.85it/s]\n",
      " 80%|███████▉  | 1593/2000 [01:49<00:25, 15.92it/s]\n",
      " 80%|███████▉  | 1595/2000 [01:50<00:25, 15.91it/s]\n",
      " 80%|███████▉  | 1597/2000 [01:50<00:25, 15.93it/s]\n",
      " 80%|███████▉  | 1599/2000 [01:50<00:26, 15.35it/s]\n",
      "                                                   \n",
      "\n",
      " 80%|████████  | 1600/2000 [01:50<00:26, 15.35it/s]\n",
      " 80%|████████  | 1601/2000 [01:50<00:25, 15.55it/s]\n",
      " 80%|████████  | 1603/2000 [01:50<00:25, 15.62it/s]\n",
      " 80%|████████  | 1605/2000 [01:50<00:25, 15.73it/s]\n",
      " 80%|████████  | 1607/2000 [01:50<00:24, 15.85it/s]\n",
      " 80%|████████  | 1609/2000 [01:50<00:24, 15.92it/s]\n",
      " 81%|████████  | 1611/2000 [01:51<00:24, 15.85it/s]\n",
      " 81%|████████  | 1613/2000 [01:51<00:24, 15.99it/s]\n",
      " 81%|████████  | 1615/2000 [01:51<00:24, 15.86it/s]\n",
      " 81%|████████  | 1617/2000 [01:51<00:24, 15.82it/s]\n",
      " 81%|████████  | 1619/2000 [01:51<00:24, 15.78it/s]\n",
      " 81%|████████  | 1621/2000 [01:51<00:24, 15.68it/s]\n",
      " 81%|████████  | 1623/2000 [01:51<00:23, 15.77it/s]\n",
      " 81%|████████▏ | 1625/2000 [01:51<00:23, 15.80it/s]\n",
      " 81%|████████▏ | 1627/2000 [01:52<00:23, 15.76it/s]\n",
      " 81%|████████▏ | 1629/2000 [01:52<00:23, 15.89it/s]\n",
      " 82%|████████▏ | 1631/2000 [01:52<00:23, 15.97it/s]\n",
      " 82%|████████▏ | 1633/2000 [01:52<00:22, 15.98it/s]\n",
      " 82%|████████▏ | 1635/2000 [01:52<00:22, 16.10it/s]\n",
      " 82%|████████▏ | 1637/2000 [01:52<00:22, 16.07it/s]\n",
      " 82%|████████▏ | 1639/2000 [01:52<00:22, 16.12it/s]\n",
      " 82%|████████▏ | 1641/2000 [01:52<00:22, 16.05it/s]\n",
      " 82%|████████▏ | 1643/2000 [01:53<00:22, 16.11it/s]\n",
      " 82%|████████▏ | 1645/2000 [01:53<00:22, 16.09it/s]\n",
      " 82%|████████▏ | 1647/2000 [01:53<00:22, 16.04it/s]\n",
      " 82%|████████▏ | 1649/2000 [01:53<00:22, 15.88it/s]\n",
      "                                                   \n",
      "\n",
      " 82%|████████▎ | 1650/2000 [01:53<00:22, 15.88it/s]\n",
      " 83%|████████▎ | 1651/2000 [01:53<00:22, 15.49it/s]\n",
      " 83%|████████▎ | 1653/2000 [01:53<00:22, 15.60it/s]\n",
      " 83%|████████▎ | 1655/2000 [01:53<00:21, 15.72it/s]\n",
      " 83%|████████▎ | 1657/2000 [01:53<00:21, 15.84it/s]\n",
      " 83%|████████▎ | 1659/2000 [01:54<00:21, 15.93it/s]\n",
      " 83%|████████▎ | 1661/2000 [01:54<00:21, 15.94it/s]\n",
      " 83%|████████▎ | 1663/2000 [01:54<00:21, 15.96it/s]\n",
      " 83%|████████▎ | 1665/2000 [01:54<00:20, 16.05it/s]\n",
      " 83%|████████▎ | 1667/2000 [01:54<00:20, 15.96it/s]\n",
      " 83%|████████▎ | 1669/2000 [01:54<00:20, 15.94it/s]\n",
      " 84%|████████▎ | 1671/2000 [01:54<00:20, 16.05it/s]\n",
      " 84%|████████▎ | 1673/2000 [01:54<00:20, 15.96it/s]\n",
      " 84%|████████▍ | 1675/2000 [01:55<00:20, 16.01it/s]\n",
      " 84%|████████▍ | 1677/2000 [01:55<00:20, 15.56it/s]\n",
      " 84%|████████▍ | 1679/2000 [01:55<00:20, 15.63it/s]\n",
      " 84%|████████▍ | 1681/2000 [01:55<00:20, 15.76it/s]\n",
      " 84%|████████▍ | 1683/2000 [01:55<00:20, 15.81it/s]\n",
      " 84%|████████▍ | 1685/2000 [01:55<00:19, 15.90it/s]\n",
      " 84%|████████▍ | 1687/2000 [01:55<00:19, 15.91it/s]\n",
      " 84%|████████▍ | 1689/2000 [01:55<00:19, 16.04it/s]\n",
      " 85%|████████▍ | 1691/2000 [01:56<00:19, 16.07it/s]\n",
      " 85%|████████▍ | 1693/2000 [01:56<00:19, 16.04it/s]\n",
      " 85%|████████▍ | 1695/2000 [01:56<00:18, 16.15it/s]\n",
      " 85%|████████▍ | 1697/2000 [01:56<00:18, 16.10it/s]\n",
      " 85%|████████▍ | 1699/2000 [01:56<00:18, 16.07it/s]\n",
      "                                                   \n",
      "\n",
      " 85%|████████▌ | 1700/2000 [01:56<00:18, 16.07it/s]\n",
      " 85%|████████▌ | 1701/2000 [01:56<00:18, 16.05it/s]\n",
      " 85%|████████▌ | 1703/2000 [01:56<00:18, 16.06it/s]\n",
      " 85%|████████▌ | 1705/2000 [01:56<00:18, 16.08it/s]\n",
      " 85%|████████▌ | 1707/2000 [01:57<00:18, 15.88it/s]\n",
      " 85%|████████▌ | 1709/2000 [01:57<00:18, 15.96it/s]\n",
      " 86%|████████▌ | 1711/2000 [01:57<00:18, 16.00it/s]\n",
      " 86%|████████▌ | 1713/2000 [01:57<00:17, 16.08it/s]\n",
      " 86%|████████▌ | 1715/2000 [01:57<00:18, 15.82it/s]\n",
      " 86%|████████▌ | 1717/2000 [01:57<00:18, 15.52it/s]\n",
      " 86%|████████▌ | 1719/2000 [01:57<00:17, 15.64it/s]\n",
      " 86%|████████▌ | 1721/2000 [01:58<00:17, 15.69it/s]\n",
      " 86%|████████▌ | 1723/2000 [01:58<00:17, 15.89it/s]\n",
      " 86%|████████▋ | 1725/2000 [01:58<00:17, 15.84it/s]\n",
      " 86%|████████▋ | 1727/2000 [01:58<00:17, 15.97it/s]\n",
      " 86%|████████▋ | 1729/2000 [01:58<00:16, 16.01it/s]\n",
      " 87%|████████▋ | 1731/2000 [01:58<00:16, 16.09it/s]\n",
      " 87%|████████▋ | 1733/2000 [01:58<00:16, 16.16it/s]\n",
      " 87%|████████▋ | 1735/2000 [01:58<00:16, 16.06it/s]\n",
      " 87%|████████▋ | 1737/2000 [01:59<00:16, 16.12it/s]\n",
      " 87%|████████▋ | 1739/2000 [01:59<00:16, 16.05it/s]\n",
      " 87%|████████▋ | 1741/2000 [01:59<00:16, 16.08it/s]\n",
      " 87%|████████▋ | 1743/2000 [01:59<00:16, 16.05it/s]\n",
      " 87%|████████▋ | 1745/2000 [01:59<00:15, 15.95it/s]\n",
      " 87%|████████▋ | 1747/2000 [01:59<00:16, 15.70it/s]\n",
      " 87%|████████▋ | 1749/2000 [01:59<00:16, 15.53it/s]\n",
      "                                                   \n",
      "\n",
      " 88%|████████▊ | 1750/2000 [01:59<00:16, 15.53it/s]\n",
      " 88%|████████▊ | 1751/2000 [01:59<00:15, 15.71it/s]\n",
      " 88%|████████▊ | 1753/2000 [02:00<00:15, 15.80it/s]\n",
      " 88%|████████▊ | 1755/2000 [02:00<00:15, 15.88it/s]\n",
      " 88%|████████▊ | 1757/2000 [02:00<00:15, 15.94it/s]\n",
      " 88%|████████▊ | 1759/2000 [02:00<00:15, 15.95it/s]\n",
      " 88%|████████▊ | 1761/2000 [02:00<00:14, 15.97it/s]\n",
      " 88%|████████▊ | 1763/2000 [02:00<00:14, 16.05it/s]\n",
      " 88%|████████▊ | 1765/2000 [02:00<00:14, 16.07it/s]\n",
      " 88%|████████▊ | 1767/2000 [02:00<00:14, 15.90it/s]\n",
      " 88%|████████▊ | 1769/2000 [02:01<00:14, 15.96it/s]\n",
      " 89%|████████▊ | 1771/2000 [02:01<00:14, 15.93it/s]\n",
      " 89%|████████▊ | 1773/2000 [02:01<00:14, 16.05it/s]\n",
      " 89%|████████▉ | 1775/2000 [02:01<00:13, 16.16it/s]\n",
      " 89%|████████▉ | 1777/2000 [02:01<00:13, 16.06it/s]\n",
      " 89%|████████▉ | 1779/2000 [02:01<00:13, 16.05it/s]\n",
      " 89%|████████▉ | 1781/2000 [02:01<00:13, 16.05it/s]\n",
      " 89%|████████▉ | 1783/2000 [02:01<00:13, 16.09it/s]\n",
      " 89%|████████▉ | 1785/2000 [02:02<00:13, 15.87it/s]\n",
      " 89%|████████▉ | 1787/2000 [02:02<00:14, 15.21it/s]\n",
      " 89%|████████▉ | 1789/2000 [02:02<00:13, 15.30it/s]\n",
      " 90%|████████▉ | 1791/2000 [02:02<00:13, 15.49it/s]\n",
      " 90%|████████▉ | 1793/2000 [02:02<00:13, 15.60it/s]\n",
      " 90%|████████▉ | 1795/2000 [02:02<00:12, 15.81it/s]\n",
      " 90%|████████▉ | 1797/2000 [02:02<00:12, 15.91it/s]\n",
      " 90%|████████▉ | 1799/2000 [02:02<00:12, 15.92it/s]\n",
      "                                                   \n",
      "\n",
      " 90%|█████████ | 1800/2000 [02:02<00:12, 15.92it/s]\n",
      " 90%|█████████ | 1801/2000 [02:03<00:12, 15.96it/s]\n",
      " 90%|█████████ | 1803/2000 [02:03<00:12, 16.02it/s]\n",
      " 90%|█████████ | 1805/2000 [02:03<00:12, 16.05it/s]\n",
      " 90%|█████████ | 1807/2000 [02:03<00:12, 16.08it/s]\n",
      " 90%|█████████ | 1809/2000 [02:03<00:11, 16.14it/s]\n",
      " 91%|█████████ | 1811/2000 [02:03<00:11, 16.18it/s]\n",
      " 91%|█████████ | 1813/2000 [02:03<00:11, 16.01it/s]\n",
      " 91%|█████████ | 1815/2000 [02:03<00:11, 16.07it/s]\n",
      " 91%|█████████ | 1817/2000 [02:04<00:11, 15.97it/s]\n",
      " 91%|█████████ | 1819/2000 [02:04<00:11, 16.02it/s]\n",
      " 91%|█████████ | 1821/2000 [02:04<00:11, 16.06it/s]\n",
      " 91%|█████████ | 1823/2000 [02:04<00:11, 16.05it/s]\n",
      " 91%|█████████▏| 1825/2000 [02:04<00:10, 16.09it/s]\n",
      " 91%|█████████▏| 1827/2000 [02:04<00:10, 16.15it/s]\n",
      " 91%|█████████▏| 1829/2000 [02:04<00:10, 16.06it/s]\n",
      " 92%|█████████▏| 1831/2000 [02:04<00:10, 16.04it/s]\n",
      " 92%|█████████▏| 1833/2000 [02:05<00:10, 16.02it/s]\n",
      " 92%|█████████▏| 1835/2000 [02:05<00:10, 16.02it/s]\n",
      " 92%|█████████▏| 1837/2000 [02:05<00:10, 16.01it/s]\n",
      " 92%|█████████▏| 1839/2000 [02:05<00:10, 16.06it/s]\n",
      " 92%|█████████▏| 1841/2000 [02:05<00:09, 16.10it/s]\n",
      " 92%|█████████▏| 1843/2000 [02:05<00:09, 16.01it/s]\n",
      " 92%|█████████▏| 1845/2000 [02:05<00:09, 16.01it/s]\n",
      " 92%|█████████▏| 1847/2000 [02:05<00:09, 16.05it/s]\n",
      " 92%|█████████▏| 1849/2000 [02:06<00:09, 15.99it/s]\n",
      "                                                   \n",
      "\n",
      " 92%|█████████▎| 1850/2000 [02:06<00:09, 15.99it/s]\n",
      " 93%|█████████▎| 1851/2000 [02:06<00:09, 15.91it/s]\n",
      " 93%|█████████▎| 1853/2000 [02:06<00:09, 15.71it/s]\n",
      " 93%|█████████▎| 1855/2000 [02:06<00:09, 15.47it/s]\n",
      " 93%|█████████▎| 1857/2000 [02:06<00:09, 15.55it/s]\n",
      " 93%|█████████▎| 1859/2000 [02:06<00:08, 15.75it/s]\n",
      " 93%|█████████▎| 1861/2000 [02:06<00:08, 15.90it/s]\n",
      " 93%|█████████▎| 1863/2000 [02:06<00:08, 15.94it/s]\n",
      " 93%|█████████▎| 1865/2000 [02:07<00:08, 15.93it/s]\n",
      " 93%|█████████▎| 1867/2000 [02:07<00:08, 15.97it/s]\n",
      " 93%|█████████▎| 1869/2000 [02:07<00:08, 16.03it/s]\n",
      " 94%|█████████▎| 1871/2000 [02:07<00:08, 16.00it/s]\n",
      " 94%|█████████▎| 1873/2000 [02:07<00:07, 16.01it/s]\n",
      " 94%|█████████▍| 1875/2000 [02:07<00:07, 15.95it/s]\n",
      " 94%|█████████▍| 1877/2000 [02:07<00:07, 16.02it/s]\n",
      " 94%|█████████▍| 1879/2000 [02:07<00:07, 16.06it/s]\n",
      " 94%|█████████▍| 1881/2000 [02:08<00:07, 16.08it/s]\n",
      " 94%|█████████▍| 1883/2000 [02:08<00:07, 15.89it/s]\n",
      " 94%|█████████▍| 1885/2000 [02:08<00:07, 15.98it/s]\n",
      " 94%|█████████▍| 1887/2000 [02:08<00:07, 16.02it/s]\n",
      " 94%|█████████▍| 1889/2000 [02:08<00:06, 16.01it/s]\n",
      " 95%|█████████▍| 1891/2000 [02:08<00:06, 16.01it/s]\n",
      " 95%|█████████▍| 1893/2000 [02:08<00:06, 15.95it/s]\n",
      " 95%|█████████▍| 1895/2000 [02:08<00:06, 15.76it/s]\n",
      " 95%|█████████▍| 1897/2000 [02:09<00:06, 15.96it/s]\n",
      " 95%|█████████▍| 1899/2000 [02:09<00:06, 16.06it/s]\n",
      "                                                   \n",
      "\n",
      " 95%|█████████▌| 1900/2000 [02:09<00:06, 16.06it/s]\n",
      " 95%|█████████▌| 1901/2000 [02:09<00:06, 16.11it/s]\n",
      " 95%|█████████▌| 1903/2000 [02:09<00:06, 16.09it/s]\n",
      " 95%|█████████▌| 1905/2000 [02:09<00:05, 16.19it/s]\n",
      " 95%|█████████▌| 1907/2000 [02:09<00:05, 16.19it/s]\n",
      " 95%|█████████▌| 1909/2000 [02:09<00:05, 16.19it/s]\n",
      " 96%|█████████▌| 1911/2000 [02:09<00:05, 16.12it/s]\n",
      " 96%|█████████▌| 1913/2000 [02:10<00:05, 16.08it/s]\n",
      " 96%|█████████▌| 1915/2000 [02:10<00:05, 16.12it/s]\n",
      " 96%|█████████▌| 1917/2000 [02:10<00:05, 16.03it/s]\n",
      " 96%|█████████▌| 1919/2000 [02:10<00:05, 16.02it/s]\n",
      " 96%|█████████▌| 1921/2000 [02:10<00:04, 16.05it/s]\n",
      " 96%|█████████▌| 1923/2000 [02:10<00:04, 15.95it/s]\n",
      " 96%|█████████▋| 1925/2000 [02:10<00:04, 16.01it/s]\n",
      " 96%|█████████▋| 1927/2000 [02:10<00:04, 15.96it/s]\n",
      " 96%|█████████▋| 1929/2000 [02:11<00:04, 15.50it/s]\n",
      " 97%|█████████▋| 1931/2000 [02:11<00:04, 15.65it/s]\n",
      " 97%|█████████▋| 1933/2000 [02:11<00:04, 15.84it/s]\n",
      " 97%|█████████▋| 1935/2000 [02:11<00:04, 15.96it/s]\n",
      " 97%|█████████▋| 1937/2000 [02:11<00:03, 15.89it/s]\n",
      " 97%|█████████▋| 1939/2000 [02:11<00:03, 15.93it/s]\n",
      " 97%|█████████▋| 1941/2000 [02:11<00:03, 15.72it/s]\n",
      " 97%|█████████▋| 1943/2000 [02:11<00:03, 15.54it/s]\n",
      " 97%|█████████▋| 1945/2000 [02:12<00:03, 15.70it/s]\n",
      " 97%|█████████▋| 1947/2000 [02:12<00:03, 15.75it/s]\n",
      " 97%|█████████▋| 1949/2000 [02:12<00:03, 15.77it/s]\n",
      "                                                   \n",
      "\n",
      " 98%|█████████▊| 1950/2000 [02:12<00:03, 15.77it/s]\n",
      " 98%|█████████▊| 1951/2000 [02:12<00:03, 15.78it/s]\n",
      " 98%|█████████▊| 1953/2000 [02:12<00:02, 15.88it/s]\n",
      " 98%|█████████▊| 1955/2000 [02:12<00:02, 15.88it/s]\n",
      " 98%|█████████▊| 1957/2000 [02:12<00:02, 15.85it/s]\n",
      " 98%|█████████▊| 1959/2000 [02:12<00:02, 15.94it/s]\n",
      " 98%|█████████▊| 1961/2000 [02:13<00:02, 16.00it/s]\n",
      " 98%|█████████▊| 1963/2000 [02:13<00:02, 16.07it/s]\n",
      " 98%|█████████▊| 1965/2000 [02:13<00:02, 16.06it/s]\n",
      " 98%|█████████▊| 1967/2000 [02:13<00:02, 16.08it/s]\n",
      " 98%|█████████▊| 1969/2000 [02:13<00:01, 16.02it/s]\n",
      " 99%|█████████▊| 1971/2000 [02:13<00:01, 15.96it/s]\n",
      " 99%|█████████▊| 1973/2000 [02:13<00:01, 16.05it/s]\n",
      " 99%|█████████▉| 1975/2000 [02:13<00:01, 16.11it/s]\n",
      " 99%|█████████▉| 1977/2000 [02:14<00:01, 16.08it/s]\n",
      " 99%|█████████▉| 1979/2000 [02:14<00:01, 15.46it/s]\n",
      " 99%|█████████▉| 1981/2000 [02:14<00:01, 15.58it/s]\n",
      " 99%|█████████▉| 1983/2000 [02:14<00:01, 15.71it/s]\n",
      " 99%|█████████▉| 1985/2000 [02:14<00:00, 15.75it/s]\n",
      " 99%|█████████▉| 1987/2000 [02:14<00:00, 15.95it/s]\n",
      " 99%|█████████▉| 1989/2000 [02:14<00:00, 15.48it/s]\n",
      "100%|█████████▉| 1991/2000 [02:14<00:00, 15.81it/s]\n",
      "100%|█████████▉| 1993/2000 [02:15<00:00, 15.69it/s]\n",
      "100%|█████████▉| 1995/2000 [02:15<00:00, 15.77it/s]\n",
      "100%|█████████▉| 1997/2000 [02:15<00:00, 15.88it/s]\n",
      "100%|█████████▉| 1999/2000 [02:15<00:00, 15.79it/s]\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [02:15<00:00, 15.79it/s][INFO|trainer.py:761] 2024-01-26 01:09:37,596 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:09:37,597 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:09:37,597 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:09:37,597 >>   Batch size = 8\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  4%|▎         | 9/250 [00:00<00:02, 85.03it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 18/250 [00:00<00:02, 78.38it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 26/250 [00:00<00:02, 76.14it/s]\u001b[A\n",
      "\n",
      " 14%|█▎        | 34/250 [00:00<00:02, 75.45it/s]\u001b[A\n",
      "\n",
      " 17%|█▋        | 42/250 [00:00<00:02, 75.19it/s]\u001b[A\n",
      "\n",
      " 20%|██        | 50/250 [00:00<00:02, 75.03it/s]\u001b[A\n",
      "\n",
      " 23%|██▎       | 58/250 [00:00<00:02, 75.05it/s]\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:00<00:02, 74.49it/s]\u001b[A\n",
      "\n",
      " 30%|██▉       | 74/250 [00:00<00:02, 73.99it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 82/250 [00:01<00:02, 74.06it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 90/250 [00:01<00:02, 74.04it/s]\u001b[A\n",
      "\n",
      " 39%|███▉      | 98/250 [00:01<00:02, 74.24it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 106/250 [00:01<00:01, 74.49it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 114/250 [00:01<00:01, 73.82it/s]\u001b[A\n",
      "\n",
      " 49%|████▉     | 122/250 [00:01<00:01, 74.04it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 130/250 [00:01<00:01, 74.24it/s]\u001b[A\n",
      "\n",
      " 55%|█████▌    | 138/250 [00:01<00:01, 73.96it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 146/250 [00:01<00:01, 73.87it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 154/250 [00:02<00:01, 73.91it/s]\u001b[A\n",
      "\n",
      " 65%|██████▍   | 162/250 [00:02<00:01, 74.06it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 170/250 [00:02<00:01, 74.39it/s]\u001b[A\n",
      "\n",
      " 71%|███████   | 178/250 [00:02<00:00, 74.13it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 186/250 [00:02<00:00, 74.09it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:02<00:00, 74.07it/s]\u001b[A\n",
      "\n",
      " 81%|████████  | 202/250 [00:02<00:00, 74.26it/s]\u001b[A\n",
      "\n",
      " 84%|████████▍ | 210/250 [00:02<00:00, 73.97it/s]\u001b[A\n",
      "\n",
      " 87%|████████▋ | 218/250 [00:02<00:00, 74.29it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 226/250 [00:03<00:00, 74.10it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▎| 234/250 [00:03<00:00, 74.18it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 242/250 [00:03<00:00, 74.02it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 74.33it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      "100%|██████████| 2000/2000 [02:18<00:00, 15.79it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 74.33it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:09:40,977 >> Saving model checkpoint to output/roberta_modified_emotion\\checkpoint-2000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:09:40,978 >> Configuration saved in output/roberta_modified_emotion\\checkpoint-2000\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:09:42,333 >> Model weights saved in output/roberta_modified_emotion\\checkpoint-2000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:09:42,334 >> tokenizer config file saved in output/roberta_modified_emotion\\checkpoint-2000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:09:42,335 >> Special tokens file saved in output/roberta_modified_emotion\\checkpoint-2000\\special_tokens_map.json\n",
      "[INFO|trainer.py:2017] 2024-01-26 01:09:47,448 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2196] 2024-01-26 01:09:47,448 >> Loading best model from output/roberta_modified_emotion\\checkpoint-2000 (score: 0.914).\n",
      "\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [02:25<00:00, 15.79it/s]\n",
      "100%|██████████| 2000/2000 [02:25<00:00, 13.73it/s]\n",
      "[INFO|trainer.py:2939] 2024-01-26 01:09:47,755 >> Saving model checkpoint to output/roberta_modified_emotion\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:09:47,756 >> Configuration saved in output/roberta_modified_emotion\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:09:53,494 >> Model weights saved in output/roberta_modified_emotion\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:09:53,495 >> tokenizer config file saved in output/roberta_modified_emotion\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:09:53,496 >> Special tokens file saved in output/roberta_modified_emotion\\special_tokens_map.json\n",
      "[INFO|trainer.py:761] 2024-01-26 01:09:53,612 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:09:53,613 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:09:53,613 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:09:53,613 >>   Batch size = 8\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  3%|▎         | 8/250 [00:00<00:03, 78.34it/s]\n",
      "  6%|▋         | 16/250 [00:00<00:03, 73.89it/s]\n",
      " 10%|▉         | 24/250 [00:00<00:03, 74.65it/s]\n",
      " 13%|█▎        | 32/250 [00:00<00:02, 74.93it/s]\n",
      " 16%|█▌        | 40/250 [00:00<00:02, 74.63it/s]\n",
      " 19%|█▉        | 48/250 [00:00<00:02, 74.84it/s]\n",
      " 22%|██▏       | 56/250 [00:00<00:02, 74.79it/s]\n",
      " 26%|██▌       | 64/250 [00:00<00:02, 75.19it/s]\n",
      " 29%|██▉       | 72/250 [00:00<00:02, 74.96it/s]\n",
      " 32%|███▏      | 80/250 [00:01<00:02, 74.80it/s]\n",
      " 35%|███▌      | 88/250 [00:01<00:02, 74.63it/s]\n",
      " 38%|███▊      | 96/250 [00:01<00:02, 74.77it/s]\n",
      " 42%|████▏     | 104/250 [00:01<00:01, 75.10it/s]\n",
      " 45%|████▍     | 112/250 [00:01<00:01, 75.18it/s]\n",
      " 48%|████▊     | 120/250 [00:01<00:01, 74.92it/s]\n",
      " 51%|█████     | 128/250 [00:01<00:01, 75.09it/s]\n",
      " 54%|█████▍    | 136/250 [00:01<00:01, 74.99it/s]\n",
      " 58%|█████▊    | 144/250 [00:01<00:01, 75.14it/s]\n",
      " 61%|██████    | 152/250 [00:02<00:01, 75.18it/s]\n",
      " 64%|██████▍   | 160/250 [00:02<00:01, 75.21it/s]\n",
      " 67%|██████▋   | 168/250 [00:02<00:01, 75.02it/s]\n",
      " 70%|███████   | 176/250 [00:02<00:00, 74.97it/s]\n",
      " 74%|███████▎  | 184/250 [00:02<00:00, 75.13it/s]\n",
      " 77%|███████▋  | 192/250 [00:02<00:00, 74.83it/s]\n",
      " 80%|████████  | 200/250 [00:02<00:00, 74.91it/s]\n",
      " 83%|████████▎ | 208/250 [00:02<00:00, 74.54it/s]\n",
      " 86%|████████▋ | 216/250 [00:02<00:00, 74.29it/s]\n",
      " 90%|████████▉ | 224/250 [00:02<00:00, 74.39it/s]\n",
      " 93%|█████████▎| 232/250 [00:03<00:00, 74.34it/s]\n",
      " 96%|█████████▌| 240/250 [00:03<00:00, 74.59it/s]\n",
      " 99%|█████████▉| 248/250 [00:03<00:00, 74.46it/s]\n",
      "100%|██████████| 250/250 [00:03<00:00, 74.67it/s]\n",
      "[INFO|modelcard.py:452] 2024-01-26 01:09:57,443 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.914}]}\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path roberta-base \\\n",
    "  --custom_model roberta_modified \\\n",
    "  --train_file data/train.json  \\\n",
    "  --validation_file data/validation.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --max_seq_length 128 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 1 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 1000 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 50 \\\n",
    "  --eval_steps 1000 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir output/roberta_modified_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassificationCustom(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHeadCustom(\n",
      "    (dense_1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "    (dense_2): Linear(in_features=1536, out_features=2304, bias=True)\n",
      "    (dense_3): Linear(in_features=2304, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassificationCustom.from_pretrained(\n",
    "    r'.\\output\\roberta_modified_emotion')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/26/2024 01:11:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-019d6cd006d41b2b\n",
      "Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:11:02,568 >> loading configuration file config.json from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:11:02,568 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:550] 2024-01-26 01:11:02,729 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:11:02,882 >> loading configuration file config.json from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:11:02,884 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file vocab.json from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\vocab.json\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file merges.txt from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\merges.txt\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file tokenizer.json from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:11:03,436 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:11:03,437 >> loading configuration file config.json from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:11:03,437 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2993] 2024-01-26 01:11:03,469 >> loading weights file model.safetensors from cache at .cache_training\\models--gpt2\\snapshots\\11c5a3d5811f50298f278a704980280950aedb10\\model.safetensors\n",
      "[INFO|modeling_utils.py:3775] 2024-01-26 01:11:04,339 >> All model checkpoint weights were used when initializing GPT2ForSequenceClassificationCustom.\n",
      "\n",
      "[WARNING|modeling_utils.py:3777] 2024-01-26 01:11:04,339 >> Some weights of GPT2ForSequenceClassificationCustom were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.dense_1_input.bias', 'score.out_proj.weight', 'score.dense_2.bias', 'score.dense_1_hidden.weight', 'score.dense_1_hidden.bias', 'score.dense_1_input.weight', 'score.dense_2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[ERROR|tokenization_utils_base.py:1091] 2024-01-26 01:11:04,376 >> Using pad_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1080] 2024-01-26 01:11:04,377 >> Using sep_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1103] 2024-01-26 01:11:04,377 >> Using cls_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1115] 2024-01-26 01:11:04,377 >> Using mask_token, but it is not set yet.\n",
      "Loading cached processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-fdce50f3e542d7aa.arrow\n",
      "[ERROR|tokenization_utils_base.py:1080] 2024-01-26 01:11:04,390 >> Using sep_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1103] 2024-01-26 01:11:04,390 >> Using cls_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1115] 2024-01-26 01:11:04,390 >> Using mask_token, but it is not set yet.\n",
      "\n",
      "Running tokenizer on dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-7a68591df3bd306e.arrow\n",
      "\n",
      "Running tokenizer on dataset: 100%|██████████| 2000/2000 [00:00<00:00, 26264.38 examples/s]\n",
      "[INFO|trainer.py:761] 2024-01-26 01:11:05,910 >> The following columns in the training set don't have a corresponding argument in `GPT2ForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:1760] 2024-01-26 01:11:05,913 >> ***** Running training *****\n",
      "[INFO|trainer.py:1761] 2024-01-26 01:11:05,913 >>   Num examples = 16,000\n",
      "[INFO|trainer.py:1762] 2024-01-26 01:11:05,913 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1763] 2024-01-26 01:11:05,913 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1766] 2024-01-26 01:11:05,913 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1767] 2024-01-26 01:11:05,913 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1768] 2024-01-26 01:11:05,913 >>   Total optimization steps = 2,000\n",
      "[INFO|trainer.py:1769] 2024-01-26 01:11:05,913 >>   Number of trainable parameters = 129,166,848\n",
      "\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]\n",
      "  0%|          | 1/2000 [00:01<37:55,  1.14s/it]\n",
      "  0%|          | 3/2000 [00:01<11:52,  2.80it/s]\n",
      "  0%|          | 5/2000 [00:01<06:52,  4.83it/s]\n",
      "  0%|          | 7/2000 [00:01<04:55,  6.74it/s]\n",
      "  0%|          | 9/2000 [00:01<03:52,  8.55it/s]\n",
      "  1%|          | 11/2000 [00:01<03:18, 10.03it/s]\n",
      "  1%|          | 13/2000 [00:01<02:55, 11.32it/s]\n",
      "  1%|          | 15/2000 [00:02<02:42, 12.24it/s]\n",
      "  1%|          | 17/2000 [00:02<02:35, 12.72it/s]\n",
      "  1%|          | 19/2000 [00:02<02:26, 13.55it/s]\n",
      "  1%|          | 21/2000 [00:02<02:20, 14.13it/s]\n",
      "  1%|          | 23/2000 [00:02<02:18, 14.28it/s]\n",
      "  1%|▏         | 25/2000 [00:02<02:15, 14.60it/s]\n",
      "  1%|▏         | 27/2000 [00:02<02:14, 14.66it/s]\n",
      "  1%|▏         | 29/2000 [00:03<02:12, 14.90it/s]\n",
      "  2%|▏         | 31/2000 [00:03<02:10, 15.07it/s]\n",
      "  2%|▏         | 33/2000 [00:03<02:12, 14.90it/s]\n",
      "  2%|▏         | 35/2000 [00:03<02:12, 14.79it/s]\n",
      "  2%|▏         | 37/2000 [00:03<02:09, 15.14it/s]\n",
      "  2%|▏         | 39/2000 [00:03<02:13, 14.72it/s]\n",
      "  2%|▏         | 41/2000 [00:03<02:13, 14.69it/s]\n",
      "  2%|▏         | 43/2000 [00:03<02:10, 15.00it/s]\n",
      "  2%|▏         | 45/2000 [00:04<02:11, 14.82it/s]\n",
      "  2%|▏         | 47/2000 [00:04<02:09, 15.09it/s]\n",
      "  2%|▏         | 49/2000 [00:04<02:10, 14.94it/s]\n",
      "                                                 \n",
      "\n",
      "  2%|▎         | 50/2000 [00:04<02:10, 14.94it/s]\n",
      "  3%|▎         | 51/2000 [00:04<02:09, 15.08it/s]\n",
      "  3%|▎         | 53/2000 [00:04<02:11, 14.86it/s]\n",
      "  3%|▎         | 55/2000 [00:04<02:11, 14.80it/s]\n",
      "  3%|▎         | 57/2000 [00:04<02:08, 15.07it/s]\n",
      "  3%|▎         | 59/2000 [00:05<02:05, 15.41it/s]\n",
      "  3%|▎         | 61/2000 [00:05<02:08, 15.04it/s]\n",
      "  3%|▎         | 63/2000 [00:05<02:06, 15.26it/s]\n",
      "  3%|▎         | 65/2000 [00:05<02:09, 15.00it/s]\n",
      "  3%|▎         | 67/2000 [00:05<02:10, 14.83it/s]\n",
      "  3%|▎         | 69/2000 [00:05<02:11, 14.65it/s]\n",
      "  4%|▎         | 71/2000 [00:05<02:09, 14.89it/s]\n",
      "  4%|▎         | 73/2000 [00:05<02:06, 15.20it/s]\n",
      "  4%|▍         | 75/2000 [00:06<02:09, 14.92it/s]\n",
      "  4%|▍         | 77/2000 [00:06<02:10, 14.79it/s]\n",
      "  4%|▍         | 79/2000 [00:06<02:08, 14.92it/s]\n",
      "  4%|▍         | 81/2000 [00:06<02:08, 14.97it/s]\n",
      "  4%|▍         | 83/2000 [00:06<02:11, 14.56it/s]\n",
      "  4%|▍         | 85/2000 [00:06<02:07, 14.98it/s]\n",
      "  4%|▍         | 87/2000 [00:06<02:09, 14.73it/s]\n",
      "  4%|▍         | 89/2000 [00:07<02:11, 14.56it/s]\n",
      "  5%|▍         | 91/2000 [00:07<02:07, 15.00it/s]\n",
      "  5%|▍         | 93/2000 [00:07<02:08, 14.83it/s]\n",
      "  5%|▍         | 95/2000 [00:07<02:07, 14.98it/s]\n",
      "  5%|▍         | 97/2000 [00:07<02:10, 14.57it/s]\n",
      "  5%|▍         | 99/2000 [00:07<02:09, 14.70it/s]\n",
      "                                                 \n",
      "\n",
      "  5%|▌         | 100/2000 [00:07<02:09, 14.70it/s]\n",
      "  5%|▌         | 101/2000 [00:07<02:06, 15.01it/s]\n",
      "  5%|▌         | 103/2000 [00:07<02:03, 15.41it/s]\n",
      "  5%|▌         | 105/2000 [00:08<02:06, 14.96it/s]\n",
      "  5%|▌         | 107/2000 [00:08<02:06, 14.91it/s]\n",
      "  5%|▌         | 109/2000 [00:08<02:05, 15.09it/s]\n",
      "  6%|▌         | 111/2000 [00:08<02:05, 15.10it/s]\n",
      "  6%|▌         | 113/2000 [00:08<02:05, 15.06it/s]\n",
      "  6%|▌         | 115/2000 [00:08<02:04, 15.18it/s]\n",
      "  6%|▌         | 117/2000 [00:08<02:04, 15.07it/s]\n",
      "  6%|▌         | 119/2000 [00:09<02:04, 15.12it/s]\n",
      "  6%|▌         | 121/2000 [00:09<02:01, 15.46it/s]\n",
      "  6%|▌         | 123/2000 [00:09<02:04, 15.08it/s]\n",
      "  6%|▋         | 125/2000 [00:09<02:02, 15.26it/s]\n",
      "  6%|▋         | 127/2000 [00:09<02:03, 15.14it/s]\n",
      "  6%|▋         | 129/2000 [00:09<02:03, 15.19it/s]\n",
      "  7%|▋         | 131/2000 [00:09<02:04, 15.01it/s]\n",
      "  7%|▋         | 133/2000 [00:09<02:03, 15.16it/s]\n",
      "  7%|▋         | 135/2000 [00:10<02:04, 15.00it/s]\n",
      "  7%|▋         | 137/2000 [00:10<02:02, 15.15it/s]\n",
      "  7%|▋         | 139/2000 [00:10<02:05, 14.84it/s]\n",
      "  7%|▋         | 141/2000 [00:10<02:03, 15.07it/s]\n",
      "  7%|▋         | 143/2000 [00:10<02:03, 15.00it/s]\n",
      "  7%|▋         | 145/2000 [00:10<02:02, 15.19it/s]\n",
      "  7%|▋         | 147/2000 [00:10<02:02, 15.07it/s]\n",
      "  7%|▋         | 149/2000 [00:11<02:00, 15.38it/s]\n",
      "                                                  \n",
      "\n",
      "  8%|▊         | 150/2000 [00:11<02:00, 15.38it/s]\n",
      "  8%|▊         | 151/2000 [00:11<02:03, 15.02it/s]\n",
      "  8%|▊         | 153/2000 [00:11<02:01, 15.16it/s]\n",
      "  8%|▊         | 155/2000 [00:11<02:03, 14.94it/s]\n",
      "  8%|▊         | 157/2000 [00:11<02:03, 14.92it/s]\n",
      "  8%|▊         | 159/2000 [00:11<02:02, 15.00it/s]\n",
      "  8%|▊         | 161/2000 [00:11<02:03, 14.87it/s]\n",
      "  8%|▊         | 163/2000 [00:11<02:02, 15.03it/s]\n",
      "  8%|▊         | 165/2000 [00:12<02:02, 15.00it/s]\n",
      "  8%|▊         | 167/2000 [00:12<02:01, 15.15it/s]\n",
      "  8%|▊         | 169/2000 [00:12<02:03, 14.80it/s]\n",
      "  9%|▊         | 171/2000 [00:12<02:01, 15.04it/s]\n",
      "  9%|▊         | 173/2000 [00:12<02:01, 14.98it/s]\n",
      "  9%|▉         | 175/2000 [00:12<02:00, 15.17it/s]\n",
      "  9%|▉         | 177/2000 [00:12<01:58, 15.38it/s]\n",
      "  9%|▉         | 179/2000 [00:13<01:57, 15.49it/s]\n",
      "  9%|▉         | 181/2000 [00:13<02:00, 15.13it/s]\n",
      "  9%|▉         | 183/2000 [00:13<02:01, 14.99it/s]\n",
      "  9%|▉         | 185/2000 [00:13<01:59, 15.21it/s]\n",
      "  9%|▉         | 187/2000 [00:13<02:01, 14.97it/s]\n",
      "  9%|▉         | 189/2000 [00:13<02:02, 14.83it/s]\n",
      " 10%|▉         | 191/2000 [00:13<01:59, 15.08it/s]\n",
      " 10%|▉         | 193/2000 [00:13<01:58, 15.30it/s]\n",
      " 10%|▉         | 195/2000 [00:14<02:00, 15.03it/s]\n",
      " 10%|▉         | 197/2000 [00:14<01:57, 15.31it/s]\n",
      " 10%|▉         | 199/2000 [00:14<01:59, 15.01it/s]\n",
      "                                                  \n",
      "\n",
      " 10%|█         | 200/2000 [00:14<01:59, 15.01it/s]\n",
      " 10%|█         | 201/2000 [00:14<02:01, 14.82it/s]\n",
      " 10%|█         | 203/2000 [00:14<02:02, 14.70it/s]\n",
      " 10%|█         | 205/2000 [00:14<02:00, 14.91it/s]\n",
      " 10%|█         | 207/2000 [00:14<01:58, 15.18it/s]\n",
      " 10%|█         | 209/2000 [00:15<01:58, 15.05it/s]\n",
      " 11%|█         | 211/2000 [00:15<01:57, 15.21it/s]\n",
      " 11%|█         | 213/2000 [00:15<01:55, 15.48it/s]\n",
      " 11%|█         | 215/2000 [00:15<01:57, 15.16it/s]\n",
      " 11%|█         | 217/2000 [00:15<01:58, 14.99it/s]\n",
      " 11%|█         | 219/2000 [00:15<01:59, 14.85it/s]\n",
      " 11%|█         | 221/2000 [00:15<01:58, 15.05it/s]\n",
      " 11%|█         | 223/2000 [00:15<01:58, 15.02it/s]\n",
      " 11%|█▏        | 225/2000 [00:16<01:58, 14.94it/s]\n",
      " 11%|█▏        | 227/2000 [00:16<02:02, 14.50it/s]\n",
      " 11%|█▏        | 229/2000 [00:16<02:03, 14.37it/s]\n",
      " 12%|█▏        | 231/2000 [00:16<02:03, 14.32it/s]\n",
      " 12%|█▏        | 233/2000 [00:16<02:00, 14.72it/s]\n",
      " 12%|█▏        | 235/2000 [00:16<01:56, 15.11it/s]\n",
      " 12%|█▏        | 237/2000 [00:16<01:58, 14.92it/s]\n",
      " 12%|█▏        | 239/2000 [00:17<01:56, 15.13it/s]\n",
      " 12%|█▏        | 241/2000 [00:17<01:57, 14.96it/s]\n",
      " 12%|█▏        | 243/2000 [00:17<01:55, 15.19it/s]\n",
      " 12%|█▏        | 245/2000 [00:17<01:56, 15.00it/s]\n",
      " 12%|█▏        | 247/2000 [00:17<01:55, 15.16it/s]\n",
      " 12%|█▏        | 249/2000 [00:17<01:57, 14.92it/s]\n",
      "                                                  \n",
      "\n",
      " 12%|█▎        | 250/2000 [00:17<01:57, 14.92it/s]\n",
      " 13%|█▎        | 251/2000 [00:17<01:54, 15.34it/s]\n",
      " 13%|█▎        | 253/2000 [00:17<01:56, 14.97it/s]\n",
      " 13%|█▎        | 255/2000 [00:18<01:54, 15.27it/s]\n",
      " 13%|█▎        | 257/2000 [00:18<01:55, 15.11it/s]\n",
      " 13%|█▎        | 259/2000 [00:18<01:55, 15.04it/s]\n",
      " 13%|█▎        | 261/2000 [00:18<01:57, 14.76it/s]\n",
      " 13%|█▎        | 263/2000 [00:18<01:55, 15.06it/s]\n",
      " 13%|█▎        | 265/2000 [00:18<01:55, 15.04it/s]\n",
      " 13%|█▎        | 267/2000 [00:18<01:57, 14.71it/s]\n",
      " 13%|█▎        | 269/2000 [00:19<01:56, 14.90it/s]\n",
      " 14%|█▎        | 271/2000 [00:19<01:56, 14.84it/s]\n",
      " 14%|█▎        | 273/2000 [00:19<01:54, 15.03it/s]\n",
      " 14%|█▍        | 275/2000 [00:19<01:56, 14.81it/s]\n",
      " 14%|█▍        | 277/2000 [00:19<01:53, 15.16it/s]\n",
      " 14%|█▍        | 279/2000 [00:19<01:55, 14.88it/s]\n",
      " 14%|█▍        | 281/2000 [00:19<01:52, 15.23it/s]\n",
      " 14%|█▍        | 283/2000 [00:19<01:54, 15.00it/s]\n",
      " 14%|█▍        | 285/2000 [00:20<01:51, 15.32it/s]\n",
      " 14%|█▍        | 287/2000 [00:20<01:54, 14.92it/s]\n",
      " 14%|█▍        | 289/2000 [00:20<01:55, 14.82it/s]\n",
      " 15%|█▍        | 291/2000 [00:20<01:54, 14.96it/s]\n",
      " 15%|█▍        | 293/2000 [00:20<01:54, 14.85it/s]\n",
      " 15%|█▍        | 295/2000 [00:20<01:55, 14.71it/s]\n",
      " 15%|█▍        | 297/2000 [00:20<01:56, 14.65it/s]\n",
      " 15%|█▍        | 299/2000 [00:21<01:54, 14.88it/s]\n",
      "                                                  \n",
      "\n",
      " 15%|█▌        | 300/2000 [00:21<01:54, 14.88it/s]\n",
      " 15%|█▌        | 301/2000 [00:21<01:55, 14.77it/s]\n",
      " 15%|█▌        | 303/2000 [00:21<01:52, 15.12it/s]\n",
      " 15%|█▌        | 305/2000 [00:21<01:54, 14.80it/s]\n",
      " 15%|█▌        | 307/2000 [00:21<01:52, 15.07it/s]\n",
      " 15%|█▌        | 309/2000 [00:21<01:54, 14.82it/s]\n",
      " 16%|█▌        | 311/2000 [00:21<01:51, 15.09it/s]\n",
      " 16%|█▌        | 313/2000 [00:21<01:50, 15.29it/s]\n",
      " 16%|█▌        | 315/2000 [00:22<01:52, 14.99it/s]\n",
      " 16%|█▌        | 317/2000 [00:22<01:49, 15.39it/s]\n",
      " 16%|█▌        | 319/2000 [00:22<01:48, 15.49it/s]\n",
      " 16%|█▌        | 321/2000 [00:22<01:51, 15.01it/s]\n",
      " 16%|█▌        | 323/2000 [00:22<01:52, 14.85it/s]\n",
      " 16%|█▋        | 325/2000 [00:22<01:53, 14.80it/s]\n",
      " 16%|█▋        | 327/2000 [00:22<01:51, 14.99it/s]\n",
      " 16%|█▋        | 329/2000 [00:23<01:51, 14.96it/s]\n",
      " 17%|█▋        | 331/2000 [00:23<01:50, 15.10it/s]\n",
      " 17%|█▋        | 333/2000 [00:23<01:48, 15.31it/s]\n",
      " 17%|█▋        | 335/2000 [00:23<01:47, 15.54it/s]\n",
      " 17%|█▋        | 337/2000 [00:23<01:50, 15.08it/s]\n",
      " 17%|█▋        | 339/2000 [00:23<01:51, 14.90it/s]\n",
      " 17%|█▋        | 341/2000 [00:23<01:49, 15.20it/s]\n",
      " 17%|█▋        | 343/2000 [00:23<01:50, 15.05it/s]\n",
      " 17%|█▋        | 345/2000 [00:24<01:50, 14.98it/s]\n",
      " 17%|█▋        | 347/2000 [00:24<01:50, 15.01it/s]\n",
      " 17%|█▋        | 349/2000 [00:24<01:47, 15.38it/s]\n",
      "                                                  \n",
      "\n",
      " 18%|█▊        | 350/2000 [00:24<01:47, 15.38it/s]\n",
      " 18%|█▊        | 351/2000 [00:24<01:50, 14.91it/s]\n",
      " 18%|█▊        | 353/2000 [00:24<01:51, 14.82it/s]\n",
      " 18%|█▊        | 355/2000 [00:24<01:49, 15.08it/s]\n",
      " 18%|█▊        | 357/2000 [00:24<01:49, 14.96it/s]\n",
      " 18%|█▊        | 359/2000 [00:25<01:48, 15.07it/s]\n",
      " 18%|█▊        | 361/2000 [00:25<01:50, 14.88it/s]\n",
      " 18%|█▊        | 363/2000 [00:25<01:49, 14.96it/s]\n",
      " 18%|█▊        | 365/2000 [00:25<01:49, 14.92it/s]\n",
      " 18%|█▊        | 367/2000 [00:25<01:50, 14.79it/s]\n",
      " 18%|█▊        | 369/2000 [00:25<01:48, 15.05it/s]\n",
      " 19%|█▊        | 371/2000 [00:25<01:49, 14.89it/s]\n",
      " 19%|█▊        | 373/2000 [00:25<01:47, 15.13it/s]\n",
      " 19%|█▉        | 375/2000 [00:26<01:48, 14.99it/s]\n",
      " 19%|█▉        | 377/2000 [00:26<01:46, 15.17it/s]\n",
      " 19%|█▉        | 379/2000 [00:26<01:44, 15.51it/s]\n",
      " 19%|█▉        | 381/2000 [00:26<01:47, 15.11it/s]\n",
      " 19%|█▉        | 383/2000 [00:26<01:48, 14.90it/s]\n",
      " 19%|█▉        | 385/2000 [00:26<01:46, 15.10it/s]\n",
      " 19%|█▉        | 387/2000 [00:26<01:47, 14.94it/s]\n",
      " 19%|█▉        | 389/2000 [00:27<01:46, 15.19it/s]\n",
      " 20%|█▉        | 391/2000 [00:27<01:44, 15.41it/s]\n",
      " 20%|█▉        | 393/2000 [00:27<01:45, 15.17it/s]\n",
      " 20%|█▉        | 395/2000 [00:27<01:44, 15.30it/s]\n",
      " 20%|█▉        | 397/2000 [00:27<01:44, 15.32it/s]\n",
      " 20%|█▉        | 399/2000 [00:27<01:45, 15.24it/s]\n",
      "                                                  \n",
      "\n",
      " 20%|██        | 400/2000 [00:27<01:44, 15.24it/s]\n",
      " 20%|██        | 401/2000 [00:27<01:45, 15.22it/s]\n",
      " 20%|██        | 403/2000 [00:27<01:46, 15.05it/s]\n",
      " 20%|██        | 405/2000 [00:28<01:47, 14.88it/s]\n",
      " 20%|██        | 407/2000 [00:28<01:45, 15.12it/s]\n",
      " 20%|██        | 409/2000 [00:28<01:45, 15.07it/s]\n",
      " 21%|██        | 411/2000 [00:28<01:44, 15.18it/s]\n",
      " 21%|██        | 413/2000 [00:28<01:45, 15.01it/s]\n",
      " 21%|██        | 415/2000 [00:28<01:44, 15.11it/s]\n",
      " 21%|██        | 417/2000 [00:28<01:46, 14.93it/s]\n",
      " 21%|██        | 419/2000 [00:28<01:44, 15.19it/s]\n",
      " 21%|██        | 421/2000 [00:29<01:45, 14.96it/s]\n",
      " 21%|██        | 423/2000 [00:29<01:44, 15.11it/s]\n",
      " 21%|██▏       | 425/2000 [00:29<01:45, 14.98it/s]\n",
      " 21%|██▏       | 427/2000 [00:29<01:46, 14.71it/s]\n",
      " 21%|██▏       | 429/2000 [00:29<01:47, 14.63it/s]\n",
      " 22%|██▏       | 431/2000 [00:29<01:46, 14.80it/s]\n",
      " 22%|██▏       | 433/2000 [00:29<01:46, 14.71it/s]\n",
      " 22%|██▏       | 435/2000 [00:30<01:44, 15.03it/s]\n",
      " 22%|██▏       | 437/2000 [00:30<01:44, 14.89it/s]\n",
      " 22%|██▏       | 439/2000 [00:30<01:46, 14.65it/s]\n",
      " 22%|██▏       | 441/2000 [00:30<01:44, 14.91it/s]\n",
      " 22%|██▏       | 443/2000 [00:30<01:44, 14.84it/s]\n",
      " 22%|██▏       | 445/2000 [00:30<01:43, 14.97it/s]\n",
      " 22%|██▏       | 447/2000 [00:30<01:42, 15.20it/s]\n",
      " 22%|██▏       | 449/2000 [00:31<01:43, 15.03it/s]\n",
      "                                                  \n",
      "\n",
      " 22%|██▎       | 450/2000 [00:31<01:43, 15.03it/s]\n",
      " 23%|██▎       | 451/2000 [00:31<01:41, 15.26it/s]\n",
      " 23%|██▎       | 453/2000 [00:31<01:39, 15.53it/s]\n",
      " 23%|██▎       | 455/2000 [00:31<01:42, 15.08it/s]\n",
      " 23%|██▎       | 457/2000 [00:31<01:40, 15.41it/s]\n",
      " 23%|██▎       | 459/2000 [00:31<01:42, 14.98it/s]\n",
      " 23%|██▎       | 461/2000 [00:31<01:40, 15.28it/s]\n",
      " 23%|██▎       | 463/2000 [00:31<01:43, 14.90it/s]\n",
      " 23%|██▎       | 465/2000 [00:32<01:40, 15.21it/s]\n",
      " 23%|██▎       | 467/2000 [00:32<01:42, 14.99it/s]\n",
      " 23%|██▎       | 469/2000 [00:32<01:44, 14.69it/s]\n",
      " 24%|██▎       | 471/2000 [00:32<01:44, 14.58it/s]\n",
      " 24%|██▎       | 473/2000 [00:32<01:44, 14.58it/s]\n",
      " 24%|██▍       | 475/2000 [00:32<01:42, 14.81it/s]\n",
      " 24%|██▍       | 477/2000 [00:32<01:43, 14.67it/s]\n",
      " 24%|██▍       | 479/2000 [00:33<01:47, 14.20it/s]\n",
      " 24%|██▍       | 481/2000 [00:33<01:43, 14.62it/s]\n",
      " 24%|██▍       | 483/2000 [00:33<01:44, 14.46it/s]\n",
      " 24%|██▍       | 485/2000 [00:33<01:44, 14.44it/s]\n",
      " 24%|██▍       | 487/2000 [00:33<01:42, 14.81it/s]\n",
      " 24%|██▍       | 489/2000 [00:33<01:43, 14.61it/s]\n",
      " 25%|██▍       | 491/2000 [00:33<01:46, 14.11it/s]\n",
      " 25%|██▍       | 493/2000 [00:34<01:45, 14.23it/s]\n",
      " 25%|██▍       | 495/2000 [00:34<01:43, 14.58it/s]\n",
      " 25%|██▍       | 497/2000 [00:34<01:43, 14.56it/s]\n",
      " 25%|██▍       | 499/2000 [00:34<01:40, 14.90it/s]\n",
      "                                                  \n",
      "\n",
      " 25%|██▌       | 500/2000 [00:34<01:40, 14.90it/s]\n",
      " 25%|██▌       | 501/2000 [00:34<01:42, 14.68it/s]\n",
      " 25%|██▌       | 503/2000 [00:34<01:39, 14.99it/s]\n",
      " 25%|██▌       | 505/2000 [00:34<01:41, 14.78it/s]\n",
      " 25%|██▌       | 507/2000 [00:34<01:41, 14.68it/s]\n",
      " 25%|██▌       | 509/2000 [00:35<01:38, 15.08it/s]\n",
      " 26%|██▌       | 511/2000 [00:35<01:40, 14.81it/s]\n",
      " 26%|██▌       | 513/2000 [00:35<01:40, 14.78it/s]\n",
      " 26%|██▌       | 515/2000 [00:35<01:39, 14.97it/s]\n",
      " 26%|██▌       | 517/2000 [00:35<01:39, 14.84it/s]\n",
      " 26%|██▌       | 519/2000 [00:35<01:40, 14.69it/s]\n",
      " 26%|██▌       | 521/2000 [00:35<01:39, 14.80it/s]\n",
      " 26%|██▌       | 523/2000 [00:36<01:42, 14.42it/s]\n",
      " 26%|██▋       | 525/2000 [00:36<01:39, 14.77it/s]\n",
      " 26%|██▋       | 527/2000 [00:36<01:40, 14.64it/s]\n",
      " 26%|██▋       | 529/2000 [00:36<01:40, 14.63it/s]\n",
      " 27%|██▋       | 531/2000 [00:36<01:38, 14.94it/s]\n",
      " 27%|██▋       | 533/2000 [00:36<01:39, 14.81it/s]\n",
      " 27%|██▋       | 535/2000 [00:36<01:37, 15.02it/s]\n",
      " 27%|██▋       | 537/2000 [00:36<01:38, 14.80it/s]\n",
      " 27%|██▋       | 539/2000 [00:37<01:36, 15.12it/s]\n",
      " 27%|██▋       | 541/2000 [00:37<01:35, 15.25it/s]\n",
      " 27%|██▋       | 543/2000 [00:37<01:37, 14.97it/s]\n",
      " 27%|██▋       | 545/2000 [00:37<01:36, 15.09it/s]\n",
      " 27%|██▋       | 547/2000 [00:37<01:37, 14.91it/s]\n",
      " 27%|██▋       | 549/2000 [00:37<01:37, 14.86it/s]\n",
      "                                                  \n",
      "\n",
      " 28%|██▊       | 550/2000 [00:37<01:37, 14.86it/s]\n",
      " 28%|██▊       | 551/2000 [00:37<01:35, 15.11it/s]\n",
      " 28%|██▊       | 553/2000 [00:38<01:37, 14.78it/s]\n",
      " 28%|██▊       | 555/2000 [00:38<01:36, 15.04it/s]\n",
      " 28%|██▊       | 557/2000 [00:38<01:36, 14.90it/s]\n",
      " 28%|██▊       | 559/2000 [00:38<01:37, 14.82it/s]\n",
      " 28%|██▊       | 561/2000 [00:38<01:38, 14.63it/s]\n",
      " 28%|██▊       | 563/2000 [00:38<01:36, 14.91it/s]\n",
      " 28%|██▊       | 565/2000 [00:38<01:37, 14.72it/s]\n",
      " 28%|██▊       | 567/2000 [00:38<01:38, 14.59it/s]\n",
      " 28%|██▊       | 569/2000 [00:39<01:38, 14.50it/s]\n",
      " 29%|██▊       | 571/2000 [00:39<01:42, 13.98it/s]\n",
      " 29%|██▊       | 573/2000 [00:39<01:41, 14.07it/s]\n",
      " 29%|██▉       | 575/2000 [00:39<01:40, 14.14it/s]\n",
      " 29%|██▉       | 577/2000 [00:39<01:37, 14.58it/s]\n",
      " 29%|██▉       | 579/2000 [00:39<01:38, 14.39it/s]\n",
      " 29%|██▉       | 581/2000 [00:39<01:38, 14.36it/s]\n",
      " 29%|██▉       | 583/2000 [00:40<01:38, 14.37it/s]\n",
      " 29%|██▉       | 585/2000 [00:40<01:36, 14.72it/s]\n",
      " 29%|██▉       | 587/2000 [00:40<01:37, 14.52it/s]\n",
      " 29%|██▉       | 589/2000 [00:40<01:37, 14.54it/s]\n",
      " 30%|██▉       | 591/2000 [00:40<01:40, 13.98it/s]\n",
      " 30%|██▉       | 593/2000 [00:40<01:39, 14.08it/s]\n",
      " 30%|██▉       | 595/2000 [00:40<01:39, 14.15it/s]\n",
      " 30%|██▉       | 597/2000 [00:41<01:38, 14.17it/s]\n",
      " 30%|██▉       | 599/2000 [00:41<01:39, 14.15it/s]\n",
      "                                                  \n",
      "\n",
      " 30%|███       | 600/2000 [00:41<01:38, 14.15it/s]\n",
      " 30%|███       | 601/2000 [00:41<01:38, 14.22it/s]\n",
      " 30%|███       | 603/2000 [00:41<01:38, 14.25it/s]\n",
      " 30%|███       | 605/2000 [00:41<01:37, 14.30it/s]\n",
      " 30%|███       | 607/2000 [00:41<01:37, 14.24it/s]\n",
      " 30%|███       | 609/2000 [00:41<01:37, 14.24it/s]\n",
      " 31%|███       | 611/2000 [00:42<01:38, 14.12it/s]\n",
      " 31%|███       | 613/2000 [00:42<01:36, 14.31it/s]\n",
      " 31%|███       | 615/2000 [00:42<01:37, 14.18it/s]\n",
      " 31%|███       | 617/2000 [00:42<01:39, 13.91it/s]\n",
      " 31%|███       | 619/2000 [00:42<01:36, 14.35it/s]\n",
      " 31%|███       | 621/2000 [00:42<01:36, 14.34it/s]\n",
      " 31%|███       | 623/2000 [00:42<01:36, 14.32it/s]\n",
      " 31%|███▏      | 625/2000 [00:43<01:36, 14.21it/s]\n",
      " 31%|███▏      | 627/2000 [00:43<01:36, 14.26it/s]\n",
      " 31%|███▏      | 629/2000 [00:43<01:35, 14.37it/s]\n",
      " 32%|███▏      | 631/2000 [00:43<01:33, 14.64it/s]\n",
      " 32%|███▏      | 633/2000 [00:43<01:35, 14.37it/s]\n",
      " 32%|███▏      | 635/2000 [00:43<01:33, 14.59it/s]\n",
      " 32%|███▏      | 637/2000 [00:43<01:34, 14.43it/s]\n",
      " 32%|███▏      | 639/2000 [00:44<01:34, 14.42it/s]\n",
      " 32%|███▏      | 641/2000 [00:44<01:34, 14.44it/s]\n",
      " 32%|███▏      | 643/2000 [00:44<01:33, 14.55it/s]\n",
      " 32%|███▏      | 645/2000 [00:44<01:32, 14.72it/s]\n",
      " 32%|███▏      | 647/2000 [00:44<01:32, 14.63it/s]\n",
      " 32%|███▏      | 649/2000 [00:44<01:33, 14.50it/s]\n",
      "                                                  \n",
      "\n",
      " 32%|███▎      | 650/2000 [00:44<01:33, 14.50it/s]\n",
      " 33%|███▎      | 651/2000 [00:44<01:33, 14.39it/s]\n",
      " 33%|███▎      | 653/2000 [00:44<01:33, 14.40it/s]\n",
      " 33%|███▎      | 655/2000 [00:45<01:33, 14.36it/s]\n",
      " 33%|███▎      | 657/2000 [00:45<01:33, 14.37it/s]\n",
      " 33%|███▎      | 659/2000 [00:45<01:30, 14.75it/s]\n",
      " 33%|███▎      | 661/2000 [00:45<01:34, 14.19it/s]\n",
      " 33%|███▎      | 663/2000 [00:45<01:31, 14.54it/s]\n",
      " 33%|███▎      | 665/2000 [00:45<01:32, 14.50it/s]\n",
      " 33%|███▎      | 667/2000 [00:45<01:30, 14.75it/s]\n",
      " 33%|███▎      | 669/2000 [00:46<01:30, 14.64it/s]\n",
      " 34%|███▎      | 671/2000 [00:46<01:31, 14.53it/s]\n",
      " 34%|███▎      | 673/2000 [00:46<01:31, 14.47it/s]\n",
      " 34%|███▍      | 675/2000 [00:46<01:33, 14.23it/s]\n",
      " 34%|███▍      | 677/2000 [00:46<01:32, 14.34it/s]\n",
      " 34%|███▍      | 679/2000 [00:46<01:30, 14.62it/s]\n",
      " 34%|███▍      | 681/2000 [00:46<01:29, 14.66it/s]\n",
      " 34%|███▍      | 683/2000 [00:47<01:30, 14.53it/s]\n",
      " 34%|███▍      | 685/2000 [00:47<01:30, 14.56it/s]\n",
      " 34%|███▍      | 687/2000 [00:47<01:30, 14.53it/s]\n",
      " 34%|███▍      | 689/2000 [00:47<01:31, 14.40it/s]\n",
      " 35%|███▍      | 691/2000 [00:47<01:31, 14.35it/s]\n",
      " 35%|███▍      | 693/2000 [00:47<01:31, 14.29it/s]\n",
      " 35%|███▍      | 695/2000 [00:47<01:31, 14.33it/s]\n",
      " 35%|███▍      | 697/2000 [00:48<01:30, 14.39it/s]\n",
      " 35%|███▍      | 699/2000 [00:48<01:28, 14.73it/s]\n",
      "                                                  \n",
      "\n",
      " 35%|███▌      | 700/2000 [00:48<01:28, 14.73it/s]\n",
      " 35%|███▌      | 701/2000 [00:48<01:31, 14.20it/s]\n",
      " 35%|███▌      | 703/2000 [00:48<01:30, 14.27it/s]\n",
      " 35%|███▌      | 705/2000 [00:48<01:28, 14.57it/s]\n",
      " 35%|███▌      | 707/2000 [00:48<01:29, 14.46it/s]\n",
      " 35%|███▌      | 709/2000 [00:48<01:29, 14.45it/s]\n",
      " 36%|███▌      | 711/2000 [00:49<01:30, 14.30it/s]\n",
      " 36%|███▌      | 713/2000 [00:49<01:29, 14.38it/s]\n",
      " 36%|███▌      | 715/2000 [00:49<01:30, 14.23it/s]\n",
      " 36%|███▌      | 717/2000 [00:49<01:29, 14.27it/s]\n",
      " 36%|███▌      | 719/2000 [00:49<01:29, 14.32it/s]\n",
      " 36%|███▌      | 721/2000 [00:49<01:27, 14.63it/s]\n",
      " 36%|███▌      | 723/2000 [00:49<01:27, 14.62it/s]\n",
      " 36%|███▋      | 725/2000 [00:49<01:27, 14.63it/s]\n",
      " 36%|███▋      | 727/2000 [00:50<01:30, 14.04it/s]\n",
      " 36%|███▋      | 729/2000 [00:50<01:27, 14.45it/s]\n",
      " 37%|███▋      | 731/2000 [00:50<01:28, 14.31it/s]\n",
      " 37%|███▋      | 733/2000 [00:50<01:28, 14.39it/s]\n",
      " 37%|███▋      | 735/2000 [00:50<01:30, 13.92it/s]\n",
      " 37%|███▋      | 737/2000 [00:50<01:30, 13.90it/s]\n",
      " 37%|███▋      | 739/2000 [00:50<01:29, 14.10it/s]\n",
      " 37%|███▋      | 741/2000 [00:51<01:28, 14.29it/s]\n",
      " 37%|███▋      | 743/2000 [00:51<01:28, 14.28it/s]\n",
      " 37%|███▋      | 745/2000 [00:51<01:25, 14.60it/s]\n",
      " 37%|███▋      | 747/2000 [00:51<01:25, 14.59it/s]\n",
      " 37%|███▋      | 749/2000 [00:51<01:25, 14.56it/s]\n",
      "                                                  \n",
      "\n",
      " 38%|███▊      | 750/2000 [00:51<01:25, 14.56it/s]\n",
      " 38%|███▊      | 751/2000 [00:51<01:26, 14.45it/s]\n",
      " 38%|███▊      | 753/2000 [00:51<01:26, 14.49it/s]\n",
      " 38%|███▊      | 755/2000 [00:52<01:26, 14.45it/s]\n",
      " 38%|███▊      | 757/2000 [00:52<01:26, 14.44it/s]\n",
      " 38%|███▊      | 759/2000 [00:52<01:26, 14.36it/s]\n",
      " 38%|███▊      | 761/2000 [00:52<01:26, 14.34it/s]\n",
      " 38%|███▊      | 763/2000 [00:52<01:24, 14.67it/s]\n",
      " 38%|███▊      | 765/2000 [00:52<01:24, 14.58it/s]\n",
      " 38%|███▊      | 767/2000 [00:52<01:24, 14.55it/s]\n",
      " 38%|███▊      | 769/2000 [00:53<01:24, 14.48it/s]\n",
      " 39%|███▊      | 771/2000 [00:53<01:25, 14.41it/s]\n",
      " 39%|███▊      | 773/2000 [00:53<01:26, 14.24it/s]\n",
      " 39%|███▉      | 775/2000 [00:53<01:25, 14.34it/s]\n",
      " 39%|███▉      | 777/2000 [00:53<01:26, 14.14it/s]\n",
      " 39%|███▉      | 779/2000 [00:53<01:27, 13.89it/s]\n",
      " 39%|███▉      | 781/2000 [00:53<01:27, 13.97it/s]\n",
      " 39%|███▉      | 783/2000 [00:54<01:27, 13.94it/s]\n",
      " 39%|███▉      | 785/2000 [00:54<01:26, 14.02it/s]\n",
      " 39%|███▉      | 787/2000 [00:54<01:27, 13.86it/s]\n",
      " 39%|███▉      | 789/2000 [00:54<01:26, 14.08it/s]\n",
      " 40%|███▉      | 791/2000 [00:54<01:27, 13.87it/s]\n",
      " 40%|███▉      | 793/2000 [00:54<01:24, 14.32it/s]\n",
      " 40%|███▉      | 795/2000 [00:54<01:24, 14.19it/s]\n",
      " 40%|███▉      | 797/2000 [00:55<01:24, 14.31it/s]\n",
      " 40%|███▉      | 799/2000 [00:55<01:25, 14.03it/s]\n",
      "                                                  \n",
      "\n",
      " 40%|████      | 800/2000 [00:55<01:25, 14.03it/s]\n",
      " 40%|████      | 801/2000 [00:55<01:24, 14.23it/s]\n",
      " 40%|████      | 803/2000 [00:55<01:24, 14.21it/s]\n",
      " 40%|████      | 805/2000 [00:55<01:23, 14.24it/s]\n",
      " 40%|████      | 807/2000 [00:55<01:21, 14.57it/s]\n",
      " 40%|████      | 809/2000 [00:55<01:22, 14.47it/s]\n",
      " 41%|████      | 811/2000 [00:55<01:22, 14.47it/s]\n",
      " 41%|████      | 813/2000 [00:56<01:22, 14.40it/s]\n",
      " 41%|████      | 815/2000 [00:56<01:20, 14.71it/s]\n",
      " 41%|████      | 817/2000 [00:56<01:21, 14.60it/s]\n",
      " 41%|████      | 819/2000 [00:56<01:19, 14.93it/s]\n",
      " 41%|████      | 821/2000 [00:56<01:20, 14.64it/s]\n",
      " 41%|████      | 823/2000 [00:56<01:20, 14.60it/s]\n",
      " 41%|████▏     | 825/2000 [00:56<01:18, 14.98it/s]\n",
      " 41%|████▏     | 827/2000 [00:57<01:20, 14.64it/s]\n",
      " 41%|████▏     | 829/2000 [00:57<01:20, 14.57it/s]\n",
      " 42%|████▏     | 831/2000 [00:57<01:23, 14.03it/s]\n",
      " 42%|████▏     | 833/2000 [00:57<01:22, 14.16it/s]\n",
      " 42%|████▏     | 835/2000 [00:57<01:21, 14.23it/s]\n",
      " 42%|████▏     | 837/2000 [00:57<01:19, 14.65it/s]\n",
      " 42%|████▏     | 839/2000 [00:57<01:22, 14.12it/s]\n",
      " 42%|████▏     | 841/2000 [00:58<01:19, 14.60it/s]\n",
      " 42%|████▏     | 843/2000 [00:58<01:20, 14.37it/s]\n",
      " 42%|████▏     | 845/2000 [00:58<01:20, 14.32it/s]\n",
      " 42%|████▏     | 847/2000 [00:58<01:20, 14.38it/s]\n",
      " 42%|████▏     | 849/2000 [00:58<01:22, 14.01it/s]\n",
      "                                                  \n",
      "\n",
      " 42%|████▎     | 850/2000 [00:58<01:22, 14.01it/s]\n",
      " 43%|████▎     | 851/2000 [00:58<01:22, 13.89it/s]\n",
      " 43%|████▎     | 853/2000 [00:58<01:21, 14.06it/s]\n",
      " 43%|████▎     | 855/2000 [00:59<01:20, 14.29it/s]\n",
      " 43%|████▎     | 857/2000 [00:59<01:22, 13.86it/s]\n",
      " 43%|████▎     | 859/2000 [00:59<01:19, 14.34it/s]\n",
      " 43%|████▎     | 861/2000 [00:59<01:19, 14.25it/s]\n",
      " 43%|████▎     | 863/2000 [00:59<01:19, 14.31it/s]\n",
      " 43%|████▎     | 865/2000 [00:59<01:19, 14.24it/s]\n",
      " 43%|████▎     | 867/2000 [00:59<01:18, 14.41it/s]\n",
      " 43%|████▎     | 869/2000 [01:00<01:16, 14.83it/s]\n",
      " 44%|████▎     | 871/2000 [01:00<01:16, 14.69it/s]\n",
      " 44%|████▎     | 873/2000 [01:00<01:17, 14.56it/s]\n",
      " 44%|████▍     | 875/2000 [01:00<01:16, 14.76it/s]\n",
      " 44%|████▍     | 877/2000 [01:00<01:16, 14.68it/s]\n",
      " 44%|████▍     | 879/2000 [01:00<01:17, 14.52it/s]\n",
      " 44%|████▍     | 881/2000 [01:00<01:17, 14.43it/s]\n",
      " 44%|████▍     | 883/2000 [01:00<01:16, 14.60it/s]\n",
      " 44%|████▍     | 885/2000 [01:01<01:15, 14.67it/s]\n",
      " 44%|████▍     | 887/2000 [01:01<01:16, 14.59it/s]\n",
      " 44%|████▍     | 889/2000 [01:01<01:16, 14.52it/s]\n",
      " 45%|████▍     | 891/2000 [01:01<01:16, 14.52it/s]\n",
      " 45%|████▍     | 893/2000 [01:01<01:16, 14.43it/s]\n",
      " 45%|████▍     | 895/2000 [01:01<01:16, 14.36it/s]\n",
      " 45%|████▍     | 897/2000 [01:01<01:16, 14.34it/s]\n",
      " 45%|████▍     | 899/2000 [01:02<01:15, 14.64it/s]\n",
      "                                                  \n",
      "\n",
      " 45%|████▌     | 900/2000 [01:02<01:15, 14.64it/s]\n",
      " 45%|████▌     | 901/2000 [01:02<01:14, 14.76it/s]\n",
      " 45%|████▌     | 903/2000 [01:02<01:12, 15.04it/s]\n",
      " 45%|████▌     | 905/2000 [01:02<01:14, 14.75it/s]\n",
      " 45%|████▌     | 907/2000 [01:02<01:14, 14.66it/s]\n",
      " 45%|████▌     | 909/2000 [01:02<01:13, 14.87it/s]\n",
      " 46%|████▌     | 911/2000 [01:02<01:13, 14.77it/s]\n",
      " 46%|████▌     | 913/2000 [01:03<01:16, 14.14it/s]\n",
      " 46%|████▌     | 915/2000 [01:03<01:16, 14.18it/s]\n",
      " 46%|████▌     | 917/2000 [01:03<01:16, 14.24it/s]\n",
      " 46%|████▌     | 919/2000 [01:03<01:15, 14.29it/s]\n",
      " 46%|████▌     | 921/2000 [01:03<01:15, 14.33it/s]\n",
      " 46%|████▌     | 923/2000 [01:03<01:13, 14.68it/s]\n",
      " 46%|████▋     | 925/2000 [01:03<01:15, 14.26it/s]\n",
      " 46%|████▋     | 927/2000 [01:04<01:14, 14.46it/s]\n",
      " 46%|████▋     | 929/2000 [01:04<01:14, 14.38it/s]\n",
      " 47%|████▋     | 931/2000 [01:04<01:14, 14.31it/s]\n",
      " 47%|████▋     | 933/2000 [01:04<01:14, 14.33it/s]\n",
      " 47%|████▋     | 935/2000 [01:04<01:14, 14.32it/s]\n",
      " 47%|████▋     | 937/2000 [01:04<01:13, 14.37it/s]\n",
      " 47%|████▋     | 939/2000 [01:04<01:13, 14.36it/s]\n",
      " 47%|████▋     | 941/2000 [01:04<01:12, 14.63it/s]\n",
      " 47%|████▋     | 943/2000 [01:05<01:12, 14.59it/s]\n",
      " 47%|████▋     | 945/2000 [01:05<01:10, 14.91it/s]\n",
      " 47%|████▋     | 947/2000 [01:05<01:11, 14.69it/s]\n",
      " 47%|████▋     | 949/2000 [01:05<01:11, 14.67it/s]\n",
      "                                                  \n",
      "\n",
      " 48%|████▊     | 950/2000 [01:05<01:11, 14.67it/s]\n",
      " 48%|████▊     | 951/2000 [01:05<01:10, 14.97it/s]\n",
      " 48%|████▊     | 953/2000 [01:05<01:11, 14.68it/s]\n",
      " 48%|████▊     | 955/2000 [01:05<01:13, 14.26it/s]\n",
      " 48%|████▊     | 957/2000 [01:06<01:13, 14.23it/s]\n",
      " 48%|████▊     | 959/2000 [01:06<01:12, 14.30it/s]\n",
      " 48%|████▊     | 961/2000 [01:06<01:13, 14.19it/s]\n",
      " 48%|████▊     | 963/2000 [01:06<01:12, 14.25it/s]\n",
      " 48%|████▊     | 965/2000 [01:06<01:12, 14.26it/s]\n",
      " 48%|████▊     | 967/2000 [01:06<01:11, 14.49it/s]\n",
      " 48%|████▊     | 969/2000 [01:06<01:11, 14.49it/s]\n",
      " 49%|████▊     | 971/2000 [01:07<01:10, 14.50it/s]\n",
      " 49%|████▊     | 973/2000 [01:07<01:10, 14.49it/s]\n",
      " 49%|████▉     | 975/2000 [01:07<01:10, 14.48it/s]\n",
      " 49%|████▉     | 977/2000 [01:07<01:10, 14.43it/s]\n",
      " 49%|████▉     | 979/2000 [01:07<01:09, 14.60it/s]\n",
      " 49%|████▉     | 981/2000 [01:07<01:09, 14.70it/s]\n",
      " 49%|████▉     | 983/2000 [01:07<01:09, 14.54it/s]\n",
      " 49%|████▉     | 985/2000 [01:08<01:10, 14.44it/s]\n",
      " 49%|████▉     | 987/2000 [01:08<01:09, 14.63it/s]\n",
      " 49%|████▉     | 989/2000 [01:08<01:09, 14.53it/s]\n",
      " 50%|████▉     | 991/2000 [01:08<01:09, 14.61it/s]\n",
      " 50%|████▉     | 993/2000 [01:08<01:08, 14.75it/s]\n",
      " 50%|████▉     | 995/2000 [01:08<01:08, 14.71it/s]\n",
      " 50%|████▉     | 997/2000 [01:08<01:09, 14.46it/s]\n",
      " 50%|████▉     | 999/2000 [01:08<01:09, 14.38it/s]\n",
      "                                                  \n",
      "\n",
      " 50%|█████     | 1000/2000 [01:09<01:09, 14.38it/s][INFO|trainer.py:761] 2024-01-26 01:12:14,967 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:12:14,968 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:12:14,968 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:12:14,968 >>   Batch size = 8\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  3%|▎         | 8/250 [00:00<00:03, 75.54it/s]\u001b[A\n",
      "\n",
      "  6%|▋         | 16/250 [00:00<00:03, 67.76it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 23/250 [00:00<00:03, 66.12it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/250 [00:00<00:03, 65.62it/s]\u001b[A\n",
      "\n",
      " 15%|█▌        | 38/250 [00:00<00:03, 67.67it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/250 [00:00<00:03, 67.85it/s]\u001b[A\n",
      "\n",
      " 21%|██        | 52/250 [00:00<00:02, 68.27it/s]\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/250 [00:00<00:02, 68.91it/s]\u001b[A\n",
      "\n",
      " 27%|██▋       | 67/250 [00:00<00:02, 68.82it/s]\u001b[A\n",
      "\n",
      " 30%|███       | 75/250 [00:01<00:02, 68.89it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 82/250 [00:01<00:02, 68.96it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 89/250 [00:01<00:02, 68.94it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 96/250 [00:01<00:02, 68.98it/s]\u001b[A\n",
      "\n",
      " 41%|████      | 103/250 [00:01<00:02, 68.27it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 110/250 [00:01<00:02, 68.56it/s]\u001b[A\n",
      "\n",
      " 47%|████▋     | 117/250 [00:01<00:01, 68.25it/s]\u001b[A\n",
      "\n",
      " 50%|████▉     | 124/250 [00:01<00:01, 68.52it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 131/250 [00:01<00:01, 68.43it/s]\u001b[A\n",
      "\n",
      " 55%|█████▌    | 138/250 [00:02<00:01, 68.40it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 145/250 [00:02<00:01, 67.72it/s]\u001b[A\n",
      "\n",
      " 61%|██████    | 152/250 [00:02<00:01, 66.67it/s]\u001b[A\n",
      "\n",
      " 64%|██████▎   | 159/250 [00:02<00:01, 67.45it/s]\u001b[A\n",
      "\n",
      " 66%|██████▋   | 166/250 [00:02<00:01, 68.03it/s]\u001b[A\n",
      "\n",
      " 69%|██████▉   | 173/250 [00:02<00:01, 67.96it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 180/250 [00:02<00:01, 68.14it/s]\u001b[A\n",
      "\n",
      " 75%|███████▍  | 187/250 [00:02<00:00, 68.49it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:02<00:00, 68.56it/s]\u001b[A\n",
      "\n",
      " 80%|████████  | 201/250 [00:02<00:00, 68.68it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 208/250 [00:03<00:00, 68.31it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 215/250 [00:03<00:00, 67.99it/s]\u001b[A\n",
      "\n",
      " 89%|████████▉ | 222/250 [00:03<00:00, 67.40it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 229/250 [00:03<00:00, 67.24it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▍| 236/250 [00:03<00:00, 67.84it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 243/250 [00:03<00:00, 67.72it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 67.68it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      " 50%|█████     | 1000/2000 [01:12<01:09, 14.38it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 67.68it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:12:18,663 >> Saving model checkpoint to output/gpt2_modified_emotion\\checkpoint-1000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:12:18,663 >> Configuration saved in output/gpt2_modified_emotion\\checkpoint-1000\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:12:19,921 >> Model weights saved in output/gpt2_modified_emotion\\checkpoint-1000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:12:19,922 >> tokenizer config file saved in output/gpt2_modified_emotion\\checkpoint-1000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:12:19,922 >> Special tokens file saved in output/gpt2_modified_emotion\\checkpoint-1000\\special_tokens_map.json\n",
      "\n",
      " 50%|█████     | 1001/2000 [01:19<26:41,  1.60s/it]\n",
      " 50%|█████     | 1003/2000 [01:19<19:02,  1.15s/it]\n",
      " 50%|█████     | 1005/2000 [01:19<13:39,  1.21it/s]\n",
      " 50%|█████     | 1007/2000 [01:19<09:53,  1.67it/s]\n",
      " 50%|█████     | 1009/2000 [01:19<07:14,  2.28it/s]\n",
      " 51%|█████     | 1011/2000 [01:20<05:24,  3.05it/s]\n",
      " 51%|█████     | 1013/2000 [01:20<04:07,  3.99it/s]\n",
      " 51%|█████     | 1015/2000 [01:20<03:13,  5.10it/s]\n",
      " 51%|█████     | 1017/2000 [01:20<02:34,  6.36it/s]\n",
      " 51%|█████     | 1019/2000 [01:20<02:07,  7.70it/s]\n",
      " 51%|█████     | 1021/2000 [01:20<01:49,  8.95it/s]\n",
      " 51%|█████     | 1023/2000 [01:20<01:36, 10.08it/s]\n",
      " 51%|█████▏    | 1025/2000 [01:21<01:27, 11.09it/s]\n",
      " 51%|█████▏    | 1027/2000 [01:21<01:20, 12.11it/s]\n",
      " 51%|█████▏    | 1029/2000 [01:21<01:16, 12.64it/s]\n",
      " 52%|█████▏    | 1031/2000 [01:21<01:15, 12.81it/s]\n",
      " 52%|█████▏    | 1033/2000 [01:21<01:13, 13.24it/s]\n",
      " 52%|█████▏    | 1035/2000 [01:21<01:10, 13.60it/s]\n",
      " 52%|█████▏    | 1037/2000 [01:21<01:10, 13.71it/s]\n",
      " 52%|█████▏    | 1039/2000 [01:22<01:11, 13.45it/s]\n",
      " 52%|█████▏    | 1041/2000 [01:22<01:09, 13.71it/s]\n",
      " 52%|█████▏    | 1043/2000 [01:22<01:08, 13.90it/s]\n",
      " 52%|█████▏    | 1045/2000 [01:22<01:07, 14.24it/s]\n",
      " 52%|█████▏    | 1047/2000 [01:22<01:08, 14.00it/s]\n",
      " 52%|█████▏    | 1049/2000 [01:22<01:07, 14.03it/s]\n",
      "                                                   \n",
      "\n",
      " 52%|█████▎    | 1050/2000 [01:22<01:07, 14.03it/s]\n",
      " 53%|█████▎    | 1051/2000 [01:22<01:07, 14.05it/s]\n",
      " 53%|█████▎    | 1053/2000 [01:23<01:07, 14.09it/s]\n",
      " 53%|█████▎    | 1055/2000 [01:23<01:06, 14.15it/s]\n",
      " 53%|█████▎    | 1057/2000 [01:23<01:06, 14.19it/s]\n",
      " 53%|█████▎    | 1059/2000 [01:23<01:08, 13.75it/s]\n",
      " 53%|█████▎    | 1061/2000 [01:23<01:07, 13.90it/s]\n",
      " 53%|█████▎    | 1063/2000 [01:23<01:06, 14.02it/s]\n",
      " 53%|█████▎    | 1065/2000 [01:23<01:04, 14.46it/s]\n",
      " 53%|█████▎    | 1067/2000 [01:23<01:03, 14.64it/s]\n",
      " 53%|█████▎    | 1069/2000 [01:24<01:04, 14.46it/s]\n",
      " 54%|█████▎    | 1071/2000 [01:24<01:02, 14.81it/s]\n",
      " 54%|█████▎    | 1073/2000 [01:24<01:03, 14.57it/s]\n",
      " 54%|█████▍    | 1075/2000 [01:24<01:03, 14.46it/s]\n",
      " 54%|█████▍    | 1077/2000 [01:24<01:04, 14.40it/s]\n",
      " 54%|█████▍    | 1079/2000 [01:24<01:04, 14.22it/s]\n",
      " 54%|█████▍    | 1081/2000 [01:24<01:04, 14.32it/s]\n",
      " 54%|█████▍    | 1083/2000 [01:25<01:02, 14.75it/s]\n",
      " 54%|█████▍    | 1085/2000 [01:25<01:05, 14.01it/s]\n",
      " 54%|█████▍    | 1087/2000 [01:25<01:05, 14.00it/s]\n",
      " 54%|█████▍    | 1089/2000 [01:25<01:04, 14.11it/s]\n",
      " 55%|█████▍    | 1091/2000 [01:25<01:03, 14.21it/s]\n",
      " 55%|█████▍    | 1093/2000 [01:25<01:03, 14.22it/s]\n",
      " 55%|█████▍    | 1095/2000 [01:25<01:04, 14.13it/s]\n",
      " 55%|█████▍    | 1097/2000 [01:26<01:02, 14.50it/s]\n",
      " 55%|█████▍    | 1099/2000 [01:26<01:02, 14.50it/s]\n",
      "                                                   \n",
      "\n",
      " 55%|█████▌    | 1100/2000 [01:26<01:02, 14.50it/s]\n",
      " 55%|█████▌    | 1101/2000 [01:26<01:02, 14.37it/s]\n",
      " 55%|█████▌    | 1103/2000 [01:26<01:04, 14.01it/s]\n",
      " 55%|█████▌    | 1105/2000 [01:26<01:03, 14.10it/s]\n",
      " 55%|█████▌    | 1107/2000 [01:26<01:01, 14.49it/s]\n",
      " 55%|█████▌    | 1109/2000 [01:26<01:03, 14.05it/s]\n",
      " 56%|█████▌    | 1111/2000 [01:27<01:01, 14.49it/s]\n",
      " 56%|█████▌    | 1113/2000 [01:27<01:01, 14.39it/s]\n",
      " 56%|█████▌    | 1115/2000 [01:27<01:01, 14.38it/s]\n",
      " 56%|█████▌    | 1117/2000 [01:27<01:01, 14.37it/s]\n",
      " 56%|█████▌    | 1119/2000 [01:27<01:01, 14.38it/s]\n",
      " 56%|█████▌    | 1121/2000 [01:27<01:01, 14.38it/s]\n",
      " 56%|█████▌    | 1123/2000 [01:27<00:59, 14.63it/s]\n",
      " 56%|█████▋    | 1125/2000 [01:28<01:00, 14.55it/s]\n",
      " 56%|█████▋    | 1127/2000 [01:28<01:00, 14.54it/s]\n",
      " 56%|█████▋    | 1129/2000 [01:28<00:58, 14.79it/s]\n",
      " 57%|█████▋    | 1131/2000 [01:28<00:58, 14.78it/s]\n",
      " 57%|█████▋    | 1133/2000 [01:28<00:59, 14.65it/s]\n",
      " 57%|█████▋    | 1135/2000 [01:28<00:59, 14.53it/s]\n",
      " 57%|█████▋    | 1137/2000 [01:28<00:58, 14.81it/s]\n",
      " 57%|█████▋    | 1139/2000 [01:28<00:58, 14.74it/s]\n",
      " 57%|█████▋    | 1141/2000 [01:29<00:58, 14.61it/s]\n",
      " 57%|█████▋    | 1143/2000 [01:29<00:58, 14.55it/s]\n",
      " 57%|█████▋    | 1145/2000 [01:29<00:57, 14.79it/s]\n",
      " 57%|█████▋    | 1147/2000 [01:29<00:58, 14.62it/s]\n",
      " 57%|█████▋    | 1149/2000 [01:29<00:58, 14.58it/s]\n",
      "                                                   \n",
      "\n",
      " 57%|█████▊    | 1150/2000 [01:29<00:58, 14.58it/s]\n",
      " 58%|█████▊    | 1151/2000 [01:29<00:57, 14.82it/s]\n",
      " 58%|█████▊    | 1153/2000 [01:29<00:57, 14.68it/s]\n",
      " 58%|█████▊    | 1155/2000 [01:30<00:58, 14.56it/s]\n",
      " 58%|█████▊    | 1157/2000 [01:30<00:58, 14.51it/s]\n",
      " 58%|█████▊    | 1159/2000 [01:30<00:57, 14.59it/s]\n",
      " 58%|█████▊    | 1161/2000 [01:30<00:57, 14.51it/s]\n",
      " 58%|█████▊    | 1163/2000 [01:30<00:56, 14.73it/s]\n",
      " 58%|█████▊    | 1165/2000 [01:30<00:57, 14.61it/s]\n",
      " 58%|█████▊    | 1167/2000 [01:30<00:56, 14.62it/s]\n",
      " 58%|█████▊    | 1169/2000 [01:31<00:56, 14.79it/s]\n",
      " 59%|█████▊    | 1171/2000 [01:31<00:57, 14.34it/s]\n",
      " 59%|█████▊    | 1173/2000 [01:31<00:57, 14.32it/s]\n",
      " 59%|█████▉    | 1175/2000 [01:31<00:56, 14.62it/s]\n",
      " 59%|█████▉    | 1177/2000 [01:31<00:57, 14.38it/s]\n",
      " 59%|█████▉    | 1179/2000 [01:31<00:56, 14.41it/s]\n",
      " 59%|█████▉    | 1181/2000 [01:31<00:56, 14.49it/s]\n",
      " 59%|█████▉    | 1183/2000 [01:32<00:56, 14.46it/s]\n",
      " 59%|█████▉    | 1185/2000 [01:32<00:55, 14.77it/s]\n",
      " 59%|█████▉    | 1187/2000 [01:32<00:55, 14.61it/s]\n",
      " 59%|█████▉    | 1189/2000 [01:32<00:55, 14.49it/s]\n",
      " 60%|█████▉    | 1191/2000 [01:32<00:56, 14.39it/s]\n",
      " 60%|█████▉    | 1193/2000 [01:32<00:56, 14.36it/s]\n",
      " 60%|█████▉    | 1195/2000 [01:32<00:55, 14.38it/s]\n",
      " 60%|█████▉    | 1197/2000 [01:32<00:55, 14.47it/s]\n",
      " 60%|█████▉    | 1199/2000 [01:33<00:56, 14.29it/s]\n",
      "                                                   \n",
      "\n",
      " 60%|██████    | 1200/2000 [01:33<00:56, 14.29it/s]\n",
      " 60%|██████    | 1201/2000 [01:33<00:55, 14.28it/s]\n",
      " 60%|██████    | 1203/2000 [01:33<00:56, 14.14it/s]\n",
      " 60%|██████    | 1205/2000 [01:33<00:55, 14.23it/s]\n",
      " 60%|██████    | 1207/2000 [01:33<00:55, 14.20it/s]\n",
      " 60%|██████    | 1209/2000 [01:33<00:55, 14.30it/s]\n",
      " 61%|██████    | 1211/2000 [01:33<00:54, 14.58it/s]\n",
      " 61%|██████    | 1213/2000 [01:34<00:53, 14.59it/s]\n",
      " 61%|██████    | 1215/2000 [01:34<00:54, 14.47it/s]\n",
      " 61%|██████    | 1217/2000 [01:34<00:52, 14.86it/s]\n",
      " 61%|██████    | 1219/2000 [01:34<00:53, 14.55it/s]\n",
      " 61%|██████    | 1221/2000 [01:34<00:55, 14.16it/s]\n",
      " 61%|██████    | 1223/2000 [01:34<00:54, 14.20it/s]\n",
      " 61%|██████▏   | 1225/2000 [01:34<00:53, 14.58it/s]\n",
      " 61%|██████▏   | 1227/2000 [01:35<00:53, 14.51it/s]\n",
      " 61%|██████▏   | 1229/2000 [01:35<00:53, 14.52it/s]\n",
      " 62%|██████▏   | 1231/2000 [01:35<00:51, 14.86it/s]\n",
      " 62%|██████▏   | 1233/2000 [01:35<00:52, 14.68it/s]\n",
      " 62%|██████▏   | 1235/2000 [01:35<00:52, 14.50it/s]\n",
      " 62%|██████▏   | 1237/2000 [01:35<00:52, 14.44it/s]\n",
      " 62%|██████▏   | 1239/2000 [01:35<00:53, 14.33it/s]\n",
      " 62%|██████▏   | 1241/2000 [01:36<00:52, 14.38it/s]\n",
      " 62%|██████▏   | 1243/2000 [01:36<00:52, 14.48it/s]\n",
      " 62%|██████▏   | 1245/2000 [01:36<00:52, 14.34it/s]\n",
      " 62%|██████▏   | 1247/2000 [01:36<00:52, 14.37it/s]\n",
      " 62%|██████▏   | 1249/2000 [01:36<00:51, 14.65it/s]\n",
      "                                                   \n",
      "\n",
      " 62%|██████▎   | 1250/2000 [01:36<00:51, 14.65it/s]\n",
      " 63%|██████▎   | 1251/2000 [01:36<00:51, 14.45it/s]\n",
      " 63%|██████▎   | 1253/2000 [01:36<00:51, 14.52it/s]\n",
      " 63%|██████▎   | 1255/2000 [01:36<00:51, 14.52it/s]\n",
      " 63%|██████▎   | 1257/2000 [01:37<00:51, 14.51it/s]\n",
      " 63%|██████▎   | 1259/2000 [01:37<00:50, 14.75it/s]\n",
      " 63%|██████▎   | 1261/2000 [01:37<00:50, 14.71it/s]\n",
      " 63%|██████▎   | 1263/2000 [01:37<00:50, 14.65it/s]\n",
      " 63%|██████▎   | 1265/2000 [01:37<00:48, 15.03it/s]\n",
      " 63%|██████▎   | 1267/2000 [01:37<00:49, 14.69it/s]\n",
      " 63%|██████▎   | 1269/2000 [01:37<00:49, 14.70it/s]\n",
      " 64%|██████▎   | 1271/2000 [01:38<00:48, 14.97it/s]\n",
      " 64%|██████▎   | 1273/2000 [01:38<00:48, 14.89it/s]\n",
      " 64%|██████▍   | 1275/2000 [01:38<00:49, 14.76it/s]\n",
      " 64%|██████▍   | 1277/2000 [01:38<00:49, 14.63it/s]\n",
      " 64%|██████▍   | 1279/2000 [01:38<00:49, 14.49it/s]\n",
      " 64%|██████▍   | 1281/2000 [01:38<00:48, 14.74it/s]\n",
      " 64%|██████▍   | 1283/2000 [01:38<00:48, 14.64it/s]\n",
      " 64%|██████▍   | 1285/2000 [01:39<00:49, 14.53it/s]\n",
      " 64%|██████▍   | 1287/2000 [01:39<00:49, 14.51it/s]\n",
      " 64%|██████▍   | 1289/2000 [01:39<00:48, 14.74it/s]\n",
      " 65%|██████▍   | 1291/2000 [01:39<00:48, 14.63it/s]\n",
      " 65%|██████▍   | 1293/2000 [01:39<00:48, 14.53it/s]\n",
      " 65%|██████▍   | 1295/2000 [01:39<00:48, 14.51it/s]\n",
      " 65%|██████▍   | 1297/2000 [01:39<00:49, 14.12it/s]\n",
      " 65%|██████▍   | 1299/2000 [01:40<00:49, 14.10it/s]\n",
      "                                                   \n",
      "\n",
      " 65%|██████▌   | 1300/2000 [01:40<00:49, 14.10it/s]\n",
      " 65%|██████▌   | 1301/2000 [01:40<00:48, 14.48it/s]\n",
      " 65%|██████▌   | 1303/2000 [01:40<00:48, 14.35it/s]\n",
      " 65%|██████▌   | 1305/2000 [01:40<00:48, 14.25it/s]\n",
      " 65%|██████▌   | 1307/2000 [01:40<00:48, 14.32it/s]\n",
      " 65%|██████▌   | 1309/2000 [01:40<00:47, 14.63it/s]\n",
      " 66%|██████▌   | 1311/2000 [01:40<00:47, 14.56it/s]\n",
      " 66%|██████▌   | 1313/2000 [01:40<00:47, 14.48it/s]\n",
      " 66%|██████▌   | 1315/2000 [01:41<00:46, 14.87it/s]\n",
      " 66%|██████▌   | 1317/2000 [01:41<00:46, 14.58it/s]\n",
      " 66%|██████▌   | 1319/2000 [01:41<00:46, 14.50it/s]\n",
      " 66%|██████▌   | 1321/2000 [01:41<00:48, 14.03it/s]\n",
      " 66%|██████▌   | 1323/2000 [01:41<00:47, 14.11it/s]\n",
      " 66%|██████▋   | 1325/2000 [01:41<00:46, 14.38it/s]\n",
      " 66%|██████▋   | 1327/2000 [01:41<00:46, 14.40it/s]\n",
      " 66%|██████▋   | 1329/2000 [01:42<00:46, 14.43it/s]\n",
      " 67%|██████▋   | 1331/2000 [01:42<00:46, 14.43it/s]\n",
      " 67%|██████▋   | 1333/2000 [01:42<00:45, 14.63it/s]\n",
      " 67%|██████▋   | 1335/2000 [01:42<00:45, 14.50it/s]\n",
      " 67%|██████▋   | 1337/2000 [01:42<00:45, 14.47it/s]\n",
      " 67%|██████▋   | 1339/2000 [01:42<00:45, 14.48it/s]\n",
      " 67%|██████▋   | 1341/2000 [01:42<00:45, 14.52it/s]\n",
      " 67%|██████▋   | 1343/2000 [01:43<00:44, 14.68it/s]\n",
      " 67%|██████▋   | 1345/2000 [01:43<00:44, 14.70it/s]\n",
      " 67%|██████▋   | 1347/2000 [01:43<00:44, 14.60it/s]\n",
      " 67%|██████▋   | 1349/2000 [01:43<00:44, 14.50it/s]\n",
      "                                                   \n",
      "\n",
      " 68%|██████▊   | 1350/2000 [01:43<00:44, 14.50it/s]\n",
      " 68%|██████▊   | 1351/2000 [01:43<00:45, 14.39it/s]\n",
      " 68%|██████▊   | 1353/2000 [01:43<00:45, 14.20it/s]\n",
      " 68%|██████▊   | 1355/2000 [01:43<00:45, 14.28it/s]\n",
      " 68%|██████▊   | 1357/2000 [01:44<00:44, 14.36it/s]\n",
      " 68%|██████▊   | 1359/2000 [01:44<00:44, 14.29it/s]\n",
      " 68%|██████▊   | 1361/2000 [01:44<00:44, 14.30it/s]\n",
      " 68%|██████▊   | 1363/2000 [01:44<00:43, 14.70it/s]\n",
      " 68%|██████▊   | 1365/2000 [01:44<00:43, 14.58it/s]\n",
      " 68%|██████▊   | 1367/2000 [01:44<00:43, 14.49it/s]\n",
      " 68%|██████▊   | 1369/2000 [01:44<00:43, 14.45it/s]\n",
      " 69%|██████▊   | 1371/2000 [01:44<00:43, 14.34it/s]\n",
      " 69%|██████▊   | 1373/2000 [01:45<00:42, 14.64it/s]\n",
      " 69%|██████▉   | 1375/2000 [01:45<00:43, 14.35it/s]\n",
      " 69%|██████▉   | 1377/2000 [01:45<00:43, 14.31it/s]\n",
      " 69%|██████▉   | 1379/2000 [01:45<00:43, 14.27it/s]\n",
      " 69%|██████▉   | 1381/2000 [01:45<00:43, 14.28it/s]\n",
      " 69%|██████▉   | 1383/2000 [01:45<00:43, 14.25it/s]\n",
      " 69%|██████▉   | 1385/2000 [01:45<00:43, 14.19it/s]\n",
      " 69%|██████▉   | 1387/2000 [01:46<00:43, 14.23it/s]\n",
      " 69%|██████▉   | 1389/2000 [01:46<00:42, 14.38it/s]\n",
      " 70%|██████▉   | 1391/2000 [01:46<00:42, 14.38it/s]\n",
      " 70%|██████▉   | 1393/2000 [01:46<00:42, 14.34it/s]\n",
      " 70%|██████▉   | 1395/2000 [01:46<00:42, 14.40it/s]\n",
      " 70%|██████▉   | 1397/2000 [01:46<00:42, 14.27it/s]\n",
      " 70%|██████▉   | 1399/2000 [01:46<00:40, 14.69it/s]\n",
      "                                                   \n",
      "\n",
      " 70%|███████   | 1400/2000 [01:46<00:40, 14.69it/s]\n",
      " 70%|███████   | 1401/2000 [01:47<00:41, 14.49it/s]\n",
      " 70%|███████   | 1403/2000 [01:47<00:40, 14.65it/s]\n",
      " 70%|███████   | 1405/2000 [01:47<00:40, 14.56it/s]\n",
      " 70%|███████   | 1407/2000 [01:47<00:40, 14.80it/s]\n",
      " 70%|███████   | 1409/2000 [01:47<00:40, 14.67it/s]\n",
      " 71%|███████   | 1411/2000 [01:47<00:40, 14.55it/s]\n",
      " 71%|███████   | 1413/2000 [01:47<00:39, 14.96it/s]\n",
      " 71%|███████   | 1415/2000 [01:48<00:40, 14.60it/s]\n",
      " 71%|███████   | 1417/2000 [01:48<00:40, 14.51it/s]\n",
      " 71%|███████   | 1419/2000 [01:48<00:40, 14.51it/s]\n",
      " 71%|███████   | 1421/2000 [01:48<00:41, 14.01it/s]\n",
      " 71%|███████   | 1423/2000 [01:48<00:42, 13.68it/s]\n",
      " 71%|███████▏  | 1425/2000 [01:48<00:41, 13.86it/s]\n",
      " 71%|███████▏  | 1427/2000 [01:48<00:42, 13.55it/s]\n",
      " 71%|███████▏  | 1429/2000 [01:49<00:41, 13.73it/s]\n",
      " 72%|███████▏  | 1431/2000 [01:49<00:41, 13.86it/s]\n",
      " 72%|███████▏  | 1433/2000 [01:49<00:40, 14.03it/s]\n",
      " 72%|███████▏  | 1435/2000 [01:49<00:40, 14.08it/s]\n",
      " 72%|███████▏  | 1437/2000 [01:49<00:39, 14.20it/s]\n",
      " 72%|███████▏  | 1439/2000 [01:49<00:39, 14.26it/s]\n",
      " 72%|███████▏  | 1441/2000 [01:49<00:39, 14.24it/s]\n",
      " 72%|███████▏  | 1443/2000 [01:50<00:39, 14.08it/s]\n",
      " 72%|███████▏  | 1445/2000 [01:50<00:38, 14.28it/s]\n",
      " 72%|███████▏  | 1447/2000 [01:50<00:39, 14.16it/s]\n",
      " 72%|███████▏  | 1449/2000 [01:50<00:38, 14.20it/s]\n",
      "                                                   \n",
      "\n",
      " 72%|███████▎  | 1450/2000 [01:50<00:38, 14.20it/s]\n",
      " 73%|███████▎  | 1451/2000 [01:50<00:38, 14.36it/s]\n",
      " 73%|███████▎  | 1453/2000 [01:50<00:38, 14.06it/s]\n",
      " 73%|███████▎  | 1455/2000 [01:50<00:38, 14.16it/s]\n",
      " 73%|███████▎  | 1457/2000 [01:51<00:39, 13.73it/s]\n",
      " 73%|███████▎  | 1459/2000 [01:51<00:39, 13.84it/s]\n",
      " 73%|███████▎  | 1461/2000 [01:51<00:37, 14.32it/s]\n",
      " 73%|███████▎  | 1463/2000 [01:51<00:37, 14.21it/s]\n",
      " 73%|███████▎  | 1465/2000 [01:51<00:37, 14.30it/s]\n",
      " 73%|███████▎  | 1467/2000 [01:51<00:37, 14.26it/s]\n",
      " 73%|███████▎  | 1469/2000 [01:51<00:37, 14.18it/s]\n",
      " 74%|███████▎  | 1471/2000 [01:51<00:37, 14.25it/s]\n",
      " 74%|███████▎  | 1473/2000 [01:52<00:36, 14.52it/s]\n",
      " 74%|███████▍  | 1475/2000 [01:52<00:36, 14.50it/s]\n",
      " 74%|███████▍  | 1477/2000 [01:52<00:36, 14.42it/s]\n",
      " 74%|███████▍  | 1479/2000 [01:52<00:36, 14.43it/s]\n",
      " 74%|███████▍  | 1481/2000 [01:52<00:35, 14.46it/s]\n",
      " 74%|███████▍  | 1483/2000 [01:52<00:35, 14.56it/s]\n",
      " 74%|███████▍  | 1485/2000 [01:52<00:35, 14.52it/s]\n",
      " 74%|███████▍  | 1487/2000 [01:53<00:35, 14.42it/s]\n",
      " 74%|███████▍  | 1489/2000 [01:53<00:35, 14.47it/s]\n",
      " 75%|███████▍  | 1491/2000 [01:53<00:36, 13.96it/s]\n",
      " 75%|███████▍  | 1493/2000 [01:53<00:36, 13.97it/s]\n",
      " 75%|███████▍  | 1495/2000 [01:53<00:35, 14.12it/s]\n",
      " 75%|███████▍  | 1497/2000 [01:53<00:35, 14.22it/s]\n",
      " 75%|███████▍  | 1499/2000 [01:53<00:35, 14.27it/s]\n",
      "                                                   \n",
      "\n",
      " 75%|███████▌  | 1500/2000 [01:54<00:35, 14.27it/s]\n",
      " 75%|███████▌  | 1501/2000 [01:54<00:35, 14.21it/s]\n",
      " 75%|███████▌  | 1503/2000 [01:54<00:36, 13.74it/s]\n",
      " 75%|███████▌  | 1505/2000 [01:54<00:35, 13.80it/s]\n",
      " 75%|███████▌  | 1507/2000 [01:54<00:35, 13.95it/s]\n",
      " 75%|███████▌  | 1509/2000 [01:54<00:35, 13.95it/s]\n",
      " 76%|███████▌  | 1511/2000 [01:54<00:35, 13.97it/s]\n",
      " 76%|███████▌  | 1513/2000 [01:54<00:34, 14.07it/s]\n",
      " 76%|███████▌  | 1515/2000 [01:55<00:34, 14.02it/s]\n",
      " 76%|███████▌  | 1517/2000 [01:55<00:34, 13.81it/s]\n",
      " 76%|███████▌  | 1519/2000 [01:55<00:33, 14.30it/s]\n",
      " 76%|███████▌  | 1521/2000 [01:55<00:33, 14.37it/s]\n",
      " 76%|███████▌  | 1523/2000 [01:55<00:33, 14.43it/s]\n",
      " 76%|███████▋  | 1525/2000 [01:55<00:33, 14.29it/s]\n",
      " 76%|███████▋  | 1527/2000 [01:55<00:34, 13.89it/s]\n",
      " 76%|███████▋  | 1529/2000 [01:56<00:33, 14.05it/s]\n",
      " 77%|███████▋  | 1531/2000 [01:56<00:33, 14.14it/s]\n",
      " 77%|███████▋  | 1533/2000 [01:56<00:32, 14.22it/s]\n",
      " 77%|███████▋  | 1535/2000 [01:56<00:32, 14.49it/s]\n",
      " 77%|███████▋  | 1537/2000 [01:56<00:32, 14.40it/s]\n",
      " 77%|███████▋  | 1539/2000 [01:56<00:31, 14.56it/s]\n",
      " 77%|███████▋  | 1541/2000 [01:56<00:32, 14.32it/s]\n",
      " 77%|███████▋  | 1543/2000 [01:57<00:31, 14.35it/s]\n",
      " 77%|███████▋  | 1545/2000 [01:57<00:31, 14.40it/s]\n",
      " 77%|███████▋  | 1547/2000 [01:57<00:32, 13.95it/s]\n",
      " 77%|███████▋  | 1549/2000 [01:57<00:32, 13.88it/s]\n",
      "                                                   \n",
      "\n",
      " 78%|███████▊  | 1550/2000 [01:57<00:32, 13.88it/s]\n",
      " 78%|███████▊  | 1551/2000 [01:57<00:31, 14.04it/s]\n",
      " 78%|███████▊  | 1553/2000 [01:57<00:31, 14.10it/s]\n",
      " 78%|███████▊  | 1555/2000 [01:57<00:31, 14.20it/s]\n",
      " 78%|███████▊  | 1557/2000 [01:58<00:32, 13.53it/s]\n",
      " 78%|███████▊  | 1559/2000 [01:58<00:32, 13.54it/s]\n",
      " 78%|███████▊  | 1561/2000 [01:58<00:32, 13.70it/s]\n",
      " 78%|███████▊  | 1563/2000 [01:58<00:31, 13.71it/s]\n",
      " 78%|███████▊  | 1565/2000 [01:58<00:31, 13.93it/s]\n",
      " 78%|███████▊  | 1567/2000 [01:58<00:30, 13.99it/s]\n",
      " 78%|███████▊  | 1569/2000 [01:58<00:30, 14.14it/s]\n",
      " 79%|███████▊  | 1571/2000 [01:59<00:30, 14.29it/s]\n",
      " 79%|███████▊  | 1573/2000 [01:59<00:30, 14.21it/s]\n",
      " 79%|███████▉  | 1575/2000 [01:59<00:29, 14.34it/s]\n",
      " 79%|███████▉  | 1577/2000 [01:59<00:29, 14.32it/s]\n",
      " 79%|███████▉  | 1579/2000 [01:59<00:29, 14.33it/s]\n",
      " 79%|███████▉  | 1581/2000 [01:59<00:28, 14.62it/s]\n",
      " 79%|███████▉  | 1583/2000 [01:59<00:28, 14.53it/s]\n",
      " 79%|███████▉  | 1585/2000 [02:00<00:28, 14.58it/s]\n",
      " 79%|███████▉  | 1587/2000 [02:00<00:27, 14.87it/s]\n",
      " 79%|███████▉  | 1589/2000 [02:00<00:28, 14.55it/s]\n",
      " 80%|███████▉  | 1591/2000 [02:00<00:27, 14.65it/s]\n",
      " 80%|███████▉  | 1593/2000 [02:00<00:28, 14.51it/s]\n",
      " 80%|███████▉  | 1595/2000 [02:00<00:28, 14.44it/s]\n",
      " 80%|███████▉  | 1597/2000 [02:00<00:27, 14.42it/s]\n",
      " 80%|███████▉  | 1599/2000 [02:00<00:28, 14.30it/s]\n",
      "                                                   \n",
      "\n",
      " 80%|████████  | 1600/2000 [02:01<00:27, 14.30it/s]\n",
      " 80%|████████  | 1601/2000 [02:01<00:28, 13.91it/s]\n",
      " 80%|████████  | 1603/2000 [02:01<00:27, 14.45it/s]\n",
      " 80%|████████  | 1605/2000 [02:01<00:27, 14.36it/s]\n",
      " 80%|████████  | 1607/2000 [02:01<00:27, 14.39it/s]\n",
      " 80%|████████  | 1609/2000 [02:01<00:27, 14.30it/s]\n",
      " 81%|████████  | 1611/2000 [02:01<00:27, 14.37it/s]\n",
      " 81%|████████  | 1613/2000 [02:01<00:27, 14.31it/s]\n",
      " 81%|████████  | 1615/2000 [02:02<00:27, 14.24it/s]\n",
      " 81%|████████  | 1617/2000 [02:02<00:26, 14.35it/s]\n",
      " 81%|████████  | 1619/2000 [02:02<00:26, 14.60it/s]\n",
      " 81%|████████  | 1621/2000 [02:02<00:26, 14.23it/s]\n",
      " 81%|████████  | 1623/2000 [02:02<00:25, 14.54it/s]\n",
      " 81%|████████▏ | 1625/2000 [02:02<00:25, 14.46it/s]\n",
      " 81%|████████▏ | 1627/2000 [02:02<00:26, 14.05it/s]\n",
      " 81%|████████▏ | 1629/2000 [02:03<00:26, 14.14it/s]\n",
      " 82%|████████▏ | 1631/2000 [02:03<00:25, 14.40it/s]\n",
      " 82%|████████▏ | 1633/2000 [02:03<00:25, 14.49it/s]\n",
      " 82%|████████▏ | 1635/2000 [02:03<00:25, 14.49it/s]\n",
      " 82%|████████▏ | 1637/2000 [02:03<00:24, 14.81it/s]\n",
      " 82%|████████▏ | 1639/2000 [02:03<00:25, 14.24it/s]\n",
      " 82%|████████▏ | 1641/2000 [02:03<00:25, 14.14it/s]\n",
      " 82%|████████▏ | 1643/2000 [02:04<00:25, 14.22it/s]\n",
      " 82%|████████▏ | 1645/2000 [02:04<00:24, 14.28it/s]\n",
      " 82%|████████▏ | 1647/2000 [02:04<00:24, 14.22it/s]\n",
      " 82%|████████▏ | 1649/2000 [02:04<00:23, 14.66it/s]\n",
      "                                                   \n",
      "\n",
      " 82%|████████▎ | 1650/2000 [02:04<00:23, 14.66it/s]\n",
      " 83%|████████▎ | 1651/2000 [02:04<00:23, 14.54it/s]\n",
      " 83%|████████▎ | 1653/2000 [02:04<00:23, 14.52it/s]\n",
      " 83%|████████▎ | 1655/2000 [02:04<00:23, 14.73it/s]\n",
      " 83%|████████▎ | 1657/2000 [02:05<00:23, 14.61it/s]\n",
      " 83%|████████▎ | 1659/2000 [02:05<00:24, 14.05it/s]\n",
      " 83%|████████▎ | 1661/2000 [02:05<00:24, 14.09it/s]\n",
      " 83%|████████▎ | 1663/2000 [02:05<00:23, 14.23it/s]\n",
      " 83%|████████▎ | 1665/2000 [02:05<00:23, 14.25it/s]\n",
      " 83%|████████▎ | 1667/2000 [02:05<00:23, 14.20it/s]\n",
      " 83%|████████▎ | 1669/2000 [02:05<00:23, 14.30it/s]\n",
      " 84%|████████▎ | 1671/2000 [02:06<00:22, 14.75it/s]\n",
      " 84%|████████▎ | 1673/2000 [02:06<00:23, 14.12it/s]\n",
      " 84%|████████▍ | 1675/2000 [02:06<00:22, 14.24it/s]\n",
      " 84%|████████▍ | 1677/2000 [02:06<00:22, 14.54it/s]\n",
      " 84%|████████▍ | 1679/2000 [02:06<00:23, 13.94it/s]\n",
      " 84%|████████▍ | 1681/2000 [02:06<00:22, 14.12it/s]\n",
      " 84%|████████▍ | 1683/2000 [02:06<00:22, 14.17it/s]\n",
      " 84%|████████▍ | 1685/2000 [02:07<00:22, 14.09it/s]\n",
      " 84%|████████▍ | 1687/2000 [02:07<00:22, 14.21it/s]\n",
      " 84%|████████▍ | 1689/2000 [02:07<00:21, 14.24it/s]\n",
      " 85%|████████▍ | 1691/2000 [02:07<00:21, 14.56it/s]\n",
      " 85%|████████▍ | 1693/2000 [02:07<00:21, 14.54it/s]\n",
      " 85%|████████▍ | 1695/2000 [02:07<00:21, 14.39it/s]\n",
      " 85%|████████▍ | 1697/2000 [02:07<00:20, 14.91it/s]\n",
      " 85%|████████▍ | 1699/2000 [02:07<00:20, 14.82it/s]\n",
      "                                                   \n",
      "\n",
      " 85%|████████▌ | 1700/2000 [02:08<00:20, 14.82it/s]\n",
      " 85%|████████▌ | 1701/2000 [02:08<00:20, 14.50it/s]\n",
      " 85%|████████▌ | 1703/2000 [02:08<00:20, 14.49it/s]\n",
      " 85%|████████▌ | 1705/2000 [02:08<00:20, 14.41it/s]\n",
      " 85%|████████▌ | 1707/2000 [02:08<00:20, 14.43it/s]\n",
      " 85%|████████▌ | 1709/2000 [02:08<00:19, 14.71it/s]\n",
      " 86%|████████▌ | 1711/2000 [02:08<00:20, 14.14it/s]\n",
      " 86%|████████▌ | 1713/2000 [02:08<00:20, 14.27it/s]\n",
      " 86%|████████▌ | 1715/2000 [02:09<00:19, 14.29it/s]\n",
      " 86%|████████▌ | 1717/2000 [02:09<00:19, 14.27it/s]\n",
      " 86%|████████▌ | 1719/2000 [02:09<00:19, 14.19it/s]\n",
      " 86%|████████▌ | 1721/2000 [02:09<00:19, 14.27it/s]\n",
      " 86%|████████▌ | 1723/2000 [02:09<00:19, 14.22it/s]\n",
      " 86%|████████▋ | 1725/2000 [02:09<00:19, 14.27it/s]\n",
      " 86%|████████▋ | 1727/2000 [02:09<00:18, 14.58it/s]\n",
      " 86%|████████▋ | 1729/2000 [02:10<00:18, 14.49it/s]\n",
      " 87%|████████▋ | 1731/2000 [02:10<00:19, 13.95it/s]\n",
      " 87%|████████▋ | 1733/2000 [02:10<00:19, 13.99it/s]\n",
      " 87%|████████▋ | 1735/2000 [02:10<00:18, 14.10it/s]\n",
      " 87%|████████▋ | 1737/2000 [02:10<00:18, 14.04it/s]\n",
      " 87%|████████▋ | 1739/2000 [02:10<00:18, 14.15it/s]\n",
      " 87%|████████▋ | 1741/2000 [02:10<00:18, 14.15it/s]\n",
      " 87%|████████▋ | 1743/2000 [02:11<00:18, 14.26it/s]\n",
      " 87%|████████▋ | 1745/2000 [02:11<00:17, 14.60it/s]\n",
      " 87%|████████▋ | 1747/2000 [02:11<00:17, 14.11it/s]\n",
      " 87%|████████▋ | 1749/2000 [02:11<00:17, 14.20it/s]\n",
      "                                                   \n",
      "\n",
      " 88%|████████▊ | 1750/2000 [02:11<00:17, 14.20it/s]\n",
      " 88%|████████▊ | 1751/2000 [02:11<00:17, 14.23it/s]\n",
      " 88%|████████▊ | 1753/2000 [02:11<00:17, 14.24it/s]\n",
      " 88%|████████▊ | 1755/2000 [02:11<00:17, 14.27it/s]\n",
      " 88%|████████▊ | 1757/2000 [02:12<00:16, 14.34it/s]\n",
      " 88%|████████▊ | 1759/2000 [02:12<00:16, 14.70it/s]\n",
      " 88%|████████▊ | 1761/2000 [02:12<00:16, 14.55it/s]\n",
      " 88%|████████▊ | 1763/2000 [02:12<00:16, 14.54it/s]\n",
      " 88%|████████▊ | 1765/2000 [02:12<00:16, 14.46it/s]\n",
      " 88%|████████▊ | 1767/2000 [02:12<00:16, 14.44it/s]\n",
      " 88%|████████▊ | 1769/2000 [02:12<00:15, 14.46it/s]\n",
      " 89%|████████▊ | 1771/2000 [02:12<00:15, 14.61it/s]\n",
      " 89%|████████▊ | 1773/2000 [02:13<00:15, 14.47it/s]\n",
      " 89%|████████▉ | 1775/2000 [02:13<00:15, 14.46it/s]\n",
      " 89%|████████▉ | 1777/2000 [02:13<00:15, 13.98it/s]\n",
      " 89%|████████▉ | 1779/2000 [02:13<00:15, 14.02it/s]\n",
      " 89%|████████▉ | 1781/2000 [02:13<00:15, 14.09it/s]\n",
      " 89%|████████▉ | 1783/2000 [02:13<00:15, 14.21it/s]\n",
      " 89%|████████▉ | 1785/2000 [02:13<00:14, 14.56it/s]\n",
      " 89%|████████▉ | 1787/2000 [02:14<00:14, 14.51it/s]\n",
      " 89%|████████▉ | 1789/2000 [02:14<00:14, 14.45it/s]\n",
      " 90%|████████▉ | 1791/2000 [02:14<00:14, 14.48it/s]\n",
      " 90%|████████▉ | 1793/2000 [02:14<00:13, 14.90it/s]\n",
      " 90%|████████▉ | 1795/2000 [02:14<00:14, 14.25it/s]\n",
      " 90%|████████▉ | 1797/2000 [02:14<00:14, 14.15it/s]\n",
      " 90%|████████▉ | 1799/2000 [02:14<00:14, 14.21it/s]\n",
      "                                                   \n",
      "\n",
      " 90%|█████████ | 1800/2000 [02:15<00:14, 14.21it/s]\n",
      " 90%|█████████ | 1801/2000 [02:15<00:14, 14.16it/s]\n",
      " 90%|█████████ | 1803/2000 [02:15<00:13, 14.29it/s]\n",
      " 90%|█████████ | 1805/2000 [02:15<00:13, 14.22it/s]\n",
      " 90%|█████████ | 1807/2000 [02:15<00:13, 14.57it/s]\n",
      " 90%|█████████ | 1809/2000 [02:15<00:13, 14.47it/s]\n",
      " 91%|█████████ | 1811/2000 [02:15<00:13, 14.53it/s]\n",
      " 91%|█████████ | 1813/2000 [02:15<00:12, 14.69it/s]\n",
      " 91%|█████████ | 1815/2000 [02:16<00:12, 14.38it/s]\n",
      " 91%|█████████ | 1817/2000 [02:16<00:12, 14.19it/s]\n",
      " 91%|█████████ | 1819/2000 [02:16<00:12, 14.33it/s]\n",
      " 91%|█████████ | 1821/2000 [02:16<00:12, 14.43it/s]\n",
      " 91%|█████████ | 1823/2000 [02:16<00:12, 14.22it/s]\n",
      " 91%|█████████▏| 1825/2000 [02:16<00:12, 14.32it/s]\n",
      " 91%|█████████▏| 1827/2000 [02:16<00:12, 14.38it/s]\n",
      " 91%|█████████▏| 1829/2000 [02:17<00:11, 14.62it/s]\n",
      " 92%|█████████▏| 1831/2000 [02:17<00:11, 14.61it/s]\n",
      " 92%|█████████▏| 1833/2000 [02:17<00:11, 14.84it/s]\n",
      " 92%|█████████▏| 1835/2000 [02:17<00:11, 14.37it/s]\n",
      " 92%|█████████▏| 1837/2000 [02:17<00:11, 14.32it/s]\n",
      " 92%|█████████▏| 1839/2000 [02:17<00:11, 13.87it/s]\n",
      " 92%|█████████▏| 1841/2000 [02:17<00:11, 14.25it/s]\n",
      " 92%|█████████▏| 1843/2000 [02:18<00:10, 14.30it/s]\n",
      " 92%|█████████▏| 1845/2000 [02:18<00:10, 14.33it/s]\n",
      " 92%|█████████▏| 1847/2000 [02:18<00:10, 14.25it/s]\n",
      " 92%|█████████▏| 1849/2000 [02:18<00:10, 14.28it/s]\n",
      "                                                   \n",
      "\n",
      " 92%|█████████▎| 1850/2000 [02:18<00:10, 14.28it/s]\n",
      " 93%|█████████▎| 1851/2000 [02:18<00:10, 14.29it/s]\n",
      " 93%|█████████▎| 1853/2000 [02:18<00:10, 14.21it/s]\n",
      " 93%|█████████▎| 1855/2000 [02:18<00:10, 14.23it/s]\n",
      " 93%|█████████▎| 1857/2000 [02:18<00:10, 14.27it/s]\n",
      " 93%|█████████▎| 1859/2000 [02:19<00:09, 14.29it/s]\n",
      " 93%|█████████▎| 1861/2000 [02:19<00:09, 14.34it/s]\n",
      " 93%|█████████▎| 1863/2000 [02:19<00:09, 14.31it/s]\n",
      " 93%|█████████▎| 1865/2000 [02:19<00:09, 14.78it/s]\n",
      " 93%|█████████▎| 1867/2000 [02:19<00:09, 14.57it/s]\n",
      " 93%|█████████▎| 1869/2000 [02:19<00:09, 14.41it/s]\n",
      " 94%|█████████▎| 1871/2000 [02:19<00:09, 14.14it/s]\n",
      " 94%|█████████▎| 1873/2000 [02:20<00:08, 14.46it/s]\n",
      " 94%|█████████▍| 1875/2000 [02:20<00:08, 14.53it/s]\n",
      " 94%|█████████▍| 1877/2000 [02:20<00:08, 14.37it/s]\n",
      " 94%|█████████▍| 1879/2000 [02:20<00:08, 14.42it/s]\n",
      " 94%|█████████▍| 1881/2000 [02:20<00:08, 14.74it/s]\n",
      " 94%|█████████▍| 1883/2000 [02:20<00:07, 14.63it/s]\n",
      " 94%|█████████▍| 1885/2000 [02:20<00:07, 14.44it/s]\n",
      " 94%|█████████▍| 1887/2000 [02:21<00:07, 14.47it/s]\n",
      " 94%|█████████▍| 1889/2000 [02:21<00:07, 14.31it/s]\n",
      " 95%|█████████▍| 1891/2000 [02:21<00:07, 14.31it/s]\n",
      " 95%|█████████▍| 1893/2000 [02:21<00:07, 13.87it/s]\n",
      " 95%|█████████▍| 1895/2000 [02:21<00:07, 14.10it/s]\n",
      " 95%|█████████▍| 1897/2000 [02:21<00:07, 14.41it/s]\n",
      " 95%|█████████▍| 1899/2000 [02:21<00:06, 14.44it/s]\n",
      "                                                   \n",
      "\n",
      " 95%|█████████▌| 1900/2000 [02:21<00:06, 14.44it/s]\n",
      " 95%|█████████▌| 1901/2000 [02:22<00:06, 14.41it/s]\n",
      " 95%|█████████▌| 1903/2000 [02:22<00:06, 14.73it/s]\n",
      " 95%|█████████▌| 1905/2000 [02:22<00:06, 14.74it/s]\n",
      " 95%|█████████▌| 1907/2000 [02:22<00:06, 14.54it/s]\n",
      " 95%|█████████▌| 1909/2000 [02:22<00:06, 14.93it/s]\n",
      " 96%|█████████▌| 1911/2000 [02:22<00:06, 14.59it/s]\n",
      " 96%|█████████▌| 1913/2000 [02:22<00:05, 14.67it/s]\n",
      " 96%|█████████▌| 1915/2000 [02:22<00:05, 14.41it/s]\n",
      " 96%|█████████▌| 1917/2000 [02:23<00:05, 14.69it/s]\n",
      " 96%|█████████▌| 1919/2000 [02:23<00:05, 14.61it/s]\n",
      " 96%|█████████▌| 1921/2000 [02:23<00:05, 14.97it/s]\n",
      " 96%|█████████▌| 1923/2000 [02:23<00:05, 14.71it/s]\n",
      " 96%|█████████▋| 1925/2000 [02:23<00:05, 14.61it/s]\n",
      " 96%|█████████▋| 1927/2000 [02:23<00:05, 14.51it/s]\n",
      " 96%|█████████▋| 1929/2000 [02:23<00:04, 14.52it/s]\n",
      " 97%|█████████▋| 1931/2000 [02:24<00:04, 14.43it/s]\n",
      " 97%|█████████▋| 1933/2000 [02:24<00:04, 14.45it/s]\n",
      " 97%|█████████▋| 1935/2000 [02:24<00:04, 14.66it/s]\n",
      " 97%|█████████▋| 1937/2000 [02:24<00:04, 14.58it/s]\n",
      " 97%|█████████▋| 1939/2000 [02:24<00:04, 14.60it/s]\n",
      " 97%|█████████▋| 1941/2000 [02:24<00:04, 14.48it/s]\n",
      " 97%|█████████▋| 1943/2000 [02:24<00:03, 14.37it/s]\n",
      " 97%|█████████▋| 1945/2000 [02:25<00:03, 14.32it/s]\n",
      " 97%|█████████▋| 1947/2000 [02:25<00:03, 14.22it/s]\n",
      " 97%|█████████▋| 1949/2000 [02:25<00:03, 14.19it/s]\n",
      "                                                   \n",
      "\n",
      " 98%|█████████▊| 1950/2000 [02:25<00:03, 14.19it/s]\n",
      " 98%|█████████▊| 1951/2000 [02:25<00:03, 13.87it/s]\n",
      " 98%|█████████▊| 1953/2000 [02:25<00:03, 14.04it/s]\n",
      " 98%|█████████▊| 1955/2000 [02:25<00:03, 14.11it/s]\n",
      " 98%|█████████▊| 1957/2000 [02:25<00:02, 14.37it/s]\n",
      " 98%|█████████▊| 1959/2000 [02:26<00:02, 14.41it/s]\n",
      " 98%|█████████▊| 1961/2000 [02:26<00:02, 14.34it/s]\n",
      " 98%|█████████▊| 1963/2000 [02:26<00:02, 14.42it/s]\n",
      " 98%|█████████▊| 1965/2000 [02:26<00:02, 14.43it/s]\n",
      " 98%|█████████▊| 1967/2000 [02:26<00:02, 14.40it/s]\n",
      " 98%|█████████▊| 1969/2000 [02:26<00:02, 14.74it/s]\n",
      " 99%|█████████▊| 1971/2000 [02:26<00:01, 14.62it/s]\n",
      " 99%|█████████▊| 1973/2000 [02:27<00:01, 14.51it/s]\n",
      " 99%|█████████▉| 1975/2000 [02:27<00:01, 14.36it/s]\n",
      " 99%|█████████▉| 1977/2000 [02:27<00:01, 14.42it/s]\n",
      " 99%|█████████▉| 1979/2000 [02:27<00:01, 14.40it/s]\n",
      " 99%|█████████▉| 1981/2000 [02:27<00:01, 14.89it/s]\n",
      " 99%|█████████▉| 1983/2000 [02:27<00:01, 14.60it/s]\n",
      " 99%|█████████▉| 1985/2000 [02:27<00:01, 14.55it/s]\n",
      " 99%|█████████▉| 1987/2000 [02:27<00:00, 14.56it/s]\n",
      " 99%|█████████▉| 1989/2000 [02:28<00:00, 14.46it/s]\n",
      "100%|█████████▉| 1991/2000 [02:28<00:00, 14.45it/s]\n",
      "100%|█████████▉| 1993/2000 [02:28<00:00, 14.34it/s]\n",
      "100%|█████████▉| 1995/2000 [02:28<00:00, 13.99it/s]\n",
      "100%|█████████▉| 1997/2000 [02:28<00:00, 14.01it/s]\n",
      "100%|█████████▉| 1999/2000 [02:28<00:00, 13.99it/s]\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [02:28<00:00, 13.99it/s][INFO|trainer.py:761] 2024-01-26 01:13:34,816 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:13:34,818 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:13:34,818 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:13:34,818 >>   Batch size = 8\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  3%|▎         | 8/250 [00:00<00:03, 74.00it/s]\u001b[A\n",
      "\n",
      "  6%|▋         | 16/250 [00:00<00:03, 69.71it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 23/250 [00:00<00:03, 69.06it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/250 [00:00<00:03, 69.06it/s]\u001b[A\n",
      "\n",
      " 15%|█▍        | 37/250 [00:00<00:03, 69.19it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 44/250 [00:00<00:02, 69.15it/s]\u001b[A\n",
      "\n",
      " 21%|██        | 52/250 [00:00<00:02, 69.31it/s]\u001b[A\n",
      "\n",
      " 24%|██▎       | 59/250 [00:00<00:02, 69.12it/s]\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:00<00:02, 69.11it/s]\u001b[A\n",
      "\n",
      " 30%|██▉       | 74/250 [00:01<00:02, 69.47it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 81/250 [00:01<00:02, 69.23it/s]\u001b[A\n",
      "\n",
      " 35%|███▌      | 88/250 [00:01<00:02, 69.02it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 96/250 [00:01<00:02, 69.26it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 104/250 [00:01<00:02, 69.43it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 111/250 [00:01<00:01, 69.53it/s]\u001b[A\n",
      "\n",
      " 48%|████▊     | 119/250 [00:01<00:01, 69.89it/s]\u001b[A\n",
      "\n",
      " 50%|█████     | 126/250 [00:01<00:01, 69.89it/s]\u001b[A\n",
      "\n",
      " 53%|█████▎    | 133/250 [00:01<00:01, 69.91it/s]\u001b[A\n",
      "\n",
      " 56%|█████▌    | 140/250 [00:02<00:01, 69.59it/s]\u001b[A\n",
      "\n",
      " 59%|█████▉    | 147/250 [00:02<00:01, 69.46it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 155/250 [00:02<00:01, 70.12it/s]\u001b[A\n",
      "\n",
      " 65%|██████▌   | 163/250 [00:02<00:01, 70.10it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 171/250 [00:02<00:01, 69.60it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 179/250 [00:02<00:01, 70.10it/s]\u001b[A\n",
      "\n",
      " 75%|███████▍  | 187/250 [00:02<00:00, 69.57it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:02<00:00, 69.29it/s]\u001b[A\n",
      "\n",
      " 80%|████████  | 201/250 [00:02<00:00, 64.96it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 208/250 [00:03<00:00, 66.14it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 215/250 [00:03<00:00, 66.87it/s]\u001b[A\n",
      "\n",
      " 89%|████████▉ | 222/250 [00:03<00:00, 67.39it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 229/250 [00:03<00:00, 67.67it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▍| 236/250 [00:03<00:00, 67.43it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 243/250 [00:03<00:00, 67.23it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 67.44it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      "100%|██████████| 2000/2000 [02:32<00:00, 13.99it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:03<00:00, 67.44it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:13:38,475 >> Saving model checkpoint to output/gpt2_modified_emotion\\checkpoint-2000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:13:38,476 >> Configuration saved in output/gpt2_modified_emotion\\checkpoint-2000\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:13:39,859 >> Model weights saved in output/gpt2_modified_emotion\\checkpoint-2000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:13:39,860 >> tokenizer config file saved in output/gpt2_modified_emotion\\checkpoint-2000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:13:39,860 >> Special tokens file saved in output/gpt2_modified_emotion\\checkpoint-2000\\special_tokens_map.json\n",
      "\n",
      "100%|██████████| 2000/2000 [02:40<00:00, 13.99it/s][INFO|trainer.py:2017] 2024-01-26 01:13:48,144 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2196] 2024-01-26 01:13:48,144 >> Loading best model from output/gpt2_modified_emotion\\checkpoint-2000 (score: 0.926).\n",
      "\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [02:42<00:00, 13.99it/s]\n",
      "100%|██████████| 2000/2000 [02:42<00:00, 12.29it/s]\n",
      "[INFO|trainer.py:2939] 2024-01-26 01:13:48,687 >> Saving model checkpoint to output/gpt2_modified_emotion\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:13:48,687 >> Configuration saved in output/gpt2_modified_emotion\\config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:13:55,508 >> Model weights saved in output/gpt2_modified_emotion\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:13:55,509 >> tokenizer config file saved in output/gpt2_modified_emotion\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:13:55,517 >> Special tokens file saved in output/gpt2_modified_emotion\\special_tokens_map.json\n",
      "[INFO|trainer.py:761] 2024-01-26 01:13:55,586 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassificationCustom.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassificationCustom.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:13:55,587 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:13:55,587 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:13:55,587 >>   Batch size = 8\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  3%|▎         | 8/250 [00:00<00:03, 71.56it/s]\n",
      "  6%|▋         | 16/250 [00:00<00:03, 67.62it/s]\n",
      "  9%|▉         | 23/250 [00:00<00:03, 67.76it/s]\n",
      " 12%|█▏        | 30/250 [00:00<00:03, 66.04it/s]\n",
      " 15%|█▍        | 37/250 [00:00<00:03, 65.48it/s]\n",
      " 18%|█▊        | 44/250 [00:00<00:03, 65.84it/s]\n",
      " 20%|██        | 51/250 [00:00<00:03, 66.08it/s]\n",
      " 23%|██▎       | 58/250 [00:00<00:02, 66.43it/s]\n",
      " 26%|██▌       | 65/250 [00:00<00:02, 67.11it/s]\n",
      " 29%|██▉       | 73/250 [00:01<00:02, 67.92it/s]\n",
      " 32%|███▏      | 80/250 [00:01<00:02, 68.16it/s]\n",
      " 35%|███▍      | 87/250 [00:01<00:02, 68.28it/s]\n",
      " 38%|███▊      | 94/250 [00:01<00:02, 63.28it/s]\n",
      " 40%|████      | 101/250 [00:01<00:02, 64.94it/s]\n",
      " 43%|████▎     | 108/250 [00:01<00:02, 65.91it/s]\n",
      " 46%|████▌     | 115/250 [00:01<00:02, 67.03it/s]\n",
      " 49%|████▉     | 122/250 [00:01<00:01, 67.33it/s]\n",
      " 52%|█████▏    | 129/250 [00:01<00:01, 67.41it/s]\n",
      " 54%|█████▍    | 136/250 [00:02<00:01, 67.62it/s]\n",
      " 57%|█████▋    | 143/250 [00:02<00:01, 67.19it/s]\n",
      " 60%|██████    | 150/250 [00:02<00:01, 66.97it/s]\n",
      " 63%|██████▎   | 157/250 [00:02<00:01, 67.78it/s]\n",
      " 66%|██████▌   | 164/250 [00:02<00:01, 68.01it/s]\n",
      " 68%|██████▊   | 171/250 [00:02<00:01, 66.35it/s]\n",
      " 71%|███████   | 178/250 [00:02<00:01, 66.85it/s]\n",
      " 74%|███████▍  | 185/250 [00:02<00:00, 67.18it/s]\n",
      " 77%|███████▋  | 192/250 [00:02<00:00, 67.34it/s]\n",
      " 80%|███████▉  | 199/250 [00:02<00:00, 68.06it/s]\n",
      " 82%|████████▏ | 206/250 [00:03<00:00, 67.67it/s]\n",
      " 85%|████████▌ | 213/250 [00:03<00:00, 67.85it/s]\n",
      " 88%|████████▊ | 220/250 [00:03<00:00, 67.47it/s]\n",
      " 91%|█████████ | 227/250 [00:03<00:00, 67.43it/s]\n",
      " 94%|█████████▎| 234/250 [00:03<00:00, 67.95it/s]\n",
      " 96%|█████████▋| 241/250 [00:03<00:00, 68.33it/s]\n",
      " 99%|█████████▉| 248/250 [00:03<00:00, 68.59it/s]\n",
      "100%|██████████| 250/250 [00:03<00:00, 67.13it/s]\n",
      "[INFO|modelcard.py:452] 2024-01-26 01:14:00,217 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.926}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "01/26/2024 01:11:01 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=1000,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/gpt2_modified_emotion\\runs\\Jan26_01-11-01_GIGA_PC,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=output/gpt2_modified_emotion,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/gpt2_modified_emotion,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=1000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/26/2024 01:11:01 - INFO - __main__ - load a local file for train: data/train.json\n",
      "01/26/2024 01:11:01 - INFO - __main__ - load a local file for validation: data/validation.json\n",
      "01/26/2024 01:11:02 - INFO - datasets.builder - Using custom data configuration default-019d6cd006d41b2b\n",
      "01/26/2024 01:11:02 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "01/26/2024 01:11:02 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "01/26/2024 01:11:02 - INFO - datasets.info - Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:11:02 - INFO - datasets.builder - Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/26/2024 01:11:02 - INFO - datasets.info - Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:11:03 - INFO - __main__ - Using hidden states in model: True\n",
      "01/26/2024 01:11:03 - INFO - __main__ - Using implementation from class: GPT2ForSequenceClassificationCustom\n",
      "01/26/2024 01:11:04 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
      "01/26/2024 01:11:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-fdce50f3e542d7aa.arrow\n",
      "01/26/2024 01:11:04 - INFO - datasets.arrow_dataset - Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-7a68591df3bd306e.arrow\n",
      "01/26/2024 01:11:04 - INFO - __main__ - Sample 10476 of the training set: {'text': 'i do find new friends i m going to try extra hard to make them stay and if i decide that i don t want to feel hurt again and just ride out the last year of school on my own i m going to have to try extra hard not to care what people think of me being a loner', 'label': 0, 'input_ids': [72, 466, 1064, 649, 2460, 1312, 285, 1016, 284, 1949, 3131, 1327, 284, 787, 606, 2652, 290, 611, 1312, 5409, 326, 1312, 836, 256, 765, 284, 1254, 5938, 757, 290, 655, 6594, 503, 262, 938, 614, 286, 1524, 319, 616, 898, 1312, 285, 1016, 284, 423, 284, 1949, 3131, 1327, 407, 284, 1337, 644, 661, 892, 286, 502, 852, 257, 300, 14491, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "01/26/2024 01:11:04 - INFO - __main__ - Sample 1824 of the training set: {'text': 'i asked them to join me in creating a world where all year old girls could grow up feeling hopeful and powerful', 'label': 1, 'input_ids': [72, 1965, 606, 284, 4654, 502, 287, 4441, 257, 995, 810, 477, 614, 1468, 4813, 714, 1663, 510, 4203, 17836, 290, 3665, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "01/26/2024 01:11:04 - INFO - __main__ - Sample 409 of the training set: {'text': 'i feel when you are a caring person you attract other caring people into your life', 'label': 2, 'input_ids': [72, 1254, 618, 345, 389, 257, 18088, 1048, 345, 4729, 584, 18088, 661, 656, 534, 1204, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "{'loss': 1.713, 'learning_rate': 1.95e-05, 'epoch': 0.03}\n",
      "{'loss': 1.5092, 'learning_rate': 1.9e-05, 'epoch': 0.05}\n",
      "{'loss': 1.6643, 'learning_rate': 1.8500000000000002e-05, 'epoch': 0.07}\n",
      "{'loss': 1.4667, 'learning_rate': 1.8e-05, 'epoch': 0.1}\n",
      "{'loss': 1.3171, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.12}\n",
      "{'loss': 1.0972, 'learning_rate': 1.7e-05, 'epoch': 0.15}\n",
      "{'loss': 1.1031, 'learning_rate': 1.65e-05, 'epoch': 0.17}\n",
      "{'loss': 0.9641, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "{'loss': 0.8993, 'learning_rate': 1.55e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8823, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.25}\n",
      "{'loss': 0.8086, 'learning_rate': 1.45e-05, 'epoch': 0.28}\n",
      "{'loss': 0.7394, 'learning_rate': 1.4e-05, 'epoch': 0.3}\n",
      "{'loss': 0.6044, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.642, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.35}\n",
      "{'loss': 0.5272, 'learning_rate': 1.25e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4399, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.5463, 'learning_rate': 1.15e-05, 'epoch': 0.42}\n",
      "{'loss': 0.5014, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3745, 'learning_rate': 1.0500000000000001e-05, 'epoch': 0.47}\n",
      "{'loss': 0.411, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'eval_loss': 0.36333397030830383, 'eval_accuracy': 0.8915, 'eval_runtime': 3.6942, 'eval_samples_per_second': 541.391, 'eval_steps_per_second': 67.674, 'epoch': 0.5}\n",
      "{'loss': 0.3802, 'learning_rate': 9.5e-06, 'epoch': 0.53}\n",
      "{'loss': 0.2897, 'learning_rate': 9e-06, 'epoch': 0.55}\n",
      "{'loss': 0.3727, 'learning_rate': 8.5e-06, 'epoch': 0.57}\n",
      "{'loss': 0.3752, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.6}\n",
      "{'loss': 0.4186, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 0.3179, 'learning_rate': 7e-06, 'epoch': 0.65}\n",
      "{'loss': 0.3444, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.68}\n",
      "{'loss': 0.3517, 'learning_rate': 6e-06, 'epoch': 0.7}\n",
      "{'loss': 0.3002, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 0.4484, 'learning_rate': 5e-06, 'epoch': 0.75}\n",
      "{'loss': 0.2433, 'learning_rate': 4.5e-06, 'epoch': 0.78}\n",
      "{'loss': 0.341, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 0.3102, 'learning_rate': 3.5e-06, 'epoch': 0.82}\n",
      "{'loss': 0.3587, 'learning_rate': 3e-06, 'epoch': 0.85}\n",
      "{'loss': 0.2972, 'learning_rate': 2.5e-06, 'epoch': 0.88}\n",
      "{'loss': 0.3155, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.9}\n",
      "{'loss': 0.3947, 'learning_rate': 1.5e-06, 'epoch': 0.93}\n",
      "{'loss': 0.283, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 0.2866, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.97}\n",
      "{'loss': 0.365, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'eval_loss': 0.24146635830402374, 'eval_accuracy': 0.926, 'eval_runtime': 3.6573, 'eval_samples_per_second': 546.856, 'eval_steps_per_second': 68.357, 'epoch': 1.0}\n",
      "{'train_runtime': 162.7728, 'train_samples_per_second': 98.297, 'train_steps_per_second': 12.287, 'train_loss': 0.625130208015442, 'epoch': 1.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     0.6251\n",
      "  train_runtime            = 0:02:42.77\n",
      "  train_samples            =      16000\n",
      "  train_samples_per_second =     98.297\n",
      "  train_steps_per_second   =     12.287\n",
      "01/26/2024 01:13:55 - INFO - __main__ - *** Evaluate ***\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =      0.926\n",
      "  eval_loss               =     0.2415\n",
      "  eval_runtime            = 0:00:03.93\n",
      "  eval_samples            =       2000\n",
      "  eval_samples_per_second =    508.632\n",
      "  eval_steps_per_second   =     63.579\n"
     ]
    }
   ],
   "source": [
    "!python run_glue.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path gpt2 \\\n",
    "  --custom_model gpt2_modified \\\n",
    "  --train_file data/train.json  \\\n",
    "  --validation_file data/validation.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --max_seq_length 128 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 1 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 1000 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 50 \\\n",
    "  --eval_steps 1000 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir output/gpt2_modified_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassificationCustom(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): GPT2ClassificationHeadCustom(\n",
      "    (dense_1_input): Linear(in_features=768, out_features=1536, bias=True)\n",
      "    (dense_1_hidden): Linear(in_features=768, out_features=1536, bias=True)\n",
      "    (dense_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=6, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GPT2ForSequenceClassificationCustom.from_pretrained(\n",
    "    r'.\\output\\gpt2_modified_emotion')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/26/2024 01:16:47 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/26/2024 01:16:47 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=1000,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=128,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/t5_freeze_emotion\\runs\\Jan26_01-16-47_GIGA_PC,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=output/t5_freeze_emotion,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/t5_freeze_emotion,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=1000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/26/2024 01:16:48 - INFO - datasets.builder - Using custom data configuration default-019d6cd006d41b2b\n",
      "01/26/2024 01:16:48 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "01/26/2024 01:16:48 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "01/26/2024 01:16:48 - INFO - datasets.info - Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:16:48 - INFO - datasets.builder - Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/26/2024 01:16:48 - INFO - datasets.info - Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/26/2024 01:21:18 - INFO - __main__ - Freezing encoder weights\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (relative_attention_bias): Embedding(32, 16)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Freezing weight T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseActDense(\n",
      "        (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "        (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (act): ReLU()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "01/26/2024 01:21:18 - INFO - __main__ - Using translation prefix: \"'emotion_classification: '\"\n",
      "01/26/2024 01:21:18 - INFO - datasets.arrow_dataset - Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-b02e697a1cfb6ab9.arrow\n",
      "01/26/2024 01:21:19 - INFO - datasets.arrow_dataset - Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-aa5629fd85648321.arrow\n",
      "{'loss': 1.6216, 'learning_rate': 4.875e-05, 'epoch': 0.03}\n",
      "{'loss': 0.7137, 'learning_rate': 4.75e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7272, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5982, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n",
      "{'loss': 0.5133, 'learning_rate': 4.375e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4001, 'learning_rate': 4.25e-05, 'epoch': 0.15}\n",
      "{'loss': 0.3813, 'learning_rate': 4.125e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3626, 'learning_rate': 4e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3263, 'learning_rate': 3.875e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3538, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3157, 'learning_rate': 3.625e-05, 'epoch': 0.28}\n",
      "{'loss': 0.2975, 'learning_rate': 3.5e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1877, 'learning_rate': 3.375000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2676, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.35}\n",
      "{'loss': 0.2353, 'learning_rate': 3.125e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1737, 'learning_rate': 3e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1852, 'learning_rate': 2.8749999999999997e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1779, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1513, 'learning_rate': 2.625e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1808, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'eval_loss': 0.14553262293338776, 'eval_bleu': 0.0, 'eval_accuracy': 1.0, 'eval_gen_len': 2.283, 'eval_runtime': 27.2796, 'eval_samples_per_second': 73.315, 'eval_steps_per_second': 9.164, 'epoch': 0.5}\n",
      "{'loss': 0.1713, 'learning_rate': 2.375e-05, 'epoch': 0.53}\n",
      "{'loss': 0.1673, 'learning_rate': 2.25e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1951, 'learning_rate': 2.125e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1672, 'learning_rate': 2e-05, 'epoch': 0.6}\n",
      "{'loss': 0.2003, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1508, 'learning_rate': 1.75e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1593, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1618, 'learning_rate': 1.5e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1311, 'learning_rate': 1.3750000000000002e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1796, 'learning_rate': 1.25e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1493, 'learning_rate': 1.125e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1272, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1322, 'learning_rate': 8.75e-06, 'epoch': 0.82}\n",
      "{'loss': 0.1497, 'learning_rate': 7.5e-06, 'epoch': 0.85}\n",
      "{'loss': 0.1136, 'learning_rate': 6.25e-06, 'epoch': 0.88}\n",
      "{'loss': 0.1296, 'learning_rate': 5e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1901, 'learning_rate': 3.75e-06, 'epoch': 0.93}\n",
      "{'loss': 0.1109, 'learning_rate': 2.5e-06, 'epoch': 0.95}\n",
      "{'loss': 0.1761, 'learning_rate': 1.25e-06, 'epoch': 0.97}\n",
      "{'loss': 0.1636, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'eval_loss': 0.1157238557934761, 'eval_bleu': 0.0, 'eval_accuracy': 1.0, 'eval_gen_len': 2.2815, 'eval_runtime': 27.2598, 'eval_samples_per_second': 73.368, 'eval_steps_per_second': 9.171, 'epoch': 1.0}\n",
      "{'train_runtime': 539.4539, 'train_samples_per_second': 29.66, 'train_steps_per_second': 3.707, 'train_loss': 0.28242340874671934, 'epoch': 1.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  train_loss               =     0.2824\n",
      "  train_runtime            = 0:08:59.45\n",
      "  train_samples            =      16000\n",
      "  train_samples_per_second =      29.66\n",
      "  train_steps_per_second   =      3.707\n",
      "01/26/2024 01:30:41 - INFO - __main__ - *** Evaluate ***\n",
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =        1.0\n",
      "  eval_bleu               =        0.0\n",
      "  eval_gen_len            =      2.283\n",
      "  eval_loss               =     0.1455\n",
      "  eval_runtime            = 0:00:27.48\n",
      "  eval_samples            =       2000\n",
      "  eval_samples_per_second =     72.778\n",
      "  eval_steps_per_second   =      9.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-019d6cd006d41b2b\n",
      "Loading Dataset Infos from c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\packaged_modules\\json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from .cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from d:/Python/DeepLearning/.cache_training/json/default-019d6cd006d41b2b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "\n",
      "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]\n",
      "config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 385kB/s]\n",
      "c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\Python\\DeepLearning\\.cache_training\\models--t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:16:48,948 >> loading configuration file config.json from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:16:48,961 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:550] 2024-01-26 01:16:49,137 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:16:49,304 >> loading configuration file config.json from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:16:49,305 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "\n",
      "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 3.14MB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 3.14MB/s]\n",
      "\n",
      "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 2.67MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 2.67MB/s]\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:16:51,304 >> loading file spiece.model from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\spiece.model\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:16:51,304 >> loading file tokenizer.json from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:16:51,304 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:16:51,304 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2043] 2024-01-26 01:16:51,304 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:715] 2024-01-26 01:16:51,305 >> loading configuration file config.json from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\config.json\n",
      "[INFO|configuration_utils.py:775] 2024-01-26 01:16:51,305 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "\n",
      "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]\n",
      "model.safetensors:   0%|          | 10.5M/2.95G [00:00<03:37, 13.5MB/s]\n",
      "model.safetensors:   1%|          | 21.0M/2.95G [00:01<02:42, 18.1MB/s]\n",
      "model.safetensors:   1%|          | 31.5M/2.95G [00:01<02:29, 19.6MB/s]\n",
      "model.safetensors:   1%|▏         | 41.9M/2.95G [00:02<02:17, 21.2MB/s]\n",
      "model.safetensors:   2%|▏         | 52.4M/2.95G [00:02<02:11, 22.0MB/s]\n",
      "model.safetensors:   2%|▏         | 62.9M/2.95G [00:03<02:07, 22.6MB/s]\n",
      "model.safetensors:   2%|▏         | 73.4M/2.95G [00:03<02:28, 19.4MB/s]\n",
      "model.safetensors:   3%|▎         | 83.9M/2.95G [00:04<03:02, 15.7MB/s]\n",
      "model.safetensors:   3%|▎         | 94.4M/2.95G [00:05<03:31, 13.5MB/s]\n",
      "model.safetensors:   4%|▎         | 105M/2.95G [00:06<03:48, 12.4MB/s] \n",
      "model.safetensors:   4%|▍         | 115M/2.95G [00:07<03:59, 11.8MB/s]\n",
      "model.safetensors:   4%|▍         | 126M/2.95G [00:08<03:50, 12.2MB/s]\n",
      "model.safetensors:   5%|▍         | 136M/2.95G [00:09<04:03, 11.6MB/s]\n",
      "model.safetensors:   5%|▍         | 147M/2.95G [00:10<04:20, 10.8MB/s]\n",
      "model.safetensors:   5%|▌         | 157M/2.95G [00:11<04:09, 11.2MB/s]\n",
      "model.safetensors:   6%|▌         | 168M/2.95G [00:12<04:22, 10.6MB/s]\n",
      "model.safetensors:   6%|▌         | 178M/2.95G [00:13<04:21, 10.6MB/s]\n",
      "model.safetensors:   6%|▋         | 189M/2.95G [00:14<04:18, 10.7MB/s]\n",
      "model.safetensors:   7%|▋         | 199M/2.95G [00:15<04:15, 10.8MB/s]\n",
      "model.safetensors:   7%|▋         | 210M/2.95G [00:16<04:01, 11.4MB/s]\n",
      "model.safetensors:   7%|▋         | 220M/2.95G [00:17<04:06, 11.1MB/s]\n",
      "model.safetensors:   8%|▊         | 231M/2.95G [00:18<04:18, 10.5MB/s]\n",
      "model.safetensors:   8%|▊         | 241M/2.95G [00:19<04:18, 10.5MB/s]\n",
      "model.safetensors:   9%|▊         | 252M/2.95G [00:20<04:25, 10.2MB/s]\n",
      "model.safetensors:   9%|▉         | 262M/2.95G [00:21<04:37, 9.67MB/s]\n",
      "model.safetensors:   9%|▉         | 273M/2.95G [00:22<04:47, 9.33MB/s]\n",
      "model.safetensors:  10%|▉         | 283M/2.95G [00:23<04:37, 9.62MB/s]\n",
      "model.safetensors:  10%|▉         | 294M/2.95G [00:24<04:17, 10.3MB/s]\n",
      "model.safetensors:  10%|█         | 304M/2.95G [00:25<03:47, 11.6MB/s]\n",
      "model.safetensors:  11%|█         | 315M/2.95G [00:26<03:24, 12.9MB/s]\n",
      "model.safetensors:  11%|█         | 325M/2.95G [00:26<03:27, 12.6MB/s]\n",
      "model.safetensors:  11%|█▏        | 336M/2.95G [00:27<03:39, 11.9MB/s]\n",
      "model.safetensors:  12%|█▏        | 346M/2.95G [00:28<03:46, 11.5MB/s]\n",
      "model.safetensors:  12%|█▏        | 357M/2.95G [00:29<03:46, 11.4MB/s]\n",
      "model.safetensors:  12%|█▏        | 367M/2.95G [00:30<03:55, 11.0MB/s]\n",
      "model.safetensors:  13%|█▎        | 377M/2.95G [00:31<04:04, 10.5MB/s]\n",
      "model.safetensors:  13%|█▎        | 388M/2.95G [00:33<04:23, 9.74MB/s]\n",
      "model.safetensors:  14%|█▎        | 398M/2.95G [00:34<04:25, 9.62MB/s]\n",
      "model.safetensors:  14%|█▍        | 409M/2.95G [00:35<04:00, 10.6MB/s]\n",
      "model.safetensors:  14%|█▍        | 419M/2.95G [00:35<03:29, 12.1MB/s]\n",
      "model.safetensors:  15%|█▍        | 430M/2.95G [00:36<03:34, 11.7MB/s]\n",
      "model.safetensors:  15%|█▍        | 440M/2.95G [00:37<03:32, 11.8MB/s]\n",
      "model.safetensors:  15%|█▌        | 451M/2.95G [00:38<03:47, 11.0MB/s]\n",
      "model.safetensors:  16%|█▌        | 461M/2.95G [00:39<03:57, 10.5MB/s]\n",
      "model.safetensors:  16%|█▌        | 472M/2.95G [00:40<03:54, 10.6MB/s]\n",
      "model.safetensors:  16%|█▋        | 482M/2.95G [00:41<03:31, 11.6MB/s]\n",
      "model.safetensors:  17%|█▋        | 493M/2.95G [00:42<03:28, 11.8MB/s]\n",
      "model.safetensors:  17%|█▋        | 503M/2.95G [00:43<03:26, 11.9MB/s]\n",
      "model.safetensors:  17%|█▋        | 514M/2.95G [00:44<03:32, 11.5MB/s]\n",
      "model.safetensors:  18%|█▊        | 524M/2.95G [00:45<03:37, 11.2MB/s]\n",
      "model.safetensors:  18%|█▊        | 535M/2.95G [00:45<03:25, 11.7MB/s]\n",
      "model.safetensors:  18%|█▊        | 545M/2.95G [00:46<03:24, 11.8MB/s]\n",
      "model.safetensors:  19%|█▉        | 556M/2.95G [00:47<03:44, 10.7MB/s]\n",
      "model.safetensors:  19%|█▉        | 566M/2.95G [00:48<03:29, 11.4MB/s]\n",
      "model.safetensors:  20%|█▉        | 577M/2.95G [00:49<03:35, 11.0MB/s]\n",
      "model.safetensors:  20%|█▉        | 587M/2.95G [00:50<03:32, 11.1MB/s]\n",
      "model.safetensors:  20%|██        | 598M/2.95G [00:51<03:39, 10.7MB/s]\n",
      "model.safetensors:  21%|██        | 608M/2.95G [00:52<03:32, 11.0MB/s]\n",
      "model.safetensors:  21%|██        | 619M/2.95G [00:53<03:30, 11.1MB/s]\n",
      "model.safetensors:  21%|██▏       | 629M/2.95G [00:54<03:38, 10.6MB/s]\n",
      "model.safetensors:  22%|██▏       | 640M/2.95G [00:55<03:35, 10.7MB/s]\n",
      "model.safetensors:  22%|██▏       | 650M/2.95G [00:56<03:43, 10.3MB/s]\n",
      "model.safetensors:  22%|██▏       | 661M/2.95G [00:58<04:01, 9.49MB/s]\n",
      "model.safetensors:  23%|██▎       | 671M/2.95G [00:59<04:01, 9.44MB/s]\n",
      "model.safetensors:  23%|██▎       | 682M/2.95G [00:59<03:36, 10.5MB/s]\n",
      "model.safetensors:  23%|██▎       | 692M/2.95G [01:00<03:11, 11.8MB/s]\n",
      "model.safetensors:  24%|██▍       | 703M/2.95G [01:01<02:47, 13.4MB/s]\n",
      "model.safetensors:  24%|██▍       | 713M/2.95G [01:01<02:57, 12.6MB/s]\n",
      "model.safetensors:  25%|██▍       | 724M/2.95G [01:02<03:05, 12.0MB/s]\n",
      "model.safetensors:  25%|██▍       | 734M/2.95G [01:03<03:11, 11.6MB/s]\n",
      "model.safetensors:  25%|██▌       | 744M/2.95G [01:04<03:11, 11.5MB/s]\n",
      "model.safetensors:  26%|██▌       | 755M/2.95G [01:05<03:18, 11.1MB/s]\n",
      "model.safetensors:  26%|██▌       | 765M/2.95G [01:06<03:12, 11.3MB/s]\n",
      "model.safetensors:  26%|██▋       | 776M/2.95G [01:07<03:18, 11.0MB/s]\n",
      "model.safetensors:  27%|██▋       | 786M/2.95G [01:08<03:17, 10.9MB/s]\n",
      "model.safetensors:  27%|██▋       | 797M/2.95G [01:09<03:22, 10.7MB/s]\n",
      "model.safetensors:  27%|██▋       | 807M/2.95G [01:10<03:22, 10.6MB/s]\n",
      "model.safetensors:  28%|██▊       | 818M/2.95G [01:11<03:14, 11.0MB/s]\n",
      "model.safetensors:  28%|██▊       | 828M/2.95G [01:12<03:10, 11.2MB/s]\n",
      "model.safetensors:  28%|██▊       | 839M/2.95G [01:13<03:19, 10.6MB/s]\n",
      "model.safetensors:  29%|██▉       | 849M/2.95G [01:14<03:26, 10.2MB/s]\n",
      "model.safetensors:  29%|██▉       | 860M/2.95G [01:15<03:28, 10.0MB/s]\n",
      "model.safetensors:  29%|██▉       | 870M/2.95G [01:16<03:11, 10.9MB/s]\n",
      "model.safetensors:  30%|██▉       | 881M/2.95G [01:17<02:50, 12.2MB/s]\n",
      "model.safetensors:  30%|███       | 891M/2.95G [01:18<03:06, 11.0MB/s]\n",
      "model.safetensors:  31%|███       | 902M/2.95G [01:19<03:17, 10.4MB/s]\n",
      "model.safetensors:  31%|███       | 912M/2.95G [01:20<03:24, 9.99MB/s]\n",
      "model.safetensors:  31%|███▏      | 923M/2.95G [01:21<03:27, 9.76MB/s]\n",
      "model.safetensors:  32%|███▏      | 933M/2.95G [01:22<03:21, 10.0MB/s]\n",
      "model.safetensors:  32%|███▏      | 944M/2.95G [01:23<03:06, 10.8MB/s]\n",
      "model.safetensors:  32%|███▏      | 954M/2.95G [01:24<02:44, 12.2MB/s]\n",
      "model.safetensors:  33%|███▎      | 965M/2.95G [01:25<02:40, 12.4MB/s]\n",
      "model.safetensors:  33%|███▎      | 975M/2.95G [01:26<02:49, 11.7MB/s]\n",
      "model.safetensors:  33%|███▎      | 986M/2.95G [01:27<02:53, 11.3MB/s]\n",
      "model.safetensors:  34%|███▍      | 996M/2.95G [01:28<02:52, 11.3MB/s]\n",
      "model.safetensors:  34%|███▍      | 1.01G/2.95G [01:29<02:59, 10.9MB/s]\n",
      "model.safetensors:  34%|███▍      | 1.02G/2.95G [01:30<03:01, 10.6MB/s]\n",
      "model.safetensors:  35%|███▍      | 1.03G/2.95G [01:31<03:06, 10.3MB/s]\n",
      "model.safetensors:  35%|███▌      | 1.04G/2.95G [01:32<03:04, 10.3MB/s]\n",
      "model.safetensors:  36%|███▌      | 1.05G/2.95G [01:33<03:05, 10.3MB/s]\n",
      "model.safetensors:  36%|███▌      | 1.06G/2.95G [01:33<02:48, 11.2MB/s]\n",
      "model.safetensors:  36%|███▌      | 1.07G/2.95G [01:34<02:36, 12.0MB/s]\n",
      "model.safetensors:  37%|███▋      | 1.08G/2.95G [01:35<02:39, 11.8MB/s]\n",
      "model.safetensors:  37%|███▋      | 1.09G/2.95G [01:36<02:42, 11.5MB/s]\n",
      "model.safetensors:  37%|███▋      | 1.10G/2.95G [01:37<02:45, 11.2MB/s]\n",
      "model.safetensors:  38%|███▊      | 1.11G/2.95G [01:38<02:35, 11.8MB/s]\n",
      "model.safetensors:  38%|███▊      | 1.12G/2.95G [01:39<02:48, 10.9MB/s]\n",
      "model.safetensors:  38%|███▊      | 1.13G/2.95G [01:40<03:02, 9.95MB/s]\n",
      "model.safetensors:  39%|███▊      | 1.14G/2.95G [01:41<03:09, 9.54MB/s]\n",
      "model.safetensors:  39%|███▉      | 1.15G/2.95G [01:42<02:59, 10.0MB/s]\n",
      "model.safetensors:  39%|███▉      | 1.16G/2.95G [01:43<02:40, 11.1MB/s]\n",
      "model.safetensors:  40%|███▉      | 1.17G/2.95G [01:44<02:18, 12.9MB/s]\n",
      "model.safetensors:  40%|████      | 1.18G/2.95G [01:45<02:26, 12.0MB/s]\n",
      "model.safetensors:  41%|████      | 1.20G/2.95G [01:46<02:38, 11.0MB/s]\n",
      "model.safetensors:  41%|████      | 1.21G/2.95G [01:47<02:45, 10.5MB/s]\n",
      "model.safetensors:  41%|████      | 1.22G/2.95G [01:48<02:39, 10.9MB/s]\n",
      "model.safetensors:  42%|████▏     | 1.23G/2.95G [01:48<02:21, 12.1MB/s]\n",
      "model.safetensors:  42%|████▏     | 1.24G/2.95G [01:49<02:20, 12.2MB/s]\n",
      "model.safetensors:  42%|████▏     | 1.25G/2.95G [01:50<02:27, 11.6MB/s]\n",
      "model.safetensors:  43%|████▎     | 1.26G/2.95G [01:51<02:32, 11.1MB/s]\n",
      "model.safetensors:  43%|████▎     | 1.27G/2.95G [01:52<02:35, 10.8MB/s]\n",
      "model.safetensors:  43%|████▎     | 1.28G/2.95G [01:53<02:25, 11.5MB/s]\n",
      "model.safetensors:  44%|████▎     | 1.29G/2.95G [01:54<02:24, 11.5MB/s]\n",
      "model.safetensors:  44%|████▍     | 1.30G/2.95G [01:55<02:23, 11.5MB/s]\n",
      "model.safetensors:  44%|████▍     | 1.31G/2.95G [01:56<02:27, 11.1MB/s]\n",
      "model.safetensors:  45%|████▍     | 1.32G/2.95G [01:57<02:27, 11.1MB/s]\n",
      "model.safetensors:  45%|████▌     | 1.33G/2.95G [01:58<02:14, 12.0MB/s]\n",
      "model.safetensors:  45%|████▌     | 1.34G/2.95G [01:59<02:24, 11.2MB/s]\n",
      "model.safetensors:  46%|████▌     | 1.35G/2.95G [02:00<02:31, 10.5MB/s]\n",
      "model.safetensors:  46%|████▌     | 1.36G/2.95G [02:01<02:37, 10.1MB/s]\n",
      "model.safetensors:  47%|████▋     | 1.37G/2.95G [02:02<02:47, 9.44MB/s]\n",
      "model.safetensors:  47%|████▋     | 1.38G/2.95G [02:03<02:26, 10.7MB/s]\n",
      "model.safetensors:  47%|████▋     | 1.39G/2.95G [02:03<02:04, 12.5MB/s]\n",
      "model.safetensors:  48%|████▊     | 1.41G/2.95G [02:04<02:09, 12.0MB/s]\n",
      "model.safetensors:  48%|████▊     | 1.42G/2.95G [02:05<02:13, 11.5MB/s]\n",
      "model.safetensors:  48%|████▊     | 1.43G/2.95G [02:06<02:16, 11.2MB/s]\n",
      "model.safetensors:  49%|████▊     | 1.44G/2.95G [02:07<02:12, 11.5MB/s]\n",
      "model.safetensors:  49%|████▉     | 1.45G/2.95G [02:08<02:15, 11.1MB/s]\n",
      "model.safetensors:  49%|████▉     | 1.46G/2.95G [02:09<02:17, 10.8MB/s]\n",
      "model.safetensors:  50%|████▉     | 1.47G/2.95G [02:10<02:20, 10.6MB/s]\n",
      "model.safetensors:  50%|█████     | 1.48G/2.95G [02:11<02:17, 10.7MB/s]\n",
      "model.safetensors:  50%|█████     | 1.49G/2.95G [02:12<02:04, 11.8MB/s]\n",
      "model.safetensors:  51%|█████     | 1.50G/2.95G [02:13<02:03, 11.7MB/s]\n",
      "model.safetensors:  51%|█████     | 1.51G/2.95G [02:14<02:06, 11.4MB/s]\n",
      "model.safetensors:  52%|█████▏    | 1.52G/2.95G [02:15<02:19, 10.3MB/s]\n",
      "model.safetensors:  52%|█████▏    | 1.53G/2.95G [02:16<02:15, 10.5MB/s]\n",
      "model.safetensors:  52%|█████▏    | 1.54G/2.95G [02:17<02:01, 11.6MB/s]\n",
      "model.safetensors:  53%|█████▎    | 1.55G/2.95G [02:18<02:00, 11.6MB/s]\n",
      "model.safetensors:  53%|█████▎    | 1.56G/2.95G [02:19<02:05, 11.1MB/s]\n",
      "model.safetensors:  53%|█████▎    | 1.57G/2.95G [02:20<02:12, 10.4MB/s]\n",
      "model.safetensors:  54%|█████▎    | 1.58G/2.95G [02:21<02:15, 10.1MB/s]\n",
      "model.safetensors:  54%|█████▍    | 1.59G/2.95G [02:22<02:05, 10.8MB/s]\n",
      "model.safetensors:  54%|█████▍    | 1.60G/2.95G [02:22<01:47, 12.5MB/s]\n",
      "model.safetensors:  55%|█████▍    | 1.61G/2.95G [02:23<01:49, 12.2MB/s]\n",
      "model.safetensors:  55%|█████▌    | 1.63G/2.95G [02:24<01:58, 11.2MB/s]\n",
      "model.safetensors:  55%|█████▌    | 1.64G/2.95G [02:25<02:04, 10.6MB/s]\n",
      "model.safetensors:  56%|█████▌    | 1.65G/2.95G [02:26<02:06, 10.4MB/s]\n",
      "model.safetensors:  56%|█████▌    | 1.66G/2.95G [02:27<01:55, 11.2MB/s]\n",
      "model.safetensors:  57%|█████▋    | 1.67G/2.95G [02:28<01:41, 12.7MB/s]\n",
      "model.safetensors:  57%|█████▋    | 1.68G/2.95G [02:29<01:48, 11.7MB/s]\n",
      "model.safetensors:  57%|█████▋    | 1.69G/2.95G [02:30<01:55, 10.9MB/s]\n",
      "model.safetensors:  58%|█████▊    | 1.70G/2.95G [02:31<01:59, 10.5MB/s]\n",
      "model.safetensors:  58%|█████▊    | 1.71G/2.95G [02:32<01:52, 11.1MB/s]\n",
      "model.safetensors:  58%|█████▊    | 1.72G/2.95G [02:33<01:42, 12.0MB/s]\n",
      "model.safetensors:  59%|█████▊    | 1.73G/2.95G [02:34<01:50, 11.0MB/s]\n",
      "model.safetensors:  59%|█████▉    | 1.74G/2.95G [02:35<01:59, 10.1MB/s]\n",
      "model.safetensors:  59%|█████▉    | 1.75G/2.95G [02:36<02:15, 8.84MB/s]\n",
      "model.safetensors:  60%|█████▉    | 1.76G/2.95G [02:37<02:06, 9.41MB/s]\n",
      "model.safetensors:  60%|██████    | 1.77G/2.95G [02:38<01:51, 10.6MB/s]\n",
      "model.safetensors:  60%|██████    | 1.78G/2.95G [02:39<01:34, 12.3MB/s]\n",
      "model.safetensors:  61%|██████    | 1.79G/2.95G [02:39<01:28, 13.1MB/s]\n",
      "model.safetensors:  61%|██████    | 1.80G/2.95G [02:40<01:31, 12.6MB/s]\n",
      "model.safetensors:  61%|██████▏   | 1.81G/2.95G [02:41<01:34, 12.0MB/s]\n",
      "model.safetensors:  62%|██████▏   | 1.82G/2.95G [02:42<01:36, 11.6MB/s]\n",
      "model.safetensors:  62%|██████▏   | 1.84G/2.95G [02:43<01:32, 12.0MB/s]\n",
      "model.safetensors:  63%|██████▎   | 1.85G/2.95G [02:44<01:34, 11.7MB/s]\n",
      "model.safetensors:  63%|██████▎   | 1.86G/2.95G [02:45<01:36, 11.4MB/s]\n",
      "model.safetensors:  63%|██████▎   | 1.87G/2.95G [02:46<01:36, 11.2MB/s]\n",
      "model.safetensors:  64%|██████▎   | 1.88G/2.95G [02:47<01:35, 11.3MB/s]\n",
      "model.safetensors:  64%|██████▍   | 1.89G/2.95G [02:48<01:38, 10.8MB/s]\n",
      "model.safetensors:  64%|██████▍   | 1.90G/2.95G [02:49<01:38, 10.7MB/s]\n",
      "model.safetensors:  65%|██████▍   | 1.91G/2.95G [02:50<01:40, 10.4MB/s]\n",
      "model.safetensors:  65%|██████▌   | 1.92G/2.95G [02:51<01:43, 9.97MB/s]\n",
      "model.safetensors:  65%|██████▌   | 1.93G/2.95G [02:52<01:43, 9.87MB/s]\n",
      "model.safetensors:  66%|██████▌   | 1.94G/2.95G [02:53<01:33, 10.8MB/s]\n",
      "model.safetensors:  66%|██████▌   | 1.95G/2.95G [02:54<01:22, 12.1MB/s]\n",
      "model.safetensors:  66%|██████▋   | 1.96G/2.95G [02:55<01:33, 10.6MB/s]\n",
      "model.safetensors:  67%|██████▋   | 1.97G/2.95G [02:56<01:30, 10.8MB/s]\n",
      "model.safetensors:  67%|██████▋   | 1.98G/2.95G [02:57<01:31, 10.6MB/s]\n",
      "model.safetensors:  68%|██████▊   | 1.99G/2.95G [02:58<01:31, 10.5MB/s]\n",
      "model.safetensors:  68%|██████▊   | 2.00G/2.95G [02:59<01:25, 11.1MB/s]\n",
      "model.safetensors:  68%|██████▊   | 2.01G/2.95G [02:59<01:21, 11.5MB/s]\n",
      "model.safetensors:  69%|██████▊   | 2.02G/2.95G [03:01<01:25, 10.9MB/s]\n",
      "model.safetensors:  69%|██████▉   | 2.03G/2.95G [03:02<01:30, 10.1MB/s]\n",
      "model.safetensors:  69%|██████▉   | 2.04G/2.95G [03:03<01:33, 9.71MB/s]\n",
      "model.safetensors:  70%|██████▉   | 2.06G/2.95G [03:04<01:26, 10.4MB/s]\n",
      "model.safetensors:  70%|███████   | 2.07G/2.95G [03:04<01:16, 11.5MB/s]\n",
      "model.safetensors:  70%|███████   | 2.08G/2.95G [03:05<01:10, 12.4MB/s]\n",
      "model.safetensors:  71%|███████   | 2.09G/2.95G [03:06<01:18, 11.0MB/s]\n",
      "model.safetensors:  71%|███████   | 2.10G/2.95G [03:08<01:25, 10.0MB/s]\n",
      "model.safetensors:  71%|███████▏  | 2.11G/2.95G [03:09<01:28, 9.49MB/s]\n",
      "model.safetensors:  72%|███████▏  | 2.12G/2.95G [03:10<01:22, 10.1MB/s]\n",
      "model.safetensors:  72%|███████▏  | 2.13G/2.95G [03:10<01:11, 11.5MB/s]\n",
      "model.safetensors:  72%|███████▏  | 2.14G/2.95G [03:11<01:04, 12.6MB/s]\n",
      "model.safetensors:  73%|███████▎  | 2.15G/2.95G [03:12<01:09, 11.6MB/s]\n",
      "model.safetensors:  73%|███████▎  | 2.16G/2.95G [03:13<01:14, 10.6MB/s]\n",
      "model.safetensors:  74%|███████▎  | 2.17G/2.95G [03:14<01:17, 10.1MB/s]\n",
      "model.safetensors:  74%|███████▍  | 2.18G/2.95G [03:15<01:13, 10.5MB/s]\n",
      "model.safetensors:  74%|███████▍  | 2.19G/2.95G [03:16<01:04, 11.8MB/s]\n",
      "model.safetensors:  75%|███████▍  | 2.20G/2.95G [03:17<01:02, 12.0MB/s]\n",
      "model.safetensors:  75%|███████▍  | 2.21G/2.95G [03:18<01:11, 10.3MB/s]\n",
      "model.safetensors:  75%|███████▌  | 2.22G/2.95G [03:19<01:12, 10.1MB/s]\n",
      "model.safetensors:  76%|███████▌  | 2.23G/2.95G [03:20<01:09, 10.4MB/s]\n",
      "model.safetensors:  76%|███████▌  | 2.24G/2.95G [03:21<01:03, 11.2MB/s]\n",
      "model.safetensors:  76%|███████▋  | 2.25G/2.95G [03:22<00:56, 12.3MB/s]\n",
      "model.safetensors:  77%|███████▋  | 2.26G/2.95G [03:23<00:59, 11.5MB/s]\n",
      "model.safetensors:  77%|███████▋  | 2.28G/2.95G [03:24<00:57, 11.7MB/s]\n",
      "model.safetensors:  77%|███████▋  | 2.29G/2.95G [03:24<00:56, 11.8MB/s]\n",
      "model.safetensors:  78%|███████▊  | 2.30G/2.95G [03:25<00:56, 11.6MB/s]\n",
      "model.safetensors:  78%|███████▊  | 2.31G/2.95G [03:26<00:57, 11.2MB/s]\n",
      "model.safetensors:  79%|███████▊  | 2.32G/2.95G [03:27<00:57, 11.0MB/s]\n",
      "model.safetensors:  79%|███████▉  | 2.33G/2.95G [03:28<00:51, 12.0MB/s]\n",
      "model.safetensors:  79%|███████▉  | 2.34G/2.95G [03:29<00:45, 13.5MB/s]\n",
      "model.safetensors:  80%|███████▉  | 2.35G/2.95G [03:29<00:41, 14.7MB/s]\n",
      "model.safetensors:  80%|███████▉  | 2.36G/2.95G [03:30<00:36, 16.3MB/s]\n",
      "model.safetensors:  80%|████████  | 2.37G/2.95G [03:30<00:35, 16.4MB/s]\n",
      "model.safetensors:  81%|████████  | 2.38G/2.95G [03:31<00:31, 18.0MB/s]\n",
      "model.safetensors:  81%|████████  | 2.39G/2.95G [03:31<00:29, 19.3MB/s]\n",
      "model.safetensors:  81%|████████▏ | 2.40G/2.95G [03:32<00:30, 18.2MB/s]\n",
      "model.safetensors:  82%|████████▏ | 2.41G/2.95G [03:33<00:35, 15.1MB/s]\n",
      "model.safetensors:  82%|████████▏ | 2.42G/2.95G [03:34<00:42, 12.5MB/s]\n",
      "model.safetensors:  82%|████████▏ | 2.43G/2.95G [03:35<00:46, 11.2MB/s]\n",
      "model.safetensors:  83%|████████▎ | 2.44G/2.95G [03:36<00:44, 11.4MB/s]\n",
      "model.safetensors:  83%|████████▎ | 2.45G/2.95G [03:37<00:40, 12.4MB/s]\n",
      "model.safetensors:  84%|████████▎ | 2.46G/2.95G [03:38<00:38, 12.6MB/s]\n",
      "model.safetensors:  84%|████████▍ | 2.47G/2.95G [03:39<00:40, 11.8MB/s]\n",
      "model.safetensors:  84%|████████▍ | 2.49G/2.95G [03:40<00:41, 11.2MB/s]\n",
      "model.safetensors:  85%|████████▍ | 2.50G/2.95G [03:41<00:42, 10.8MB/s]\n",
      "model.safetensors:  85%|████████▍ | 2.51G/2.95G [03:41<00:39, 11.2MB/s]\n",
      "model.safetensors:  85%|████████▌ | 2.52G/2.95G [03:42<00:39, 11.1MB/s]\n",
      "model.safetensors:  86%|████████▌ | 2.53G/2.95G [03:44<00:42, 10.0MB/s]\n",
      "model.safetensors:  86%|████████▌ | 2.54G/2.95G [03:45<00:44, 9.36MB/s]\n",
      "model.safetensors:  86%|████████▋ | 2.55G/2.95G [03:46<00:42, 9.45MB/s]\n",
      "model.safetensors:  87%|████████▋ | 2.56G/2.95G [03:47<00:37, 10.5MB/s]\n",
      "model.safetensors:  87%|████████▋ | 2.57G/2.95G [03:47<00:31, 12.1MB/s]\n",
      "model.safetensors:  87%|████████▋ | 2.58G/2.95G [03:48<00:27, 13.4MB/s]\n",
      "model.safetensors:  88%|████████▊ | 2.59G/2.95G [03:49<00:29, 12.3MB/s]\n",
      "model.safetensors:  88%|████████▊ | 2.60G/2.95G [03:50<00:30, 11.5MB/s]\n",
      "model.safetensors:  88%|████████▊ | 2.61G/2.95G [03:51<00:33, 10.0MB/s]\n",
      "model.safetensors:  89%|████████▉ | 2.62G/2.95G [03:52<00:30, 10.8MB/s]\n",
      "model.safetensors:  89%|████████▉ | 2.63G/2.95G [03:53<00:26, 12.0MB/s]\n",
      "model.safetensors:  90%|████████▉ | 2.64G/2.95G [03:54<00:27, 11.3MB/s]\n",
      "model.safetensors:  90%|████████▉ | 2.65G/2.95G [03:55<00:29, 10.2MB/s]\n",
      "model.safetensors:  90%|█████████ | 2.66G/2.95G [03:56<00:30, 9.54MB/s]\n",
      "model.safetensors:  91%|█████████ | 2.67G/2.95G [03:58<00:28, 9.66MB/s]\n",
      "model.safetensors:  91%|█████████ | 2.68G/2.95G [03:58<00:25, 10.6MB/s]\n",
      "model.safetensors:  91%|█████████▏| 2.69G/2.95G [03:59<00:21, 12.0MB/s]\n",
      "model.safetensors:  92%|█████████▏| 2.71G/2.95G [03:59<00:18, 13.2MB/s]\n",
      "model.safetensors:  92%|█████████▏| 2.72G/2.95G [04:01<00:19, 11.8MB/s]\n",
      "model.safetensors:  92%|█████████▏| 2.73G/2.95G [04:02<00:22, 9.92MB/s]\n",
      "model.safetensors:  93%|█████████▎| 2.74G/2.95G [04:03<00:22, 9.60MB/s]\n",
      "model.safetensors:  93%|█████████▎| 2.75G/2.95G [04:04<00:20, 10.0MB/s]\n",
      "model.safetensors:  93%|█████████▎| 2.76G/2.95G [04:05<00:16, 11.4MB/s]\n",
      "model.safetensors:  94%|█████████▍| 2.77G/2.95G [04:05<00:14, 12.7MB/s]\n",
      "model.safetensors:  94%|█████████▍| 2.78G/2.95G [04:06<00:14, 12.0MB/s]\n",
      "model.safetensors:  95%|█████████▍| 2.79G/2.95G [04:07<00:13, 11.8MB/s]\n",
      "model.safetensors:  95%|█████████▍| 2.80G/2.95G [04:08<00:13, 11.5MB/s]\n",
      "model.safetensors:  95%|█████████▌| 2.81G/2.95G [04:09<00:12, 11.2MB/s]\n",
      "model.safetensors:  96%|█████████▌| 2.82G/2.95G [04:10<00:11, 11.0MB/s]\n",
      "model.safetensors:  96%|█████████▌| 2.83G/2.95G [04:11<00:10, 10.9MB/s]\n",
      "model.safetensors:  96%|█████████▋| 2.84G/2.95G [04:12<00:10, 10.7MB/s]\n",
      "model.safetensors:  97%|█████████▋| 2.85G/2.95G [04:13<00:08, 11.2MB/s]\n",
      "model.safetensors:  97%|█████████▋| 2.86G/2.95G [04:14<00:08, 10.5MB/s]\n",
      "model.safetensors:  97%|█████████▋| 2.87G/2.95G [04:16<00:08, 9.58MB/s]\n",
      "model.safetensors:  98%|█████████▊| 2.88G/2.95G [04:17<00:07, 9.16MB/s]\n",
      "model.safetensors:  98%|█████████▊| 2.89G/2.95G [04:18<00:05, 9.92MB/s]\n",
      "model.safetensors:  98%|█████████▊| 2.90G/2.95G [04:18<00:04, 11.4MB/s]\n",
      "model.safetensors:  99%|█████████▉| 2.92G/2.95G [04:19<00:02, 12.6MB/s]\n",
      "model.safetensors:  99%|█████████▉| 2.93G/2.95G [04:20<00:02, 11.6MB/s]\n",
      "model.safetensors: 100%|█████████▉| 2.94G/2.95G [04:21<00:01, 9.66MB/s]\n",
      "model.safetensors: 100%|█████████▉| 2.95G/2.95G [04:23<00:00, 9.45MB/s]\n",
      "model.safetensors: 100%|██████████| 2.95G/2.95G [04:23<00:00, 9.64MB/s]\n",
      "model.safetensors: 100%|██████████| 2.95G/2.95G [04:23<00:00, 11.2MB/s]\n",
      "[INFO|modeling_utils.py:2993] 2024-01-26 01:21:15,354 >> loading weights file model.safetensors from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\model.safetensors\n",
      "[INFO|configuration_utils.py:770] 2024-01-26 01:21:15,381 >> Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3775] 2024-01-26 01:21:17,975 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3783] 2024-01-26 01:21:17,975 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "\n",
      "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]\n",
      "generation_config.json: 100%|██████████| 147/147 [00:00<00:00, 73.4kB/s]\n",
      "[INFO|configuration_utils.py:730] 2024-01-26 01:21:18,511 >> loading configuration file generation_config.json from cache at .cache_training\\models--t5-large\\snapshots\\150ebc2c4b72291e770f58e6057481c8d2ed331a\\generation_config.json\n",
      "[INFO|configuration_utils.py:770] 2024-01-26 01:21:18,512 >> Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[ERROR|tokenization_utils_base.py:1046] 2024-01-26 01:21:18,724 >> Using bos_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1080] 2024-01-26 01:21:18,724 >> Using sep_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1103] 2024-01-26 01:21:18,724 >> Using cls_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1115] 2024-01-26 01:21:18,724 >> Using mask_token, but it is not set yet.\n",
      "\n",
      "Running tokenizer on train dataset:   0%|          | 0/16000 [00:00<?, ? examples/s]Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-b02e697a1cfb6ab9.arrow\n",
      "\n",
      "Running tokenizer on train dataset:  31%|███▏      | 5000/16000 [00:00<00:00, 36316.46 examples/s]\n",
      "Running tokenizer on train dataset:  69%|██████▉   | 11000/16000 [00:00<00:00, 46442.69 examples/s]\n",
      "Running tokenizer on train dataset: 100%|██████████| 16000/16000 [00:00<00:00, 43597.04 examples/s]\n",
      "Running tokenizer on train dataset: 100%|██████████| 16000/16000 [00:00<00:00, 42964.80 examples/s]\n",
      "[ERROR|tokenization_utils_base.py:1046] 2024-01-26 01:21:19,109 >> Using bos_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1080] 2024-01-26 01:21:19,109 >> Using sep_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1103] 2024-01-26 01:21:19,109 >> Using cls_token, but it is not set yet.\n",
      "[ERROR|tokenization_utils_base.py:1115] 2024-01-26 01:21:19,109 >> Using mask_token, but it is not set yet.\n",
      "\n",
      "Running tokenizer on validation dataset:   0%|          | 0/2000 [00:00<?, ? examples/s]Caching processed dataset at d:\\Python\\DeepLearning\\.cache_training\\json\\default-019d6cd006d41b2b\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-aa5629fd85648321.arrow\n",
      "\n",
      "Running tokenizer on validation dataset: 100%|██████████| 2000/2000 [00:00<00:00, 54736.63 examples/s]\n",
      "[INFO|trainer.py:1760] 2024-01-26 01:21:22,843 >> ***** Running training *****\n",
      "[INFO|trainer.py:1761] 2024-01-26 01:21:22,843 >>   Num examples = 16,000\n",
      "[INFO|trainer.py:1762] 2024-01-26 01:21:22,843 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1763] 2024-01-26 01:21:22,843 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1766] 2024-01-26 01:21:22,843 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1767] 2024-01-26 01:21:22,843 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1768] 2024-01-26 01:21:22,843 >>   Total optimization steps = 2,000\n",
      "[INFO|trainer.py:1769] 2024-01-26 01:21:22,844 >>   Number of trainable parameters = 586,648,064\n",
      "\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s][WARNING|logging.py:290] 2024-01-26 01:21:22,846 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|          | 1/2000 [00:01<49:34,  1.49s/it]\n",
      "  0%|          | 2/2000 [00:01<24:17,  1.37it/s]\n",
      "  0%|          | 3/2000 [00:01<15:52,  2.10it/s]\n",
      "  0%|          | 4/2000 [00:02<12:00,  2.77it/s]\n",
      "  0%|          | 5/2000 [00:02<10:04,  3.30it/s]\n",
      "  0%|          | 6/2000 [00:02<08:44,  3.80it/s]\n",
      "  0%|          | 7/2000 [00:02<07:58,  4.16it/s]\n",
      "  0%|          | 8/2000 [00:02<07:32,  4.40it/s]\n",
      "  0%|          | 9/2000 [00:03<07:09,  4.64it/s]\n",
      "  0%|          | 10/2000 [00:03<06:51,  4.83it/s]\n",
      "  1%|          | 11/2000 [00:03<06:44,  4.92it/s]\n",
      "  1%|          | 12/2000 [00:03<06:26,  5.15it/s]\n",
      "  1%|          | 13/2000 [00:03<06:19,  5.23it/s]\n",
      "  1%|          | 14/2000 [00:03<06:09,  5.38it/s]\n",
      "  1%|          | 15/2000 [00:04<06:07,  5.40it/s]\n",
      "  1%|          | 16/2000 [00:04<06:06,  5.42it/s]\n",
      "  1%|          | 17/2000 [00:04<06:02,  5.48it/s]\n",
      "  1%|          | 18/2000 [00:04<06:06,  5.41it/s]\n",
      "  1%|          | 19/2000 [00:04<06:00,  5.49it/s]\n",
      "  1%|          | 20/2000 [00:05<06:02,  5.46it/s]\n",
      "  1%|          | 21/2000 [00:05<05:58,  5.52it/s]\n",
      "  1%|          | 22/2000 [00:05<05:58,  5.52it/s]\n",
      "  1%|          | 23/2000 [00:05<05:52,  5.60it/s]\n",
      "  1%|          | 24/2000 [00:05<05:50,  5.64it/s]\n",
      "  1%|▏         | 25/2000 [00:05<05:53,  5.58it/s]\n",
      "  1%|▏         | 26/2000 [00:06<05:57,  5.53it/s]\n",
      "  1%|▏         | 27/2000 [00:06<06:01,  5.46it/s]\n",
      "  1%|▏         | 28/2000 [00:06<05:55,  5.54it/s]\n",
      "  1%|▏         | 29/2000 [00:06<05:57,  5.51it/s]\n",
      "  2%|▏         | 30/2000 [00:06<06:01,  5.45it/s]\n",
      "  2%|▏         | 31/2000 [00:07<06:03,  5.42it/s]\n",
      "  2%|▏         | 32/2000 [00:07<05:56,  5.52it/s]\n",
      "  2%|▏         | 33/2000 [00:07<05:57,  5.50it/s]\n",
      "  2%|▏         | 34/2000 [00:07<05:52,  5.58it/s]\n",
      "  2%|▏         | 35/2000 [00:07<05:58,  5.48it/s]\n",
      "  2%|▏         | 36/2000 [00:07<06:00,  5.45it/s]\n",
      "  2%|▏         | 37/2000 [00:08<05:53,  5.55it/s]\n",
      "  2%|▏         | 38/2000 [00:08<05:56,  5.51it/s]\n",
      "  2%|▏         | 39/2000 [00:08<06:17,  5.19it/s]\n",
      "  2%|▏         | 40/2000 [00:08<06:16,  5.21it/s]\n",
      "  2%|▏         | 41/2000 [00:08<06:04,  5.38it/s]\n",
      "  2%|▏         | 42/2000 [00:09<06:03,  5.39it/s]\n",
      "  2%|▏         | 43/2000 [00:09<05:56,  5.49it/s]\n",
      "  2%|▏         | 44/2000 [00:09<05:56,  5.48it/s]\n",
      "  2%|▏         | 45/2000 [00:09<05:52,  5.54it/s]\n",
      "  2%|▏         | 46/2000 [00:09<05:49,  5.59it/s]\n",
      "  2%|▏         | 47/2000 [00:09<05:47,  5.62it/s]\n",
      "  2%|▏         | 48/2000 [00:10<05:56,  5.47it/s]\n",
      "  2%|▏         | 49/2000 [00:10<05:53,  5.52it/s]\n",
      "  2%|▎         | 50/2000 [00:10<05:53,  5.51it/s]\n",
      "                                                 \n",
      "\n",
      "  2%|▎         | 50/2000 [00:10<05:53,  5.51it/s]\n",
      "  3%|▎         | 51/2000 [00:10<05:51,  5.54it/s]\n",
      "  3%|▎         | 52/2000 [00:10<06:02,  5.38it/s]\n",
      "  3%|▎         | 53/2000 [00:11<05:54,  5.50it/s]\n",
      "  3%|▎         | 54/2000 [00:11<05:50,  5.55it/s]\n",
      "  3%|▎         | 55/2000 [00:11<05:54,  5.48it/s]\n",
      "  3%|▎         | 56/2000 [00:11<05:56,  5.46it/s]\n",
      "  3%|▎         | 57/2000 [00:11<05:50,  5.55it/s]\n",
      "  3%|▎         | 58/2000 [00:11<05:54,  5.48it/s]\n",
      "  3%|▎         | 59/2000 [00:12<05:50,  5.54it/s]\n",
      "  3%|▎         | 60/2000 [00:12<05:45,  5.61it/s]\n",
      "  3%|▎         | 61/2000 [00:12<05:42,  5.67it/s]\n",
      "  3%|▎         | 62/2000 [00:12<05:41,  5.67it/s]\n",
      "  3%|▎         | 63/2000 [00:12<05:43,  5.63it/s]\n",
      "  3%|▎         | 64/2000 [00:12<05:42,  5.66it/s]\n",
      "  3%|▎         | 65/2000 [00:13<05:48,  5.55it/s]\n",
      "  3%|▎         | 66/2000 [00:13<05:45,  5.59it/s]\n",
      "  3%|▎         | 67/2000 [00:13<05:48,  5.54it/s]\n",
      "  3%|▎         | 68/2000 [00:13<05:50,  5.51it/s]\n",
      "  3%|▎         | 69/2000 [00:13<05:54,  5.45it/s]\n",
      "  4%|▎         | 70/2000 [00:14<06:04,  5.29it/s]\n",
      "  4%|▎         | 71/2000 [00:14<05:57,  5.40it/s]\n",
      "  4%|▎         | 72/2000 [00:14<05:55,  5.42it/s]\n",
      "  4%|▎         | 73/2000 [00:14<05:50,  5.50it/s]\n",
      "  4%|▎         | 74/2000 [00:14<05:51,  5.47it/s]\n",
      "  4%|▍         | 75/2000 [00:15<05:55,  5.42it/s]\n",
      "  4%|▍         | 76/2000 [00:15<05:53,  5.44it/s]\n",
      "  4%|▍         | 77/2000 [00:15<05:49,  5.50it/s]\n",
      "  4%|▍         | 78/2000 [00:15<05:58,  5.36it/s]\n",
      "  4%|▍         | 79/2000 [00:15<06:10,  5.19it/s]\n",
      "  4%|▍         | 80/2000 [00:15<06:05,  5.25it/s]\n",
      "  4%|▍         | 81/2000 [00:16<06:06,  5.23it/s]\n",
      "  4%|▍         | 82/2000 [00:16<06:03,  5.28it/s]\n",
      "  4%|▍         | 83/2000 [00:16<06:01,  5.31it/s]\n",
      "  4%|▍         | 84/2000 [00:16<06:00,  5.31it/s]\n",
      "  4%|▍         | 85/2000 [00:16<06:02,  5.28it/s]\n",
      "  4%|▍         | 86/2000 [00:17<06:07,  5.21it/s]\n",
      "  4%|▍         | 87/2000 [00:17<06:03,  5.27it/s]\n",
      "  4%|▍         | 88/2000 [00:17<05:54,  5.40it/s]\n",
      "  4%|▍         | 89/2000 [00:17<05:54,  5.39it/s]\n",
      "  4%|▍         | 90/2000 [00:17<05:53,  5.40it/s]\n",
      "  5%|▍         | 91/2000 [00:18<05:48,  5.47it/s]\n",
      "  5%|▍         | 92/2000 [00:18<05:48,  5.47it/s]\n",
      "  5%|▍         | 93/2000 [00:18<05:53,  5.40it/s]\n",
      "  5%|▍         | 94/2000 [00:18<05:53,  5.39it/s]\n",
      "  5%|▍         | 95/2000 [00:18<06:02,  5.25it/s]\n",
      "  5%|▍         | 96/2000 [00:18<06:00,  5.28it/s]\n",
      "  5%|▍         | 97/2000 [00:19<05:57,  5.33it/s]\n",
      "  5%|▍         | 98/2000 [00:19<05:56,  5.33it/s]\n",
      "  5%|▍         | 99/2000 [00:19<05:52,  5.39it/s]\n",
      "  5%|▌         | 100/2000 [00:19<05:54,  5.36it/s]\n",
      "                                                  \n",
      "\n",
      "  5%|▌         | 100/2000 [00:19<05:54,  5.36it/s]\n",
      "  5%|▌         | 101/2000 [00:19<06:04,  5.20it/s]\n",
      "  5%|▌         | 102/2000 [00:20<05:55,  5.34it/s]\n",
      "  5%|▌         | 103/2000 [00:20<05:57,  5.30it/s]\n",
      "  5%|▌         | 104/2000 [00:20<05:54,  5.35it/s]\n",
      "  5%|▌         | 105/2000 [00:20<05:52,  5.38it/s]\n",
      "  5%|▌         | 106/2000 [00:20<06:04,  5.20it/s]\n",
      "  5%|▌         | 107/2000 [00:21<06:05,  5.17it/s]\n",
      "  5%|▌         | 108/2000 [00:21<06:03,  5.21it/s]\n",
      "  5%|▌         | 109/2000 [00:21<05:55,  5.31it/s]\n",
      "  6%|▌         | 110/2000 [00:21<05:52,  5.36it/s]\n",
      "  6%|▌         | 111/2000 [00:21<05:49,  5.41it/s]\n",
      "  6%|▌         | 112/2000 [00:21<05:43,  5.50it/s]\n",
      "  6%|▌         | 113/2000 [00:22<05:55,  5.31it/s]\n",
      "  6%|▌         | 114/2000 [00:22<05:46,  5.45it/s]\n",
      "  6%|▌         | 115/2000 [00:22<05:40,  5.54it/s]\n",
      "  6%|▌         | 116/2000 [00:22<05:42,  5.51it/s]\n",
      "  6%|▌         | 117/2000 [00:22<05:48,  5.41it/s]\n",
      "  6%|▌         | 118/2000 [00:23<05:55,  5.29it/s]\n",
      "  6%|▌         | 119/2000 [00:23<05:47,  5.41it/s]\n",
      "  6%|▌         | 120/2000 [00:23<05:53,  5.32it/s]\n",
      "  6%|▌         | 121/2000 [00:23<05:53,  5.32it/s]\n",
      "  6%|▌         | 122/2000 [00:23<05:45,  5.44it/s]\n",
      "  6%|▌         | 123/2000 [00:24<05:45,  5.44it/s]\n",
      "  6%|▌         | 124/2000 [00:24<05:47,  5.40it/s]\n",
      "  6%|▋         | 125/2000 [00:24<05:49,  5.37it/s]\n",
      "  6%|▋         | 126/2000 [00:24<05:52,  5.32it/s]\n",
      "  6%|▋         | 127/2000 [00:24<05:49,  5.36it/s]\n",
      "  6%|▋         | 128/2000 [00:24<05:39,  5.51it/s]\n",
      "  6%|▋         | 129/2000 [00:25<05:34,  5.59it/s]\n",
      "  6%|▋         | 130/2000 [00:25<05:49,  5.35it/s]\n",
      "  7%|▋         | 131/2000 [00:25<05:50,  5.33it/s]\n",
      "  7%|▋         | 132/2000 [00:25<05:49,  5.34it/s]\n",
      "  7%|▋         | 133/2000 [00:25<05:51,  5.31it/s]\n",
      "  7%|▋         | 134/2000 [00:26<05:49,  5.33it/s]\n",
      "  7%|▋         | 135/2000 [00:26<05:43,  5.43it/s]\n",
      "  7%|▋         | 136/2000 [00:26<05:43,  5.42it/s]\n",
      "  7%|▋         | 137/2000 [00:26<05:43,  5.43it/s]\n",
      "  7%|▋         | 138/2000 [00:26<05:39,  5.49it/s]\n",
      "  7%|▋         | 139/2000 [00:26<05:37,  5.51it/s]\n",
      "  7%|▋         | 140/2000 [00:27<05:29,  5.64it/s]\n",
      "  7%|▋         | 141/2000 [00:27<05:32,  5.60it/s]\n",
      "  7%|▋         | 142/2000 [00:27<05:36,  5.52it/s]\n",
      "  7%|▋         | 143/2000 [00:27<05:40,  5.46it/s]\n",
      "  7%|▋         | 144/2000 [00:27<05:33,  5.56it/s]\n",
      "  7%|▋         | 145/2000 [00:28<05:36,  5.51it/s]\n",
      "  7%|▋         | 146/2000 [00:28<05:32,  5.58it/s]\n",
      "  7%|▋         | 147/2000 [00:28<05:27,  5.65it/s]\n",
      "  7%|▋         | 148/2000 [00:28<05:31,  5.59it/s]\n",
      "  7%|▋         | 149/2000 [00:28<05:38,  5.47it/s]\n",
      "  8%|▊         | 150/2000 [00:28<05:42,  5.40it/s]\n",
      "                                                  \n",
      "\n",
      "  8%|▊         | 150/2000 [00:28<05:42,  5.40it/s]\n",
      "  8%|▊         | 151/2000 [00:29<05:43,  5.38it/s]\n",
      "  8%|▊         | 152/2000 [00:29<05:34,  5.52it/s]\n",
      "  8%|▊         | 153/2000 [00:29<05:28,  5.62it/s]\n",
      "  8%|▊         | 154/2000 [00:29<05:33,  5.53it/s]\n",
      "  8%|▊         | 155/2000 [00:29<05:29,  5.61it/s]\n",
      "  8%|▊         | 156/2000 [00:30<05:26,  5.65it/s]\n",
      "  8%|▊         | 157/2000 [00:30<05:23,  5.69it/s]\n",
      "  8%|▊         | 158/2000 [00:30<05:24,  5.67it/s]\n",
      "  8%|▊         | 159/2000 [00:30<05:26,  5.64it/s]\n",
      "  8%|▊         | 160/2000 [00:30<05:32,  5.53it/s]\n",
      "  8%|▊         | 161/2000 [00:30<05:35,  5.48it/s]\n",
      "  8%|▊         | 162/2000 [00:31<05:30,  5.56it/s]\n",
      "  8%|▊         | 163/2000 [00:31<05:32,  5.52it/s]\n",
      "  8%|▊         | 164/2000 [00:31<05:28,  5.59it/s]\n",
      "  8%|▊         | 165/2000 [00:31<05:25,  5.64it/s]\n",
      "  8%|▊         | 166/2000 [00:31<05:27,  5.60it/s]\n",
      "  8%|▊         | 167/2000 [00:31<05:24,  5.65it/s]\n",
      "  8%|▊         | 168/2000 [00:32<05:24,  5.65it/s]\n",
      "  8%|▊         | 169/2000 [00:32<05:20,  5.71it/s]\n",
      "  8%|▊         | 170/2000 [00:32<05:25,  5.63it/s]\n",
      "  9%|▊         | 171/2000 [00:32<05:24,  5.64it/s]\n",
      "  9%|▊         | 172/2000 [00:32<05:30,  5.53it/s]\n",
      "  9%|▊         | 173/2000 [00:33<05:32,  5.50it/s]\n",
      "  9%|▊         | 174/2000 [00:33<05:25,  5.60it/s]\n",
      "  9%|▉         | 175/2000 [00:33<05:31,  5.51it/s]\n",
      "  9%|▉         | 176/2000 [00:33<05:40,  5.35it/s]\n",
      "  9%|▉         | 177/2000 [00:33<05:39,  5.37it/s]\n",
      "  9%|▉         | 178/2000 [00:33<05:36,  5.42it/s]\n",
      "  9%|▉         | 179/2000 [00:34<05:45,  5.27it/s]\n",
      "  9%|▉         | 180/2000 [00:34<05:41,  5.33it/s]\n",
      "  9%|▉         | 181/2000 [00:34<05:38,  5.38it/s]\n",
      "  9%|▉         | 182/2000 [00:34<05:33,  5.45it/s]\n",
      "  9%|▉         | 183/2000 [00:34<05:40,  5.34it/s]\n",
      "  9%|▉         | 184/2000 [00:35<05:33,  5.45it/s]\n",
      "  9%|▉         | 185/2000 [00:35<05:43,  5.29it/s]\n",
      "  9%|▉         | 186/2000 [00:35<05:35,  5.40it/s]\n",
      "  9%|▉         | 187/2000 [00:35<05:32,  5.45it/s]\n",
      "  9%|▉         | 188/2000 [00:35<05:30,  5.49it/s]\n",
      "  9%|▉         | 189/2000 [00:36<05:49,  5.18it/s]\n",
      " 10%|▉         | 190/2000 [00:36<05:39,  5.33it/s]\n",
      " 10%|▉         | 191/2000 [00:36<05:36,  5.37it/s]\n",
      " 10%|▉         | 192/2000 [00:36<05:31,  5.46it/s]\n",
      " 10%|▉         | 193/2000 [00:36<05:25,  5.55it/s]\n",
      " 10%|▉         | 194/2000 [00:36<05:27,  5.51it/s]\n",
      " 10%|▉         | 195/2000 [00:37<05:29,  5.49it/s]\n",
      " 10%|▉         | 196/2000 [00:37<05:34,  5.40it/s]\n",
      " 10%|▉         | 197/2000 [00:37<05:35,  5.38it/s]\n",
      " 10%|▉         | 198/2000 [00:37<05:37,  5.34it/s]\n",
      " 10%|▉         | 199/2000 [00:37<05:42,  5.27it/s]\n",
      " 10%|█         | 200/2000 [00:38<05:42,  5.25it/s]\n",
      "                                                  \n",
      "\n",
      " 10%|█         | 200/2000 [00:38<05:42,  5.25it/s]\n",
      " 10%|█         | 201/2000 [00:38<05:35,  5.37it/s]\n",
      " 10%|█         | 202/2000 [00:38<05:35,  5.36it/s]\n",
      " 10%|█         | 203/2000 [00:38<05:32,  5.40it/s]\n",
      " 10%|█         | 204/2000 [00:38<05:32,  5.40it/s]\n",
      " 10%|█         | 205/2000 [00:39<05:33,  5.38it/s]\n",
      " 10%|█         | 206/2000 [00:39<05:34,  5.36it/s]\n",
      " 10%|█         | 207/2000 [00:39<05:27,  5.47it/s]\n",
      " 10%|█         | 208/2000 [00:39<05:30,  5.43it/s]\n",
      " 10%|█         | 209/2000 [00:39<05:31,  5.40it/s]\n",
      " 10%|█         | 210/2000 [00:39<05:31,  5.41it/s]\n",
      " 11%|█         | 211/2000 [00:40<05:34,  5.35it/s]\n",
      " 11%|█         | 212/2000 [00:40<05:32,  5.38it/s]\n",
      " 11%|█         | 213/2000 [00:40<05:26,  5.47it/s]\n",
      " 11%|█         | 214/2000 [00:40<05:28,  5.43it/s]\n",
      " 11%|█         | 215/2000 [00:40<05:26,  5.47it/s]\n",
      " 11%|█         | 216/2000 [00:41<05:23,  5.51it/s]\n",
      " 11%|█         | 217/2000 [00:41<05:27,  5.44it/s]\n",
      " 11%|█         | 218/2000 [00:41<05:27,  5.44it/s]\n",
      " 11%|█         | 219/2000 [00:41<05:30,  5.40it/s]\n",
      " 11%|█         | 220/2000 [00:41<05:29,  5.41it/s]\n",
      " 11%|█         | 221/2000 [00:41<05:30,  5.39it/s]\n",
      " 11%|█         | 222/2000 [00:42<05:30,  5.38it/s]\n",
      " 11%|█         | 223/2000 [00:42<05:24,  5.47it/s]\n",
      " 11%|█         | 224/2000 [00:42<05:23,  5.49it/s]\n",
      " 11%|█▏        | 225/2000 [00:42<05:27,  5.42it/s]\n",
      " 11%|█▏        | 226/2000 [00:42<05:22,  5.50it/s]\n",
      " 11%|█▏        | 227/2000 [00:43<05:26,  5.42it/s]\n",
      " 11%|█▏        | 228/2000 [00:43<05:51,  5.04it/s]\n",
      " 11%|█▏        | 229/2000 [00:43<05:44,  5.15it/s]\n",
      " 12%|█▏        | 230/2000 [00:43<05:40,  5.20it/s]\n",
      " 12%|█▏        | 231/2000 [00:43<05:36,  5.25it/s]\n",
      " 12%|█▏        | 232/2000 [00:44<05:27,  5.40it/s]\n",
      " 12%|█▏        | 233/2000 [00:44<05:26,  5.41it/s]\n",
      " 12%|█▏        | 234/2000 [00:44<05:18,  5.54it/s]\n",
      " 12%|█▏        | 235/2000 [00:44<05:17,  5.56it/s]\n",
      " 12%|█▏        | 236/2000 [00:44<05:21,  5.48it/s]\n",
      " 12%|█▏        | 237/2000 [00:44<05:23,  5.44it/s]\n",
      " 12%|█▏        | 238/2000 [00:45<05:22,  5.47it/s]\n",
      " 12%|█▏        | 239/2000 [00:45<05:25,  5.40it/s]\n",
      " 12%|█▏        | 240/2000 [00:45<05:26,  5.38it/s]\n",
      " 12%|█▏        | 241/2000 [00:45<05:27,  5.37it/s]\n",
      " 12%|█▏        | 242/2000 [00:45<05:18,  5.52it/s]\n",
      " 12%|█▏        | 243/2000 [00:46<05:22,  5.45it/s]\n",
      " 12%|█▏        | 244/2000 [00:46<05:24,  5.42it/s]\n",
      " 12%|█▏        | 245/2000 [00:46<05:25,  5.39it/s]\n",
      " 12%|█▏        | 246/2000 [00:46<05:20,  5.47it/s]\n",
      " 12%|█▏        | 247/2000 [00:46<05:20,  5.47it/s]\n",
      " 12%|█▏        | 248/2000 [00:46<05:21,  5.44it/s]\n",
      " 12%|█▏        | 249/2000 [00:47<05:32,  5.27it/s]\n",
      " 12%|█▎        | 250/2000 [00:47<05:25,  5.37it/s]\n",
      "                                                  \n",
      "\n",
      " 12%|█▎        | 250/2000 [00:47<05:25,  5.37it/s]\n",
      " 13%|█▎        | 251/2000 [00:47<05:25,  5.38it/s]\n",
      " 13%|█▎        | 252/2000 [00:47<05:35,  5.22it/s]\n",
      " 13%|█▎        | 253/2000 [00:47<05:28,  5.31it/s]\n",
      " 13%|█▎        | 254/2000 [00:48<05:20,  5.44it/s]\n",
      " 13%|█▎        | 255/2000 [00:48<05:18,  5.48it/s]\n",
      " 13%|█▎        | 256/2000 [00:48<05:16,  5.50it/s]\n",
      " 13%|█▎        | 257/2000 [00:48<05:19,  5.45it/s]\n",
      " 13%|█▎        | 258/2000 [00:48<05:21,  5.41it/s]\n",
      " 13%|█▎        | 259/2000 [00:49<05:28,  5.29it/s]\n",
      " 13%|█▎        | 260/2000 [00:49<05:25,  5.35it/s]\n",
      " 13%|█▎        | 261/2000 [00:49<05:21,  5.42it/s]\n",
      " 13%|█▎        | 262/2000 [00:49<05:20,  5.43it/s]\n",
      " 13%|█▎        | 263/2000 [00:49<05:22,  5.38it/s]\n",
      " 13%|█▎        | 264/2000 [00:49<05:24,  5.35it/s]\n",
      " 13%|█▎        | 265/2000 [00:50<05:22,  5.37it/s]\n",
      " 13%|█▎        | 266/2000 [00:50<05:25,  5.32it/s]\n",
      " 13%|█▎        | 267/2000 [00:50<05:24,  5.34it/s]\n",
      " 13%|█▎        | 268/2000 [00:50<05:22,  5.36it/s]\n",
      " 13%|█▎        | 269/2000 [00:50<05:14,  5.50it/s]\n",
      " 14%|█▎        | 270/2000 [00:51<05:12,  5.54it/s]\n",
      " 14%|█▎        | 271/2000 [00:51<05:12,  5.54it/s]\n",
      " 14%|█▎        | 272/2000 [00:51<05:08,  5.59it/s]\n",
      " 14%|█▎        | 273/2000 [00:51<05:12,  5.52it/s]\n",
      " 14%|█▎        | 274/2000 [00:51<05:08,  5.59it/s]\n",
      " 14%|█▍        | 275/2000 [00:51<05:18,  5.42it/s]\n",
      " 14%|█▍        | 276/2000 [00:52<05:14,  5.48it/s]\n",
      " 14%|█▍        | 277/2000 [00:52<05:15,  5.46it/s]\n",
      " 14%|█▍        | 278/2000 [00:52<05:21,  5.35it/s]\n",
      " 14%|█▍        | 279/2000 [00:52<05:30,  5.20it/s]\n",
      " 14%|█▍        | 280/2000 [00:52<05:31,  5.20it/s]\n",
      " 14%|█▍        | 281/2000 [00:53<05:32,  5.17it/s]\n",
      " 14%|█▍        | 282/2000 [00:53<05:31,  5.18it/s]\n",
      " 14%|█▍        | 283/2000 [00:53<05:25,  5.27it/s]\n",
      " 14%|█▍        | 284/2000 [00:53<05:27,  5.23it/s]\n",
      " 14%|█▍        | 285/2000 [00:53<05:17,  5.40it/s]\n",
      " 14%|█▍        | 286/2000 [00:54<05:10,  5.52it/s]\n",
      " 14%|█▍        | 287/2000 [00:54<05:09,  5.54it/s]\n",
      " 14%|█▍        | 288/2000 [00:54<05:07,  5.56it/s]\n",
      " 14%|█▍        | 289/2000 [00:54<05:03,  5.63it/s]\n",
      " 14%|█▍        | 290/2000 [00:54<05:02,  5.65it/s]\n",
      " 15%|█▍        | 291/2000 [00:54<05:06,  5.58it/s]\n",
      " 15%|█▍        | 292/2000 [00:55<05:04,  5.62it/s]\n",
      " 15%|█▍        | 293/2000 [00:55<05:02,  5.64it/s]\n",
      " 15%|█▍        | 294/2000 [00:55<05:04,  5.60it/s]\n",
      " 15%|█▍        | 295/2000 [00:55<05:03,  5.62it/s]\n",
      " 15%|█▍        | 296/2000 [00:55<05:00,  5.67it/s]\n",
      " 15%|█▍        | 297/2000 [00:55<05:00,  5.68it/s]\n",
      " 15%|█▍        | 298/2000 [00:56<05:09,  5.49it/s]\n",
      " 15%|█▍        | 299/2000 [00:56<05:12,  5.44it/s]\n",
      " 15%|█▌        | 300/2000 [00:56<05:16,  5.37it/s]\n",
      "                                                  \n",
      "\n",
      " 15%|█▌        | 300/2000 [00:56<05:16,  5.37it/s]\n",
      " 15%|█▌        | 301/2000 [00:56<05:38,  5.02it/s]\n",
      " 15%|█▌        | 302/2000 [00:56<05:24,  5.24it/s]\n",
      " 15%|█▌        | 303/2000 [00:57<05:15,  5.38it/s]\n",
      " 15%|█▌        | 304/2000 [00:57<05:07,  5.52it/s]\n",
      " 15%|█▌        | 305/2000 [00:57<05:09,  5.48it/s]\n",
      " 15%|█▌        | 306/2000 [00:57<05:04,  5.57it/s]\n",
      " 15%|█▌        | 307/2000 [00:57<05:05,  5.54it/s]\n",
      " 15%|█▌        | 308/2000 [00:57<05:02,  5.60it/s]\n",
      " 15%|█▌        | 309/2000 [00:58<04:58,  5.67it/s]\n",
      " 16%|█▌        | 310/2000 [00:58<04:54,  5.73it/s]\n",
      " 16%|█▌        | 311/2000 [00:58<04:58,  5.65it/s]\n",
      " 16%|█▌        | 312/2000 [00:58<05:02,  5.57it/s]\n",
      " 16%|█▌        | 313/2000 [00:58<05:18,  5.29it/s]\n",
      " 16%|█▌        | 314/2000 [00:59<05:16,  5.33it/s]\n",
      " 16%|█▌        | 315/2000 [00:59<05:23,  5.20it/s]\n",
      " 16%|█▌        | 316/2000 [00:59<05:15,  5.33it/s]\n",
      " 16%|█▌        | 317/2000 [00:59<05:14,  5.35it/s]\n",
      " 16%|█▌        | 318/2000 [00:59<05:16,  5.32it/s]\n",
      " 16%|█▌        | 319/2000 [01:00<05:09,  5.43it/s]\n",
      " 16%|█▌        | 320/2000 [01:00<05:07,  5.46it/s]\n",
      " 16%|█▌        | 321/2000 [01:00<05:04,  5.51it/s]\n",
      " 16%|█▌        | 322/2000 [01:00<04:58,  5.62it/s]\n",
      " 16%|█▌        | 323/2000 [01:00<05:02,  5.55it/s]\n",
      " 16%|█▌        | 324/2000 [01:00<05:01,  5.57it/s]\n",
      " 16%|█▋        | 325/2000 [01:01<04:58,  5.62it/s]\n",
      " 16%|█▋        | 326/2000 [01:01<05:01,  5.55it/s]\n",
      " 16%|█▋        | 327/2000 [01:01<05:03,  5.52it/s]\n",
      " 16%|█▋        | 328/2000 [01:01<05:00,  5.56it/s]\n",
      " 16%|█▋        | 329/2000 [01:01<04:55,  5.65it/s]\n",
      " 16%|█▋        | 330/2000 [01:02<05:05,  5.47it/s]\n",
      " 17%|█▋        | 331/2000 [01:02<05:11,  5.37it/s]\n",
      " 17%|█▋        | 332/2000 [01:02<05:11,  5.35it/s]\n",
      " 17%|█▋        | 333/2000 [01:02<05:09,  5.39it/s]\n",
      " 17%|█▋        | 334/2000 [01:02<05:05,  5.45it/s]\n",
      " 17%|█▋        | 335/2000 [01:02<04:57,  5.59it/s]\n",
      " 17%|█▋        | 336/2000 [01:03<05:10,  5.36it/s]\n",
      " 17%|█▋        | 337/2000 [01:03<05:14,  5.29it/s]\n",
      " 17%|█▋        | 338/2000 [01:03<05:09,  5.37it/s]\n",
      " 17%|█▋        | 339/2000 [01:03<05:04,  5.45it/s]\n",
      " 17%|█▋        | 340/2000 [01:03<05:11,  5.33it/s]\n",
      " 17%|█▋        | 341/2000 [01:04<05:06,  5.41it/s]\n",
      " 17%|█▋        | 342/2000 [01:04<05:08,  5.38it/s]\n",
      " 17%|█▋        | 343/2000 [01:04<05:07,  5.39it/s]\n",
      " 17%|█▋        | 344/2000 [01:04<05:14,  5.27it/s]\n",
      " 17%|█▋        | 345/2000 [01:04<05:03,  5.46it/s]\n",
      " 17%|█▋        | 346/2000 [01:04<05:02,  5.47it/s]\n",
      " 17%|█▋        | 347/2000 [01:05<05:02,  5.47it/s]\n",
      " 17%|█▋        | 348/2000 [01:05<05:04,  5.42it/s]\n",
      " 17%|█▋        | 349/2000 [01:05<05:01,  5.48it/s]\n",
      " 18%|█▊        | 350/2000 [01:05<04:57,  5.54it/s]\n",
      "                                                  \n",
      "\n",
      " 18%|█▊        | 350/2000 [01:05<04:57,  5.54it/s]\n",
      " 18%|█▊        | 351/2000 [01:05<05:03,  5.43it/s]\n",
      " 18%|█▊        | 352/2000 [01:06<05:03,  5.43it/s]\n",
      " 18%|█▊        | 353/2000 [01:06<04:55,  5.58it/s]\n",
      " 18%|█▊        | 354/2000 [01:06<04:53,  5.61it/s]\n",
      " 18%|█▊        | 355/2000 [01:06<04:51,  5.64it/s]\n",
      " 18%|█▊        | 356/2000 [01:06<04:53,  5.60it/s]\n",
      " 18%|█▊        | 357/2000 [01:06<04:55,  5.56it/s]\n",
      " 18%|█▊        | 358/2000 [01:07<04:53,  5.60it/s]\n",
      " 18%|█▊        | 359/2000 [01:07<04:55,  5.55it/s]\n",
      " 18%|█▊        | 360/2000 [01:07<04:52,  5.60it/s]\n",
      " 18%|█▊        | 361/2000 [01:07<04:57,  5.52it/s]\n",
      " 18%|█▊        | 362/2000 [01:07<04:59,  5.47it/s]\n",
      " 18%|█▊        | 363/2000 [01:08<04:59,  5.47it/s]\n",
      " 18%|█▊        | 364/2000 [01:08<04:56,  5.52it/s]\n",
      " 18%|█▊        | 365/2000 [01:08<04:57,  5.49it/s]\n",
      " 18%|█▊        | 366/2000 [01:08<04:55,  5.53it/s]\n",
      " 18%|█▊        | 367/2000 [01:08<04:48,  5.66it/s]\n",
      " 18%|█▊        | 368/2000 [01:08<04:51,  5.60it/s]\n",
      " 18%|█▊        | 369/2000 [01:09<04:50,  5.62it/s]\n",
      " 18%|█▊        | 370/2000 [01:09<04:54,  5.54it/s]\n",
      " 19%|█▊        | 371/2000 [01:09<05:01,  5.40it/s]\n",
      " 19%|█▊        | 372/2000 [01:09<05:03,  5.36it/s]\n",
      " 19%|█▊        | 373/2000 [01:09<04:57,  5.47it/s]\n",
      " 19%|█▊        | 374/2000 [01:10<04:53,  5.54it/s]\n",
      " 19%|█▉        | 375/2000 [01:10<04:51,  5.58it/s]\n",
      " 19%|█▉        | 376/2000 [01:10<04:53,  5.54it/s]\n",
      " 19%|█▉        | 377/2000 [01:10<04:48,  5.63it/s]\n",
      " 19%|█▉        | 378/2000 [01:10<04:52,  5.55it/s]\n",
      " 19%|█▉        | 379/2000 [01:10<04:47,  5.63it/s]\n",
      " 19%|█▉        | 380/2000 [01:11<04:45,  5.67it/s]\n",
      " 19%|█▉        | 381/2000 [01:11<04:51,  5.56it/s]\n",
      " 19%|█▉        | 382/2000 [01:11<04:52,  5.53it/s]\n",
      " 19%|█▉        | 383/2000 [01:11<04:51,  5.55it/s]\n",
      " 19%|█▉        | 384/2000 [01:11<04:53,  5.50it/s]\n",
      " 19%|█▉        | 385/2000 [01:12<04:52,  5.53it/s]\n",
      " 19%|█▉        | 386/2000 [01:12<04:55,  5.46it/s]\n",
      " 19%|█▉        | 387/2000 [01:12<05:00,  5.36it/s]\n",
      " 19%|█▉        | 388/2000 [01:12<05:01,  5.34it/s]\n",
      " 19%|█▉        | 389/2000 [01:12<05:00,  5.36it/s]\n",
      " 20%|█▉        | 390/2000 [01:12<05:00,  5.36it/s]\n",
      " 20%|█▉        | 391/2000 [01:13<04:53,  5.49it/s]\n",
      " 20%|█▉        | 392/2000 [01:13<04:55,  5.44it/s]\n",
      " 20%|█▉        | 393/2000 [01:13<04:50,  5.53it/s]\n",
      " 20%|█▉        | 394/2000 [01:13<04:51,  5.50it/s]\n",
      " 20%|█▉        | 395/2000 [01:13<04:49,  5.55it/s]\n",
      " 20%|█▉        | 396/2000 [01:14<04:51,  5.51it/s]\n",
      " 20%|█▉        | 397/2000 [01:14<04:52,  5.49it/s]\n",
      " 20%|█▉        | 398/2000 [01:14<04:55,  5.43it/s]\n",
      " 20%|█▉        | 399/2000 [01:14<05:04,  5.27it/s]\n",
      " 20%|██        | 400/2000 [01:14<04:54,  5.43it/s]\n",
      "                                                  \n",
      "\n",
      " 20%|██        | 400/2000 [01:14<04:54,  5.43it/s]\n",
      " 20%|██        | 401/2000 [01:14<04:51,  5.49it/s]\n",
      " 20%|██        | 402/2000 [01:15<04:55,  5.41it/s]\n",
      " 20%|██        | 403/2000 [01:15<04:51,  5.47it/s]\n",
      " 20%|██        | 404/2000 [01:15<04:53,  5.43it/s]\n",
      " 20%|██        | 405/2000 [01:15<04:54,  5.42it/s]\n",
      " 20%|██        | 406/2000 [01:15<04:50,  5.49it/s]\n",
      " 20%|██        | 407/2000 [01:16<04:55,  5.38it/s]\n",
      " 20%|██        | 408/2000 [01:16<04:49,  5.49it/s]\n",
      " 20%|██        | 409/2000 [01:16<04:52,  5.44it/s]\n",
      " 20%|██        | 410/2000 [01:16<04:53,  5.42it/s]\n",
      " 21%|██        | 411/2000 [01:16<04:48,  5.51it/s]\n",
      " 21%|██        | 412/2000 [01:16<04:50,  5.46it/s]\n",
      " 21%|██        | 413/2000 [01:17<04:52,  5.42it/s]\n",
      " 21%|██        | 414/2000 [01:17<04:50,  5.45it/s]\n",
      " 21%|██        | 415/2000 [01:17<04:47,  5.52it/s]\n",
      " 21%|██        | 416/2000 [01:17<04:48,  5.48it/s]\n",
      " 21%|██        | 417/2000 [01:17<04:46,  5.52it/s]\n",
      " 21%|██        | 418/2000 [01:18<04:55,  5.36it/s]\n",
      " 21%|██        | 419/2000 [01:18<04:48,  5.48it/s]\n",
      " 21%|██        | 420/2000 [01:18<04:43,  5.57it/s]\n",
      " 21%|██        | 421/2000 [01:18<04:40,  5.63it/s]\n",
      " 21%|██        | 422/2000 [01:18<04:36,  5.70it/s]\n",
      " 21%|██        | 423/2000 [01:18<04:40,  5.62it/s]\n",
      " 21%|██        | 424/2000 [01:19<04:44,  5.54it/s]\n",
      " 21%|██▏       | 425/2000 [01:19<04:46,  5.49it/s]\n",
      " 21%|██▏       | 426/2000 [01:19<04:45,  5.52it/s]\n",
      " 21%|██▏       | 427/2000 [01:19<04:46,  5.49it/s]\n",
      " 21%|██▏       | 428/2000 [01:19<04:47,  5.47it/s]\n",
      " 21%|██▏       | 429/2000 [01:20<04:50,  5.41it/s]\n",
      " 22%|██▏       | 430/2000 [01:20<04:53,  5.35it/s]\n",
      " 22%|██▏       | 431/2000 [01:20<04:54,  5.33it/s]\n",
      " 22%|██▏       | 432/2000 [01:20<04:48,  5.43it/s]\n",
      " 22%|██▏       | 433/2000 [01:20<04:55,  5.30it/s]\n",
      " 22%|██▏       | 434/2000 [01:21<05:00,  5.22it/s]\n",
      " 22%|██▏       | 435/2000 [01:21<04:49,  5.41it/s]\n",
      " 22%|██▏       | 436/2000 [01:21<04:48,  5.43it/s]\n",
      " 22%|██▏       | 437/2000 [01:21<04:46,  5.45it/s]\n",
      " 22%|██▏       | 438/2000 [01:21<04:45,  5.46it/s]\n",
      " 22%|██▏       | 439/2000 [01:21<04:48,  5.42it/s]\n",
      " 22%|██▏       | 440/2000 [01:22<04:43,  5.50it/s]\n",
      " 22%|██▏       | 441/2000 [01:22<04:42,  5.51it/s]\n",
      " 22%|██▏       | 442/2000 [01:22<04:45,  5.46it/s]\n",
      " 22%|██▏       | 443/2000 [01:22<04:42,  5.51it/s]\n",
      " 22%|██▏       | 444/2000 [01:22<04:43,  5.48it/s]\n",
      " 22%|██▏       | 445/2000 [01:23<04:37,  5.61it/s]\n",
      " 22%|██▏       | 446/2000 [01:23<04:42,  5.50it/s]\n",
      " 22%|██▏       | 447/2000 [01:23<04:38,  5.59it/s]\n",
      " 22%|██▏       | 448/2000 [01:23<04:40,  5.54it/s]\n",
      " 22%|██▏       | 449/2000 [01:23<04:38,  5.57it/s]\n",
      " 22%|██▎       | 450/2000 [01:23<04:35,  5.62it/s]\n",
      "                                                  \n",
      "\n",
      " 22%|██▎       | 450/2000 [01:23<04:35,  5.62it/s]\n",
      " 23%|██▎       | 451/2000 [01:24<04:33,  5.67it/s]\n",
      " 23%|██▎       | 452/2000 [01:24<04:32,  5.69it/s]\n",
      " 23%|██▎       | 453/2000 [01:24<04:37,  5.58it/s]\n",
      " 23%|██▎       | 454/2000 [01:24<04:41,  5.49it/s]\n",
      " 23%|██▎       | 455/2000 [01:24<04:43,  5.46it/s]\n",
      " 23%|██▎       | 456/2000 [01:24<04:44,  5.43it/s]\n",
      " 23%|██▎       | 457/2000 [01:25<04:44,  5.42it/s]\n",
      " 23%|██▎       | 458/2000 [01:25<04:39,  5.51it/s]\n",
      " 23%|██▎       | 459/2000 [01:25<04:35,  5.60it/s]\n",
      " 23%|██▎       | 460/2000 [01:25<04:44,  5.42it/s]\n",
      " 23%|██▎       | 461/2000 [01:25<04:39,  5.51it/s]\n",
      " 23%|██▎       | 462/2000 [01:26<04:48,  5.33it/s]\n",
      " 23%|██▎       | 463/2000 [01:26<04:42,  5.44it/s]\n",
      " 23%|██▎       | 464/2000 [01:26<04:37,  5.54it/s]\n",
      " 23%|██▎       | 465/2000 [01:26<04:40,  5.47it/s]\n",
      " 23%|██▎       | 466/2000 [01:26<04:41,  5.44it/s]\n",
      " 23%|██▎       | 467/2000 [01:27<04:38,  5.51it/s]\n",
      " 23%|██▎       | 468/2000 [01:27<04:44,  5.39it/s]\n",
      " 23%|██▎       | 469/2000 [01:27<04:51,  5.26it/s]\n",
      " 24%|██▎       | 470/2000 [01:27<04:51,  5.25it/s]\n",
      " 24%|██▎       | 471/2000 [01:27<04:48,  5.29it/s]\n",
      " 24%|██▎       | 472/2000 [01:27<04:47,  5.31it/s]\n",
      " 24%|██▎       | 473/2000 [01:28<04:41,  5.42it/s]\n",
      " 24%|██▎       | 474/2000 [01:28<04:36,  5.52it/s]\n",
      " 24%|██▍       | 475/2000 [01:28<04:37,  5.50it/s]\n",
      " 24%|██▍       | 476/2000 [01:28<04:42,  5.39it/s]\n",
      " 24%|██▍       | 477/2000 [01:28<04:41,  5.41it/s]\n",
      " 24%|██▍       | 478/2000 [01:29<04:37,  5.49it/s]\n",
      " 24%|██▍       | 479/2000 [01:29<04:36,  5.50it/s]\n",
      " 24%|██▍       | 480/2000 [01:29<04:49,  5.26it/s]\n",
      " 24%|██▍       | 481/2000 [01:29<05:19,  4.76it/s]\n",
      " 24%|██▍       | 482/2000 [01:29<05:25,  4.67it/s]\n",
      " 24%|██▍       | 483/2000 [01:30<05:06,  4.94it/s]\n",
      " 24%|██▍       | 484/2000 [01:30<05:00,  5.04it/s]\n",
      " 24%|██▍       | 485/2000 [01:30<04:55,  5.13it/s]\n",
      " 24%|██▍       | 486/2000 [01:30<04:53,  5.15it/s]\n",
      " 24%|██▍       | 487/2000 [01:30<04:48,  5.24it/s]\n",
      " 24%|██▍       | 488/2000 [01:31<04:49,  5.22it/s]\n",
      " 24%|██▍       | 489/2000 [01:31<04:42,  5.35it/s]\n",
      " 24%|██▍       | 490/2000 [01:31<04:37,  5.44it/s]\n",
      " 25%|██▍       | 491/2000 [01:31<04:31,  5.55it/s]\n",
      " 25%|██▍       | 492/2000 [01:31<04:33,  5.51it/s]\n",
      " 25%|██▍       | 493/2000 [01:31<04:33,  5.51it/s]\n",
      " 25%|██▍       | 494/2000 [01:32<04:33,  5.51it/s]\n",
      " 25%|██▍       | 495/2000 [01:32<04:33,  5.50it/s]\n",
      " 25%|██▍       | 496/2000 [01:32<04:34,  5.49it/s]\n",
      " 25%|██▍       | 497/2000 [01:32<04:31,  5.54it/s]\n",
      " 25%|██▍       | 498/2000 [01:32<04:28,  5.60it/s]\n",
      " 25%|██▍       | 499/2000 [01:33<04:30,  5.56it/s]\n",
      " 25%|██▌       | 500/2000 [01:33<04:24,  5.66it/s]\n",
      "                                                  \n",
      "\n",
      " 25%|██▌       | 500/2000 [01:33<04:24,  5.66it/s]\n",
      " 25%|██▌       | 501/2000 [01:33<04:26,  5.63it/s]\n",
      " 25%|██▌       | 502/2000 [01:33<04:34,  5.45it/s]\n",
      " 25%|██▌       | 503/2000 [01:33<04:34,  5.45it/s]\n",
      " 25%|██▌       | 504/2000 [01:33<04:45,  5.25it/s]\n",
      " 25%|██▌       | 505/2000 [01:34<04:37,  5.39it/s]\n",
      " 25%|██▌       | 506/2000 [01:34<04:35,  5.43it/s]\n",
      " 25%|██▌       | 507/2000 [01:34<04:36,  5.40it/s]\n",
      " 25%|██▌       | 508/2000 [01:34<04:41,  5.30it/s]\n",
      " 25%|██▌       | 509/2000 [01:34<04:39,  5.34it/s]\n",
      " 26%|██▌       | 510/2000 [01:35<04:36,  5.39it/s]\n",
      " 26%|██▌       | 511/2000 [01:35<04:33,  5.45it/s]\n",
      " 26%|██▌       | 512/2000 [01:35<04:32,  5.47it/s]\n",
      " 26%|██▌       | 513/2000 [01:35<04:31,  5.49it/s]\n",
      " 26%|██▌       | 514/2000 [01:35<04:29,  5.51it/s]\n",
      " 26%|██▌       | 515/2000 [01:35<04:25,  5.59it/s]\n",
      " 26%|██▌       | 516/2000 [01:36<04:24,  5.61it/s]\n",
      " 26%|██▌       | 517/2000 [01:36<04:25,  5.58it/s]\n",
      " 26%|██▌       | 518/2000 [01:36<04:29,  5.49it/s]\n",
      " 26%|██▌       | 519/2000 [01:36<04:27,  5.54it/s]\n",
      " 26%|██▌       | 520/2000 [01:36<04:21,  5.65it/s]\n",
      " 26%|██▌       | 521/2000 [01:37<04:23,  5.60it/s]\n",
      " 26%|██▌       | 522/2000 [01:37<04:34,  5.39it/s]\n",
      " 26%|██▌       | 523/2000 [01:37<04:36,  5.35it/s]\n",
      " 26%|██▌       | 524/2000 [01:37<04:37,  5.32it/s]\n",
      " 26%|██▋       | 525/2000 [01:37<04:36,  5.33it/s]\n",
      " 26%|██▋       | 526/2000 [01:37<04:34,  5.37it/s]\n",
      " 26%|██▋       | 527/2000 [01:38<04:37,  5.31it/s]\n",
      " 26%|██▋       | 528/2000 [01:38<04:29,  5.46it/s]\n",
      " 26%|██▋       | 529/2000 [01:38<04:24,  5.57it/s]\n",
      " 26%|██▋       | 530/2000 [01:38<04:27,  5.50it/s]\n",
      " 27%|██▋       | 531/2000 [01:38<04:27,  5.48it/s]\n",
      " 27%|██▋       | 532/2000 [01:39<04:28,  5.46it/s]\n",
      " 27%|██▋       | 533/2000 [01:39<04:25,  5.52it/s]\n",
      " 27%|██▋       | 534/2000 [01:39<04:27,  5.47it/s]\n",
      " 27%|██▋       | 535/2000 [01:39<04:28,  5.47it/s]\n",
      " 27%|██▋       | 536/2000 [01:39<04:24,  5.53it/s]\n",
      " 27%|██▋       | 537/2000 [01:40<05:07,  4.76it/s]\n",
      " 27%|██▋       | 538/2000 [01:40<05:02,  4.83it/s]\n",
      " 27%|██▋       | 539/2000 [01:40<05:19,  4.58it/s]\n",
      " 27%|██▋       | 540/2000 [01:40<05:15,  4.62it/s]\n",
      " 27%|██▋       | 541/2000 [01:40<05:02,  4.83it/s]\n",
      " 27%|██▋       | 542/2000 [01:41<04:51,  5.01it/s]\n",
      " 27%|██▋       | 543/2000 [01:41<04:41,  5.18it/s]\n",
      " 27%|██▋       | 544/2000 [01:41<04:38,  5.23it/s]\n",
      " 27%|██▋       | 545/2000 [01:41<04:38,  5.22it/s]\n",
      " 27%|██▋       | 546/2000 [01:41<04:46,  5.08it/s]\n",
      " 27%|██▋       | 547/2000 [01:42<04:40,  5.18it/s]\n",
      " 27%|██▋       | 548/2000 [01:42<04:41,  5.16it/s]\n",
      " 27%|██▋       | 549/2000 [01:42<04:36,  5.25it/s]\n",
      " 28%|██▊       | 550/2000 [01:42<04:37,  5.22it/s]\n",
      "                                                  \n",
      "\n",
      " 28%|██▊       | 550/2000 [01:42<04:37,  5.22it/s]\n",
      " 28%|██▊       | 551/2000 [01:42<04:53,  4.94it/s]\n",
      " 28%|██▊       | 552/2000 [01:43<04:44,  5.10it/s]\n",
      " 28%|██▊       | 553/2000 [01:43<04:46,  5.04it/s]\n",
      " 28%|██▊       | 554/2000 [01:43<04:45,  5.06it/s]\n",
      " 28%|██▊       | 555/2000 [01:43<04:39,  5.17it/s]\n",
      " 28%|██▊       | 556/2000 [01:43<04:35,  5.23it/s]\n",
      " 28%|██▊       | 557/2000 [01:44<04:46,  5.04it/s]\n",
      " 28%|██▊       | 558/2000 [01:44<04:49,  4.99it/s]\n",
      " 28%|██▊       | 559/2000 [01:44<04:48,  4.99it/s]\n",
      " 28%|██▊       | 560/2000 [01:44<04:53,  4.91it/s]\n",
      " 28%|██▊       | 561/2000 [01:44<05:26,  4.40it/s]\n",
      " 28%|██▊       | 562/2000 [01:45<05:30,  4.35it/s]\n",
      " 28%|██▊       | 563/2000 [01:45<05:55,  4.04it/s]\n",
      " 28%|██▊       | 564/2000 [01:45<05:52,  4.08it/s]\n",
      " 28%|██▊       | 565/2000 [01:45<06:02,  3.96it/s]\n",
      " 28%|██▊       | 566/2000 [01:46<05:34,  4.28it/s]\n",
      " 28%|██▊       | 567/2000 [01:46<05:22,  4.44it/s]\n",
      " 28%|██▊       | 568/2000 [01:46<05:57,  4.01it/s]\n",
      " 28%|██▊       | 569/2000 [01:46<05:37,  4.25it/s]\n",
      " 28%|██▊       | 570/2000 [01:47<05:15,  4.53it/s]\n",
      " 29%|██▊       | 571/2000 [01:47<04:56,  4.82it/s]\n",
      " 29%|██▊       | 572/2000 [01:47<04:59,  4.77it/s]\n",
      " 29%|██▊       | 573/2000 [01:47<04:45,  5.01it/s]\n",
      " 29%|██▊       | 574/2000 [01:47<04:43,  5.03it/s]\n",
      " 29%|██▉       | 575/2000 [01:47<04:40,  5.09it/s]\n",
      " 29%|██▉       | 576/2000 [01:48<04:37,  5.13it/s]\n",
      " 29%|██▉       | 577/2000 [01:48<04:37,  5.13it/s]\n",
      " 29%|██▉       | 578/2000 [01:48<04:54,  4.83it/s]\n",
      " 29%|██▉       | 579/2000 [01:48<04:51,  4.88it/s]\n",
      " 29%|██▉       | 580/2000 [01:48<04:44,  4.99it/s]\n",
      " 29%|██▉       | 581/2000 [01:49<04:33,  5.19it/s]\n",
      " 29%|██▉       | 582/2000 [01:49<04:30,  5.25it/s]\n",
      " 29%|██▉       | 583/2000 [01:49<04:33,  5.18it/s]\n",
      " 29%|██▉       | 584/2000 [01:49<04:29,  5.24it/s]\n",
      " 29%|██▉       | 585/2000 [01:49<04:27,  5.29it/s]\n",
      " 29%|██▉       | 586/2000 [01:50<04:23,  5.36it/s]\n",
      " 29%|██▉       | 587/2000 [01:50<04:22,  5.39it/s]\n",
      " 29%|██▉       | 588/2000 [01:50<04:21,  5.39it/s]\n",
      " 29%|██▉       | 589/2000 [01:50<04:24,  5.33it/s]\n",
      " 30%|██▉       | 590/2000 [01:50<04:23,  5.36it/s]\n",
      " 30%|██▉       | 591/2000 [01:51<04:21,  5.38it/s]\n",
      " 30%|██▉       | 592/2000 [01:51<04:29,  5.22it/s]\n",
      " 30%|██▉       | 593/2000 [01:51<04:28,  5.24it/s]\n",
      " 30%|██▉       | 594/2000 [01:51<04:22,  5.35it/s]\n",
      " 30%|██▉       | 595/2000 [01:51<04:22,  5.36it/s]\n",
      " 30%|██▉       | 596/2000 [01:51<04:20,  5.38it/s]\n",
      " 30%|██▉       | 597/2000 [01:52<04:20,  5.39it/s]\n",
      " 30%|██▉       | 598/2000 [01:52<04:24,  5.29it/s]\n",
      " 30%|██▉       | 599/2000 [01:52<04:29,  5.20it/s]\n",
      " 30%|███       | 600/2000 [01:52<04:47,  4.87it/s]\n",
      "                                                  \n",
      "\n",
      " 30%|███       | 600/2000 [01:52<04:47,  4.87it/s]\n",
      " 30%|███       | 601/2000 [01:52<04:33,  5.12it/s]\n",
      " 30%|███       | 602/2000 [01:53<04:23,  5.31it/s]\n",
      " 30%|███       | 603/2000 [01:53<04:20,  5.36it/s]\n",
      " 30%|███       | 604/2000 [01:53<04:16,  5.45it/s]\n",
      " 30%|███       | 605/2000 [01:53<04:22,  5.30it/s]\n",
      " 30%|███       | 606/2000 [01:53<04:18,  5.40it/s]\n",
      " 30%|███       | 607/2000 [01:54<04:19,  5.37it/s]\n",
      " 30%|███       | 608/2000 [01:54<04:19,  5.36it/s]\n",
      " 30%|███       | 609/2000 [01:54<04:20,  5.34it/s]\n",
      " 30%|███       | 610/2000 [01:54<04:20,  5.33it/s]\n",
      " 31%|███       | 611/2000 [01:54<04:42,  4.91it/s]\n",
      " 31%|███       | 612/2000 [01:55<04:45,  4.86it/s]\n",
      " 31%|███       | 613/2000 [01:55<04:37,  5.00it/s]\n",
      " 31%|███       | 614/2000 [01:55<04:31,  5.10it/s]\n",
      " 31%|███       | 615/2000 [01:55<04:26,  5.20it/s]\n",
      " 31%|███       | 616/2000 [01:55<04:19,  5.34it/s]\n",
      " 31%|███       | 617/2000 [01:55<04:16,  5.39it/s]\n",
      " 31%|███       | 618/2000 [01:56<04:18,  5.35it/s]\n",
      " 31%|███       | 619/2000 [01:56<04:21,  5.29it/s]\n",
      " 31%|███       | 620/2000 [01:56<04:18,  5.34it/s]\n",
      " 31%|███       | 621/2000 [01:56<04:19,  5.32it/s]\n",
      " 31%|███       | 622/2000 [01:56<04:22,  5.25it/s]\n",
      " 31%|███       | 623/2000 [01:57<04:16,  5.37it/s]\n",
      " 31%|███       | 624/2000 [01:57<04:09,  5.51it/s]\n",
      " 31%|███▏      | 625/2000 [01:57<04:17,  5.34it/s]\n",
      " 31%|███▏      | 626/2000 [01:57<04:19,  5.29it/s]\n",
      " 31%|███▏      | 627/2000 [01:57<04:14,  5.39it/s]\n",
      " 31%|███▏      | 628/2000 [01:58<04:12,  5.43it/s]\n",
      " 31%|███▏      | 629/2000 [01:58<04:13,  5.41it/s]\n",
      " 32%|███▏      | 630/2000 [01:58<04:15,  5.36it/s]\n",
      " 32%|███▏      | 631/2000 [01:58<04:15,  5.37it/s]\n",
      " 32%|███▏      | 632/2000 [01:58<04:15,  5.35it/s]\n",
      " 32%|███▏      | 633/2000 [01:59<04:25,  5.16it/s]\n",
      " 32%|███▏      | 634/2000 [01:59<04:28,  5.09it/s]\n",
      " 32%|███▏      | 635/2000 [01:59<04:20,  5.24it/s]\n",
      " 32%|███▏      | 636/2000 [01:59<04:23,  5.17it/s]\n",
      " 32%|███▏      | 637/2000 [01:59<04:15,  5.34it/s]\n",
      " 32%|███▏      | 638/2000 [01:59<04:11,  5.42it/s]\n",
      " 32%|███▏      | 639/2000 [02:00<04:07,  5.49it/s]\n",
      " 32%|███▏      | 640/2000 [02:00<04:05,  5.54it/s]\n",
      " 32%|███▏      | 641/2000 [02:00<04:02,  5.61it/s]\n",
      " 32%|███▏      | 642/2000 [02:00<04:05,  5.53it/s]\n",
      " 32%|███▏      | 643/2000 [02:00<04:08,  5.47it/s]\n",
      " 32%|███▏      | 644/2000 [02:01<04:08,  5.46it/s]\n",
      " 32%|███▏      | 645/2000 [02:01<04:06,  5.50it/s]\n",
      " 32%|███▏      | 646/2000 [02:01<04:02,  5.57it/s]\n",
      " 32%|███▏      | 647/2000 [02:01<04:02,  5.58it/s]\n",
      " 32%|███▏      | 648/2000 [02:01<04:07,  5.45it/s]\n",
      " 32%|███▏      | 649/2000 [02:01<04:17,  5.26it/s]\n",
      " 32%|███▎      | 650/2000 [02:02<04:13,  5.32it/s]\n",
      "                                                  \n",
      "\n",
      " 32%|███▎      | 650/2000 [02:02<04:13,  5.32it/s]\n",
      " 33%|███▎      | 651/2000 [02:02<04:14,  5.31it/s]\n",
      " 33%|███▎      | 652/2000 [02:02<04:08,  5.42it/s]\n",
      " 33%|███▎      | 653/2000 [02:02<04:06,  5.46it/s]\n",
      " 33%|███▎      | 654/2000 [02:02<04:09,  5.40it/s]\n",
      " 33%|███▎      | 655/2000 [02:03<04:13,  5.30it/s]\n",
      " 33%|███▎      | 656/2000 [02:03<04:11,  5.35it/s]\n",
      " 33%|███▎      | 657/2000 [02:03<04:09,  5.39it/s]\n",
      " 33%|███▎      | 658/2000 [02:03<04:09,  5.38it/s]\n",
      " 33%|███▎      | 659/2000 [02:03<04:09,  5.38it/s]\n",
      " 33%|███▎      | 660/2000 [02:03<04:06,  5.43it/s]\n",
      " 33%|███▎      | 661/2000 [02:04<04:06,  5.43it/s]\n",
      " 33%|███▎      | 662/2000 [02:04<04:00,  5.56it/s]\n",
      " 33%|███▎      | 663/2000 [02:04<04:01,  5.53it/s]\n",
      " 33%|███▎      | 664/2000 [02:04<04:09,  5.35it/s]\n",
      " 33%|███▎      | 665/2000 [02:04<04:11,  5.31it/s]\n",
      " 33%|███▎      | 666/2000 [02:05<04:15,  5.21it/s]\n",
      " 33%|███▎      | 667/2000 [02:05<04:24,  5.03it/s]\n",
      " 33%|███▎      | 668/2000 [02:05<04:20,  5.12it/s]\n",
      " 33%|███▎      | 669/2000 [02:05<04:18,  5.15it/s]\n",
      " 34%|███▎      | 670/2000 [02:05<04:14,  5.23it/s]\n",
      " 34%|███▎      | 671/2000 [02:06<04:08,  5.35it/s]\n",
      " 34%|███▎      | 672/2000 [02:06<04:00,  5.51it/s]\n",
      " 34%|███▎      | 673/2000 [02:06<03:56,  5.60it/s]\n",
      " 34%|███▎      | 674/2000 [02:06<03:57,  5.58it/s]\n",
      " 34%|███▍      | 675/2000 [02:06<04:01,  5.49it/s]\n",
      " 34%|███▍      | 676/2000 [02:06<04:04,  5.41it/s]\n",
      " 34%|███▍      | 677/2000 [02:07<04:03,  5.44it/s]\n",
      " 34%|███▍      | 678/2000 [02:07<04:14,  5.19it/s]\n",
      " 34%|███▍      | 679/2000 [02:07<04:13,  5.22it/s]\n",
      " 34%|███▍      | 680/2000 [02:07<04:09,  5.29it/s]\n",
      " 34%|███▍      | 681/2000 [02:07<04:07,  5.33it/s]\n",
      " 34%|███▍      | 682/2000 [02:08<04:03,  5.41it/s]\n",
      " 34%|███▍      | 683/2000 [02:08<04:01,  5.46it/s]\n",
      " 34%|███▍      | 684/2000 [02:08<04:08,  5.29it/s]\n",
      " 34%|███▍      | 685/2000 [02:08<04:05,  5.36it/s]\n",
      " 34%|███▍      | 686/2000 [02:08<04:02,  5.41it/s]\n",
      " 34%|███▍      | 687/2000 [02:09<03:58,  5.50it/s]\n",
      " 34%|███▍      | 688/2000 [02:09<03:58,  5.51it/s]\n",
      " 34%|███▍      | 689/2000 [02:09<04:00,  5.45it/s]\n",
      " 34%|███▍      | 690/2000 [02:09<04:00,  5.44it/s]\n",
      " 35%|███▍      | 691/2000 [02:09<04:08,  5.27it/s]\n",
      " 35%|███▍      | 692/2000 [02:09<04:12,  5.19it/s]\n",
      " 35%|███▍      | 693/2000 [02:10<04:19,  5.04it/s]\n",
      " 35%|███▍      | 694/2000 [02:10<04:20,  5.02it/s]\n",
      " 35%|███▍      | 695/2000 [02:10<04:15,  5.12it/s]\n",
      " 35%|███▍      | 696/2000 [02:10<04:16,  5.09it/s]\n",
      " 35%|███▍      | 697/2000 [02:10<04:19,  5.01it/s]\n",
      " 35%|███▍      | 698/2000 [02:11<04:15,  5.09it/s]\n",
      " 35%|███▍      | 699/2000 [02:11<04:12,  5.16it/s]\n",
      " 35%|███▌      | 700/2000 [02:11<04:07,  5.25it/s]\n",
      "                                                  \n",
      "\n",
      " 35%|███▌      | 700/2000 [02:11<04:07,  5.25it/s]\n",
      " 35%|███▌      | 701/2000 [02:11<04:05,  5.29it/s]\n",
      " 35%|███▌      | 702/2000 [02:11<04:00,  5.40it/s]\n",
      " 35%|███▌      | 703/2000 [02:12<04:05,  5.29it/s]\n",
      " 35%|███▌      | 704/2000 [02:12<04:05,  5.28it/s]\n",
      " 35%|███▌      | 705/2000 [02:12<04:09,  5.18it/s]\n",
      " 35%|███▌      | 706/2000 [02:12<04:03,  5.31it/s]\n",
      " 35%|███▌      | 707/2000 [02:12<04:02,  5.33it/s]\n",
      " 35%|███▌      | 708/2000 [02:13<03:57,  5.43it/s]\n",
      " 35%|███▌      | 709/2000 [02:13<03:55,  5.48it/s]\n",
      " 36%|███▌      | 710/2000 [02:13<03:53,  5.53it/s]\n",
      " 36%|███▌      | 711/2000 [02:13<04:05,  5.24it/s]\n",
      " 36%|███▌      | 712/2000 [02:13<04:26,  4.83it/s]\n",
      " 36%|███▌      | 713/2000 [02:14<04:14,  5.06it/s]\n",
      " 36%|███▌      | 714/2000 [02:14<04:04,  5.26it/s]\n",
      " 36%|███▌      | 715/2000 [02:14<04:08,  5.16it/s]\n",
      " 36%|███▌      | 716/2000 [02:14<04:06,  5.21it/s]\n",
      " 36%|███▌      | 717/2000 [02:14<04:05,  5.23it/s]\n",
      " 36%|███▌      | 718/2000 [02:14<04:03,  5.26it/s]\n",
      " 36%|███▌      | 719/2000 [02:15<03:57,  5.39it/s]\n",
      " 36%|███▌      | 720/2000 [02:15<03:56,  5.41it/s]\n",
      " 36%|███▌      | 721/2000 [02:15<04:09,  5.12it/s]\n",
      " 36%|███▌      | 722/2000 [02:15<04:05,  5.20it/s]\n",
      " 36%|███▌      | 723/2000 [02:15<04:21,  4.88it/s]\n",
      " 36%|███▌      | 724/2000 [02:16<04:14,  5.02it/s]\n",
      " 36%|███▋      | 725/2000 [02:16<04:09,  5.10it/s]\n",
      " 36%|███▋      | 726/2000 [02:16<04:03,  5.22it/s]\n",
      " 36%|███▋      | 727/2000 [02:16<04:01,  5.28it/s]\n",
      " 36%|███▋      | 728/2000 [02:16<04:01,  5.27it/s]\n",
      " 36%|███▋      | 729/2000 [02:17<04:01,  5.26it/s]\n",
      " 36%|███▋      | 730/2000 [02:17<04:00,  5.29it/s]\n",
      " 37%|███▋      | 731/2000 [02:17<03:57,  5.35it/s]\n",
      " 37%|███▋      | 732/2000 [02:17<03:52,  5.46it/s]\n",
      " 37%|███▋      | 733/2000 [02:17<03:48,  5.54it/s]\n",
      " 37%|███▋      | 734/2000 [02:17<03:48,  5.53it/s]\n",
      " 37%|███▋      | 735/2000 [02:18<03:53,  5.42it/s]\n",
      " 37%|███▋      | 736/2000 [02:18<03:53,  5.42it/s]\n",
      " 37%|███▋      | 737/2000 [02:18<03:54,  5.39it/s]\n",
      " 37%|███▋      | 738/2000 [02:18<03:54,  5.39it/s]\n",
      " 37%|███▋      | 739/2000 [02:18<03:54,  5.39it/s]\n",
      " 37%|███▋      | 740/2000 [02:19<03:55,  5.36it/s]\n",
      " 37%|███▋      | 741/2000 [02:19<03:55,  5.35it/s]\n",
      " 37%|███▋      | 742/2000 [02:19<03:55,  5.34it/s]\n",
      " 37%|███▋      | 743/2000 [02:19<03:54,  5.37it/s]\n",
      " 37%|███▋      | 744/2000 [02:19<03:54,  5.36it/s]\n",
      " 37%|███▋      | 745/2000 [02:20<03:52,  5.41it/s]\n",
      " 37%|███▋      | 746/2000 [02:20<04:01,  5.18it/s]\n",
      " 37%|███▋      | 747/2000 [02:20<03:58,  5.26it/s]\n",
      " 37%|███▋      | 748/2000 [02:20<03:57,  5.28it/s]\n",
      " 37%|███▋      | 749/2000 [02:20<03:56,  5.30it/s]\n",
      " 38%|███▊      | 750/2000 [02:21<04:01,  5.18it/s]\n",
      "                                                  \n",
      "\n",
      " 38%|███▊      | 750/2000 [02:21<04:01,  5.18it/s]\n",
      " 38%|███▊      | 751/2000 [02:21<03:58,  5.24it/s]\n",
      " 38%|███▊      | 752/2000 [02:21<03:55,  5.30it/s]\n",
      " 38%|███▊      | 753/2000 [02:21<04:04,  5.11it/s]\n",
      " 38%|███▊      | 754/2000 [02:21<04:05,  5.08it/s]\n",
      " 38%|███▊      | 755/2000 [02:21<03:54,  5.30it/s]\n",
      " 38%|███▊      | 756/2000 [02:22<03:56,  5.27it/s]\n",
      " 38%|███▊      | 757/2000 [02:22<04:00,  5.17it/s]\n",
      " 38%|███▊      | 758/2000 [02:22<03:55,  5.27it/s]\n",
      " 38%|███▊      | 759/2000 [02:22<03:56,  5.26it/s]\n",
      " 38%|███▊      | 760/2000 [02:22<03:58,  5.20it/s]\n",
      " 38%|███▊      | 761/2000 [02:23<03:56,  5.25it/s]\n",
      " 38%|███▊      | 762/2000 [02:23<03:56,  5.24it/s]\n",
      " 38%|███▊      | 763/2000 [02:23<03:54,  5.28it/s]\n",
      " 38%|███▊      | 764/2000 [02:23<03:48,  5.40it/s]\n",
      " 38%|███▊      | 765/2000 [02:23<03:44,  5.50it/s]\n",
      " 38%|███▊      | 766/2000 [02:24<03:47,  5.42it/s]\n",
      " 38%|███▊      | 767/2000 [02:24<03:51,  5.33it/s]\n",
      " 38%|███▊      | 768/2000 [02:24<03:50,  5.35it/s]\n",
      " 38%|███▊      | 769/2000 [02:24<04:07,  4.97it/s]\n",
      " 38%|███▊      | 770/2000 [02:24<04:13,  4.84it/s]\n",
      " 39%|███▊      | 771/2000 [02:25<04:02,  5.07it/s]\n",
      " 39%|███▊      | 772/2000 [02:25<03:53,  5.27it/s]\n",
      " 39%|███▊      | 773/2000 [02:25<03:55,  5.22it/s]\n",
      " 39%|███▊      | 774/2000 [02:25<03:49,  5.34it/s]\n",
      " 39%|███▉      | 775/2000 [02:25<03:49,  5.34it/s]\n",
      " 39%|███▉      | 776/2000 [02:25<03:44,  5.45it/s]\n",
      " 39%|███▉      | 777/2000 [02:26<03:43,  5.46it/s]\n",
      " 39%|███▉      | 778/2000 [02:26<03:45,  5.43it/s]\n",
      " 39%|███▉      | 779/2000 [02:26<03:44,  5.43it/s]\n",
      " 39%|███▉      | 780/2000 [02:26<03:42,  5.47it/s]\n",
      " 39%|███▉      | 781/2000 [02:26<03:42,  5.47it/s]\n",
      " 39%|███▉      | 782/2000 [02:27<03:42,  5.48it/s]\n",
      " 39%|███▉      | 783/2000 [02:27<03:40,  5.52it/s]\n",
      " 39%|███▉      | 784/2000 [02:27<03:37,  5.59it/s]\n",
      " 39%|███▉      | 785/2000 [02:27<03:39,  5.54it/s]\n",
      " 39%|███▉      | 786/2000 [02:27<03:42,  5.45it/s]\n",
      " 39%|███▉      | 787/2000 [02:27<03:39,  5.53it/s]\n",
      " 39%|███▉      | 788/2000 [02:28<03:40,  5.50it/s]\n",
      " 39%|███▉      | 789/2000 [02:28<03:41,  5.48it/s]\n",
      " 40%|███▉      | 790/2000 [02:28<03:38,  5.54it/s]\n",
      " 40%|███▉      | 791/2000 [02:28<03:39,  5.51it/s]\n",
      " 40%|███▉      | 792/2000 [02:28<03:41,  5.45it/s]\n",
      " 40%|███▉      | 793/2000 [02:29<03:55,  5.13it/s]\n",
      " 40%|███▉      | 794/2000 [02:29<03:54,  5.15it/s]\n",
      " 40%|███▉      | 795/2000 [02:29<03:52,  5.18it/s]\n",
      " 40%|███▉      | 796/2000 [02:29<03:48,  5.26it/s]\n",
      " 40%|███▉      | 797/2000 [02:29<03:44,  5.36it/s]\n",
      " 40%|███▉      | 798/2000 [02:29<03:42,  5.41it/s]\n",
      " 40%|███▉      | 799/2000 [02:30<03:44,  5.36it/s]\n",
      " 40%|████      | 800/2000 [02:30<03:41,  5.42it/s]\n",
      "                                                  \n",
      "\n",
      " 40%|████      | 800/2000 [02:30<03:41,  5.42it/s]\n",
      " 40%|████      | 801/2000 [02:30<03:38,  5.50it/s]\n",
      " 40%|████      | 802/2000 [02:30<03:36,  5.53it/s]\n",
      " 40%|████      | 803/2000 [02:30<03:47,  5.27it/s]\n",
      " 40%|████      | 804/2000 [02:31<03:46,  5.27it/s]\n",
      " 40%|████      | 805/2000 [02:31<03:48,  5.22it/s]\n",
      " 40%|████      | 806/2000 [02:31<03:48,  5.22it/s]\n",
      " 40%|████      | 807/2000 [02:31<03:46,  5.28it/s]\n",
      " 40%|████      | 808/2000 [02:31<03:39,  5.43it/s]\n",
      " 40%|████      | 809/2000 [02:32<03:39,  5.43it/s]\n",
      " 40%|████      | 810/2000 [02:32<03:36,  5.49it/s]\n",
      " 41%|████      | 811/2000 [02:32<03:37,  5.47it/s]\n",
      " 41%|████      | 812/2000 [02:32<03:39,  5.41it/s]\n",
      " 41%|████      | 813/2000 [02:32<03:37,  5.47it/s]\n",
      " 41%|████      | 814/2000 [02:32<03:35,  5.50it/s]\n",
      " 41%|████      | 815/2000 [02:33<03:33,  5.55it/s]\n",
      " 41%|████      | 816/2000 [02:33<03:33,  5.55it/s]\n",
      " 41%|████      | 817/2000 [02:33<03:31,  5.58it/s]\n",
      " 41%|████      | 818/2000 [02:33<03:37,  5.45it/s]\n",
      " 41%|████      | 819/2000 [02:33<03:36,  5.47it/s]\n",
      " 41%|████      | 820/2000 [02:34<03:31,  5.57it/s]\n",
      " 41%|████      | 821/2000 [02:34<03:33,  5.51it/s]\n",
      " 41%|████      | 822/2000 [02:34<03:52,  5.08it/s]\n",
      " 41%|████      | 823/2000 [02:34<03:53,  5.04it/s]\n",
      " 41%|████      | 824/2000 [02:34<04:02,  4.85it/s]\n",
      " 41%|████▏     | 825/2000 [02:35<04:01,  4.86it/s]\n",
      " 41%|████▏     | 826/2000 [02:35<03:58,  4.92it/s]\n",
      " 41%|████▏     | 827/2000 [02:35<03:53,  5.02it/s]\n",
      " 41%|████▏     | 828/2000 [02:35<03:58,  4.91it/s]\n",
      " 41%|████▏     | 829/2000 [02:35<04:00,  4.87it/s]\n",
      " 42%|████▏     | 830/2000 [02:36<03:54,  5.00it/s]\n",
      " 42%|████▏     | 831/2000 [02:36<03:55,  4.96it/s]\n",
      " 42%|████▏     | 832/2000 [02:36<03:56,  4.94it/s]\n",
      " 42%|████▏     | 833/2000 [02:36<03:46,  5.16it/s]\n",
      " 42%|████▏     | 834/2000 [02:36<03:48,  5.11it/s]\n",
      " 42%|████▏     | 835/2000 [02:37<03:44,  5.19it/s]\n",
      " 42%|████▏     | 836/2000 [02:37<03:38,  5.32it/s]\n",
      " 42%|████▏     | 837/2000 [02:37<03:38,  5.32it/s]\n",
      " 42%|████▏     | 838/2000 [02:37<03:42,  5.22it/s]\n",
      " 42%|████▏     | 839/2000 [02:37<03:46,  5.12it/s]\n",
      " 42%|████▏     | 840/2000 [02:38<03:39,  5.29it/s]\n",
      " 42%|████▏     | 841/2000 [02:38<03:37,  5.34it/s]\n",
      " 42%|████▏     | 842/2000 [02:38<03:33,  5.43it/s]\n",
      " 42%|████▏     | 843/2000 [02:38<03:31,  5.47it/s]\n",
      " 42%|████▏     | 844/2000 [02:38<03:34,  5.38it/s]\n",
      " 42%|████▏     | 845/2000 [02:38<03:40,  5.24it/s]\n",
      " 42%|████▏     | 846/2000 [02:39<03:34,  5.37it/s]\n",
      " 42%|████▏     | 847/2000 [02:39<03:36,  5.33it/s]\n",
      " 42%|████▏     | 848/2000 [02:39<03:34,  5.38it/s]\n",
      " 42%|████▏     | 849/2000 [02:39<03:33,  5.39it/s]\n",
      " 42%|████▎     | 850/2000 [02:39<03:36,  5.32it/s]\n",
      "                                                  \n",
      "\n",
      " 42%|████▎     | 850/2000 [02:39<03:36,  5.32it/s]\n",
      " 43%|████▎     | 851/2000 [02:40<03:39,  5.23it/s]\n",
      " 43%|████▎     | 852/2000 [02:40<03:34,  5.36it/s]\n",
      " 43%|████▎     | 853/2000 [02:40<03:31,  5.43it/s]\n",
      " 43%|████▎     | 854/2000 [02:40<03:28,  5.50it/s]\n",
      " 43%|████▎     | 855/2000 [02:40<03:29,  5.45it/s]\n",
      " 43%|████▎     | 856/2000 [02:40<03:30,  5.42it/s]\n",
      " 43%|████▎     | 857/2000 [02:41<03:30,  5.44it/s]\n",
      " 43%|████▎     | 858/2000 [02:41<03:31,  5.40it/s]\n",
      " 43%|████▎     | 859/2000 [02:41<03:28,  5.48it/s]\n",
      " 43%|████▎     | 860/2000 [02:41<03:29,  5.45it/s]\n",
      " 43%|████▎     | 861/2000 [02:41<03:25,  5.55it/s]\n",
      " 43%|████▎     | 862/2000 [02:42<03:26,  5.50it/s]\n",
      " 43%|████▎     | 863/2000 [02:42<03:26,  5.51it/s]\n",
      " 43%|████▎     | 864/2000 [02:42<03:28,  5.45it/s]\n",
      " 43%|████▎     | 865/2000 [02:42<03:30,  5.40it/s]\n",
      " 43%|████▎     | 866/2000 [02:42<03:30,  5.40it/s]\n",
      " 43%|████▎     | 867/2000 [02:42<03:27,  5.47it/s]\n",
      " 43%|████▎     | 868/2000 [02:43<03:28,  5.44it/s]\n",
      " 43%|████▎     | 869/2000 [02:43<03:36,  5.23it/s]\n",
      " 44%|████▎     | 870/2000 [02:43<03:40,  5.13it/s]\n",
      " 44%|████▎     | 871/2000 [02:43<03:36,  5.21it/s]\n",
      " 44%|████▎     | 872/2000 [02:43<03:40,  5.13it/s]\n",
      " 44%|████▎     | 873/2000 [02:44<03:32,  5.30it/s]\n",
      " 44%|████▎     | 874/2000 [02:44<03:30,  5.35it/s]\n",
      " 44%|████▍     | 875/2000 [02:44<03:27,  5.43it/s]\n",
      " 44%|████▍     | 876/2000 [02:44<03:27,  5.41it/s]\n",
      " 44%|████▍     | 877/2000 [02:44<03:32,  5.29it/s]\n",
      " 44%|████▍     | 878/2000 [02:45<03:32,  5.29it/s]\n",
      " 44%|████▍     | 879/2000 [02:45<03:31,  5.31it/s]\n",
      " 44%|████▍     | 880/2000 [02:45<03:26,  5.42it/s]\n",
      " 44%|████▍     | 881/2000 [02:45<03:27,  5.41it/s]\n",
      " 44%|████▍     | 882/2000 [02:45<03:33,  5.24it/s]\n",
      " 44%|████▍     | 883/2000 [02:46<03:36,  5.17it/s]\n",
      " 44%|████▍     | 884/2000 [02:46<03:33,  5.23it/s]\n",
      " 44%|████▍     | 885/2000 [02:46<03:30,  5.29it/s]\n",
      " 44%|████▍     | 886/2000 [02:46<03:29,  5.33it/s]\n",
      " 44%|████▍     | 887/2000 [02:46<03:26,  5.40it/s]\n",
      " 44%|████▍     | 888/2000 [02:46<03:25,  5.40it/s]\n",
      " 44%|████▍     | 889/2000 [02:47<03:24,  5.43it/s]\n",
      " 44%|████▍     | 890/2000 [02:47<03:22,  5.49it/s]\n",
      " 45%|████▍     | 891/2000 [02:47<03:19,  5.56it/s]\n",
      " 45%|████▍     | 892/2000 [02:47<03:19,  5.56it/s]\n",
      " 45%|████▍     | 893/2000 [02:47<03:17,  5.61it/s]\n",
      " 45%|████▍     | 894/2000 [02:48<03:20,  5.52it/s]\n",
      " 45%|████▍     | 895/2000 [02:48<03:22,  5.46it/s]\n",
      " 45%|████▍     | 896/2000 [02:48<03:19,  5.54it/s]\n",
      " 45%|████▍     | 897/2000 [02:48<03:21,  5.48it/s]\n",
      " 45%|████▍     | 898/2000 [02:48<03:23,  5.42it/s]\n",
      " 45%|████▍     | 899/2000 [02:48<03:24,  5.39it/s]\n",
      " 45%|████▌     | 900/2000 [02:49<03:20,  5.50it/s]\n",
      "                                                  \n",
      "\n",
      " 45%|████▌     | 900/2000 [02:49<03:20,  5.50it/s]\n",
      " 45%|████▌     | 901/2000 [02:49<03:20,  5.49it/s]\n",
      " 45%|████▌     | 902/2000 [02:49<03:17,  5.56it/s]\n",
      " 45%|████▌     | 903/2000 [02:49<03:25,  5.34it/s]\n",
      " 45%|████▌     | 904/2000 [02:49<03:19,  5.49it/s]\n",
      " 45%|████▌     | 905/2000 [02:50<03:19,  5.49it/s]\n",
      " 45%|████▌     | 906/2000 [02:50<03:16,  5.56it/s]\n",
      " 45%|████▌     | 907/2000 [02:50<03:17,  5.54it/s]\n",
      " 45%|████▌     | 908/2000 [02:50<03:20,  5.46it/s]\n",
      " 45%|████▌     | 909/2000 [02:50<03:21,  5.42it/s]\n",
      " 46%|████▌     | 910/2000 [02:50<03:22,  5.39it/s]\n",
      " 46%|████▌     | 911/2000 [02:51<03:20,  5.43it/s]\n",
      " 46%|████▌     | 912/2000 [02:51<03:17,  5.50it/s]\n",
      " 46%|████▌     | 913/2000 [02:51<03:17,  5.50it/s]\n",
      " 46%|████▌     | 914/2000 [02:51<03:15,  5.55it/s]\n",
      " 46%|████▌     | 915/2000 [02:51<03:16,  5.51it/s]\n",
      " 46%|████▌     | 916/2000 [02:52<03:14,  5.59it/s]\n",
      " 46%|████▌     | 917/2000 [02:52<03:13,  5.58it/s]\n",
      " 46%|████▌     | 918/2000 [02:52<03:29,  5.16it/s]\n",
      " 46%|████▌     | 919/2000 [02:52<03:27,  5.22it/s]\n",
      " 46%|████▌     | 920/2000 [02:52<03:25,  5.24it/s]\n",
      " 46%|████▌     | 921/2000 [02:52<03:24,  5.27it/s]\n",
      " 46%|████▌     | 922/2000 [02:53<03:19,  5.41it/s]\n",
      " 46%|████▌     | 923/2000 [02:53<03:19,  5.41it/s]\n",
      " 46%|████▌     | 924/2000 [02:53<03:15,  5.51it/s]\n",
      " 46%|████▋     | 925/2000 [02:53<03:16,  5.46it/s]\n",
      " 46%|████▋     | 926/2000 [02:53<03:16,  5.45it/s]\n",
      " 46%|████▋     | 927/2000 [02:54<03:17,  5.42it/s]\n",
      " 46%|████▋     | 928/2000 [02:54<03:15,  5.49it/s]\n",
      " 46%|████▋     | 929/2000 [02:54<03:15,  5.46it/s]\n",
      " 46%|████▋     | 930/2000 [02:54<03:22,  5.28it/s]\n",
      " 47%|████▋     | 931/2000 [02:54<03:21,  5.31it/s]\n",
      " 47%|████▋     | 932/2000 [02:55<03:20,  5.32it/s]\n",
      " 47%|████▋     | 933/2000 [02:55<03:20,  5.32it/s]\n",
      " 47%|████▋     | 934/2000 [02:55<03:20,  5.33it/s]\n",
      " 47%|████▋     | 935/2000 [02:55<03:22,  5.25it/s]\n",
      " 47%|████▋     | 936/2000 [02:55<03:23,  5.24it/s]\n",
      " 47%|████▋     | 937/2000 [02:55<03:21,  5.28it/s]\n",
      " 47%|████▋     | 938/2000 [02:56<03:16,  5.40it/s]\n",
      " 47%|████▋     | 939/2000 [02:56<03:25,  5.17it/s]\n",
      " 47%|████▋     | 940/2000 [02:56<03:23,  5.21it/s]\n",
      " 47%|████▋     | 941/2000 [02:56<03:21,  5.25it/s]\n",
      " 47%|████▋     | 942/2000 [02:56<03:19,  5.31it/s]\n",
      " 47%|████▋     | 943/2000 [02:57<03:15,  5.40it/s]\n",
      " 47%|████▋     | 944/2000 [02:57<03:10,  5.53it/s]\n",
      " 47%|████▋     | 945/2000 [02:57<03:14,  5.43it/s]\n",
      " 47%|████▋     | 946/2000 [02:57<03:16,  5.37it/s]\n",
      " 47%|████▋     | 947/2000 [02:57<03:15,  5.38it/s]\n",
      " 47%|████▋     | 948/2000 [02:58<03:16,  5.37it/s]\n",
      " 47%|████▋     | 949/2000 [02:58<03:15,  5.38it/s]\n",
      " 48%|████▊     | 950/2000 [02:58<03:11,  5.49it/s]\n",
      "                                                  \n",
      "\n",
      " 48%|████▊     | 950/2000 [02:58<03:11,  5.49it/s]\n",
      " 48%|████▊     | 951/2000 [02:58<03:21,  5.21it/s]\n",
      " 48%|████▊     | 952/2000 [02:58<03:16,  5.33it/s]\n",
      " 48%|████▊     | 953/2000 [02:58<03:15,  5.34it/s]\n",
      " 48%|████▊     | 954/2000 [02:59<03:15,  5.35it/s]\n",
      " 48%|████▊     | 955/2000 [02:59<03:15,  5.35it/s]\n",
      " 48%|████▊     | 956/2000 [02:59<03:11,  5.46it/s]\n",
      " 48%|████▊     | 957/2000 [02:59<03:11,  5.46it/s]\n",
      " 48%|████▊     | 958/2000 [02:59<03:08,  5.54it/s]\n",
      " 48%|████▊     | 959/2000 [03:00<03:10,  5.47it/s]\n",
      " 48%|████▊     | 960/2000 [03:00<03:10,  5.45it/s]\n",
      " 48%|████▊     | 961/2000 [03:00<03:12,  5.39it/s]\n",
      " 48%|████▊     | 962/2000 [03:00<03:11,  5.41it/s]\n",
      " 48%|████▊     | 963/2000 [03:00<03:19,  5.20it/s]\n",
      " 48%|████▊     | 964/2000 [03:01<03:16,  5.27it/s]\n",
      " 48%|████▊     | 965/2000 [03:01<03:14,  5.33it/s]\n",
      " 48%|████▊     | 966/2000 [03:01<03:10,  5.44it/s]\n",
      " 48%|████▊     | 967/2000 [03:01<03:14,  5.30it/s]\n",
      " 48%|████▊     | 968/2000 [03:01<03:15,  5.28it/s]\n",
      " 48%|████▊     | 969/2000 [03:01<03:13,  5.33it/s]\n",
      " 48%|████▊     | 970/2000 [03:02<03:10,  5.41it/s]\n",
      " 49%|████▊     | 971/2000 [03:02<03:15,  5.26it/s]\n",
      " 49%|████▊     | 972/2000 [03:02<03:13,  5.33it/s]\n",
      " 49%|████▊     | 973/2000 [03:02<03:13,  5.32it/s]\n",
      " 49%|████▊     | 974/2000 [03:02<03:17,  5.20it/s]\n",
      " 49%|████▉     | 975/2000 [03:03<03:16,  5.22it/s]\n",
      " 49%|████▉     | 976/2000 [03:03<03:20,  5.11it/s]\n",
      " 49%|████▉     | 977/2000 [03:03<03:25,  4.97it/s]\n",
      " 49%|████▉     | 978/2000 [03:03<03:26,  4.94it/s]\n",
      " 49%|████▉     | 979/2000 [03:03<03:20,  5.08it/s]\n",
      " 49%|████▉     | 980/2000 [03:04<03:16,  5.18it/s]\n",
      " 49%|████▉     | 981/2000 [03:04<03:11,  5.33it/s]\n",
      " 49%|████▉     | 982/2000 [03:04<03:08,  5.39it/s]\n",
      " 49%|████▉     | 983/2000 [03:04<03:04,  5.50it/s]\n",
      " 49%|████▉     | 984/2000 [03:04<03:04,  5.51it/s]\n",
      " 49%|████▉     | 985/2000 [03:04<03:01,  5.58it/s]\n",
      " 49%|████▉     | 986/2000 [03:05<03:04,  5.51it/s]\n",
      " 49%|████▉     | 987/2000 [03:05<03:01,  5.57it/s]\n",
      " 49%|████▉     | 988/2000 [03:05<02:58,  5.66it/s]\n",
      " 49%|████▉     | 989/2000 [03:05<03:01,  5.58it/s]\n",
      " 50%|████▉     | 990/2000 [03:05<02:59,  5.62it/s]\n",
      " 50%|████▉     | 991/2000 [03:06<03:00,  5.59it/s]\n",
      " 50%|████▉     | 992/2000 [03:06<03:07,  5.39it/s]\n",
      " 50%|████▉     | 993/2000 [03:06<03:05,  5.42it/s]\n",
      " 50%|████▉     | 994/2000 [03:06<03:08,  5.33it/s]\n",
      " 50%|████▉     | 995/2000 [03:06<03:09,  5.30it/s]\n",
      " 50%|████▉     | 996/2000 [03:07<03:14,  5.16it/s]\n",
      " 50%|████▉     | 997/2000 [03:07<03:12,  5.20it/s]\n",
      " 50%|████▉     | 998/2000 [03:07<03:22,  4.94it/s]\n",
      " 50%|████▉     | 999/2000 [03:07<03:18,  5.05it/s]\n",
      " 50%|█████     | 1000/2000 [03:07<03:14,  5.14it/s]\n",
      "                                                   \n",
      "\n",
      " 50%|█████     | 1000/2000 [03:07<03:14,  5.14it/s][INFO|trainer.py:3213] 2024-01-26 01:24:30,646 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:24:30,646 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:24:30,646 >>   Batch size = 8\n",
      "[INFO|configuration_utils.py:770] 2024-01-26 01:24:30,649 >> Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  1%|          | 2/250 [00:00<00:13, 18.47it/s]\u001b[A\n",
      "\n",
      "  2%|▏         | 4/250 [00:00<00:23, 10.41it/s]\u001b[A\n",
      "\n",
      "  2%|▏         | 6/250 [00:00<00:24,  9.79it/s]\u001b[A\n",
      "\n",
      "  3%|▎         | 8/250 [00:00<00:25,  9.58it/s]\u001b[A\n",
      "\n",
      "  4%|▍         | 10/250 [00:00<00:24,  9.62it/s]\u001b[A\n",
      "\n",
      "  5%|▍         | 12/250 [00:01<00:23,  9.94it/s]\u001b[A\n",
      "\n",
      "  6%|▌         | 14/250 [00:01<00:23,  9.85it/s]\u001b[A\n",
      "\n",
      "  6%|▋         | 16/250 [00:01<00:24,  9.71it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 17/250 [00:01<00:24,  9.69it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 18/250 [00:01<00:23,  9.70it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 19/250 [00:01<00:24,  9.46it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 20/250 [00:02<00:24,  9.52it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 21/250 [00:02<00:24,  9.53it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 22/250 [00:02<00:24,  9.44it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 23/250 [00:02<00:23,  9.50it/s]\u001b[A\n",
      "\n",
      " 10%|▉         | 24/250 [00:02<00:24,  9.09it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 25/250 [00:02<00:25,  8.97it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 26/250 [00:02<00:25,  8.75it/s]\u001b[A\n",
      "\n",
      " 11%|█         | 27/250 [00:02<00:25,  8.80it/s]\u001b[A\n",
      "\n",
      " 11%|█         | 28/250 [00:02<00:24,  9.08it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 29/250 [00:03<00:24,  9.01it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 31/250 [00:03<00:22,  9.62it/s]\u001b[A\n",
      "\n",
      " 13%|█▎        | 33/250 [00:03<00:22,  9.69it/s]\u001b[A\n",
      "\n",
      " 14%|█▎        | 34/250 [00:03<00:22,  9.66it/s]\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/250 [00:03<00:22,  9.54it/s]\u001b[A\n",
      "\n",
      " 14%|█▍        | 36/250 [00:03<00:22,  9.52it/s]\u001b[A\n",
      "\n",
      " 15%|█▍        | 37/250 [00:03<00:22,  9.39it/s]\u001b[A\n",
      "\n",
      " 16%|█▌        | 39/250 [00:04<00:21,  9.67it/s]\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/250 [00:04<00:22,  9.47it/s]\u001b[A\n",
      "\n",
      " 16%|█▋        | 41/250 [00:04<00:22,  9.37it/s]\u001b[A\n",
      "\n",
      " 17%|█▋        | 43/250 [00:04<00:21,  9.70it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 44/250 [00:04<00:21,  9.69it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/250 [00:04<00:21,  9.59it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 46/250 [00:04<00:21,  9.43it/s]\u001b[A\n",
      "\n",
      " 19%|█▉        | 47/250 [00:04<00:22,  9.01it/s]\u001b[A\n",
      "\n",
      " 19%|█▉        | 48/250 [00:05<00:22,  8.98it/s]\u001b[A\n",
      "\n",
      " 20%|█▉        | 49/250 [00:05<00:22,  8.85it/s]\u001b[A\n",
      "\n",
      " 20%|██        | 50/250 [00:05<00:22,  8.89it/s]\u001b[A\n",
      "\n",
      " 21%|██        | 52/250 [00:05<00:21,  9.27it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 54/250 [00:05<00:19,  9.92it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/250 [00:05<00:19,  9.81it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 56/250 [00:05<00:19,  9.84it/s]\u001b[A\n",
      "\n",
      " 23%|██▎       | 58/250 [00:06<00:19,  9.98it/s]\u001b[A\n",
      "\n",
      " 24%|██▎       | 59/250 [00:06<00:19,  9.81it/s]\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/250 [00:06<00:19,  9.53it/s]\u001b[A\n",
      "\n",
      " 24%|██▍       | 61/250 [00:06<00:21,  8.77it/s]\u001b[A\n",
      "\n",
      " 25%|██▍       | 62/250 [00:06<00:21,  8.66it/s]\u001b[A\n",
      "\n",
      " 25%|██▌       | 63/250 [00:06<00:21,  8.86it/s]\u001b[A\n",
      "\n",
      " 26%|██▌       | 64/250 [00:06<00:20,  8.92it/s]\u001b[A\n",
      "\n",
      " 26%|██▌       | 65/250 [00:06<00:20,  8.99it/s]\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:06<00:20,  9.09it/s]\u001b[A\n",
      "\n",
      " 27%|██▋       | 67/250 [00:07<00:19,  9.18it/s]\u001b[A\n",
      "\n",
      " 27%|██▋       | 68/250 [00:07<00:20,  9.05it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 69/250 [00:07<00:20,  8.67it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/250 [00:07<00:20,  8.72it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 71/250 [00:07<00:21,  8.15it/s]\u001b[A\n",
      "\n",
      " 29%|██▉       | 72/250 [00:07<00:20,  8.50it/s]\u001b[A\n",
      "\n",
      " 29%|██▉       | 73/250 [00:07<00:20,  8.61it/s]\u001b[A\n",
      "\n",
      " 30%|██▉       | 74/250 [00:07<00:19,  8.92it/s]\u001b[A\n",
      "\n",
      " 30%|███       | 75/250 [00:07<00:19,  9.07it/s]\u001b[A\n",
      "\n",
      " 30%|███       | 76/250 [00:08<00:19,  8.87it/s]\u001b[A\n",
      "\n",
      " 31%|███       | 77/250 [00:08<00:19,  8.85it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 79/250 [00:08<00:18,  9.30it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/250 [00:08<00:18,  9.23it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 81/250 [00:08<00:18,  9.06it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 82/250 [00:08<00:18,  9.28it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 83/250 [00:08<00:19,  8.57it/s]\u001b[A\n",
      "\n",
      " 34%|███▎      | 84/250 [00:09<00:19,  8.59it/s]\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/250 [00:09<00:18,  8.86it/s]\u001b[A\n",
      "\n",
      " 34%|███▍      | 86/250 [00:09<00:18,  9.07it/s]\u001b[A\n",
      "\n",
      " 35%|███▍      | 87/250 [00:09<00:18,  8.90it/s]\u001b[A\n",
      "\n",
      " 35%|███▌      | 88/250 [00:09<00:17,  9.08it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 90/250 [00:09<00:16,  9.44it/s]\u001b[A\n",
      "\n",
      " 36%|███▋      | 91/250 [00:09<00:17,  9.27it/s]\u001b[A\n",
      "\n",
      " 37%|███▋      | 92/250 [00:09<00:16,  9.40it/s]\u001b[A\n",
      "\n",
      " 37%|███▋      | 93/250 [00:09<00:16,  9.44it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 94/250 [00:10<00:16,  9.54it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 96/250 [00:10<00:16,  9.51it/s]\u001b[A\n",
      "\n",
      " 39%|███▉      | 97/250 [00:10<00:16,  9.54it/s]\u001b[A\n",
      "\n",
      " 40%|███▉      | 99/250 [00:10<00:15,  9.64it/s]\u001b[A\n",
      "\n",
      " 40%|████      | 100/250 [00:10<00:15,  9.65it/s]\u001b[A\n",
      "\n",
      " 40%|████      | 101/250 [00:10<00:17,  8.72it/s]\u001b[A\n",
      "\n",
      " 41%|████      | 102/250 [00:10<00:16,  8.72it/s]\u001b[A\n",
      "\n",
      " 41%|████      | 103/250 [00:11<00:16,  8.90it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 104/250 [00:11<00:16,  9.02it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 105/250 [00:11<00:16,  9.01it/s]\u001b[A\n",
      "\n",
      " 43%|████▎     | 107/250 [00:11<00:15,  9.24it/s]\u001b[A\n",
      "\n",
      " 43%|████▎     | 108/250 [00:11<00:15,  9.21it/s]\u001b[A\n",
      "\n",
      " 44%|████▎     | 109/250 [00:11<00:15,  9.22it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 110/250 [00:11<00:15,  8.85it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 111/250 [00:11<00:15,  9.03it/s]\u001b[A\n",
      "\n",
      " 45%|████▍     | 112/250 [00:12<00:15,  9.18it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 114/250 [00:12<00:13,  9.91it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 115/250 [00:12<00:13,  9.84it/s]\u001b[A\n",
      "\n",
      " 46%|████▋     | 116/250 [00:12<00:13,  9.83it/s]\u001b[A\n",
      "\n",
      " 47%|████▋     | 117/250 [00:12<00:13,  9.84it/s]\u001b[A\n",
      "\n",
      " 47%|████▋     | 118/250 [00:12<00:13,  9.74it/s]\u001b[A\n",
      "\n",
      " 48%|████▊     | 120/250 [00:12<00:12, 10.13it/s]\u001b[A\n",
      "\n",
      " 49%|████▉     | 122/250 [00:13<00:12, 10.19it/s]\u001b[A\n",
      "\n",
      " 50%|████▉     | 124/250 [00:13<00:12,  9.76it/s]\u001b[A\n",
      "\n",
      " 50%|█████     | 125/250 [00:13<00:13,  9.56it/s]\u001b[A\n",
      "\n",
      " 50%|█████     | 126/250 [00:13<00:12,  9.66it/s]\u001b[A\n",
      "\n",
      " 51%|█████     | 128/250 [00:13<00:12,  9.77it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 129/250 [00:13<00:13,  9.14it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 130/250 [00:13<00:12,  9.23it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 131/250 [00:13<00:12,  9.18it/s]\u001b[A\n",
      "\n",
      " 53%|█████▎    | 133/250 [00:14<00:13,  8.68it/s]\u001b[A\n",
      "\n",
      " 54%|█████▎    | 134/250 [00:14<00:14,  8.27it/s]\u001b[A\n",
      "\n",
      " 54%|█████▍    | 135/250 [00:14<00:13,  8.43it/s]\u001b[A\n",
      "\n",
      " 54%|█████▍    | 136/250 [00:14<00:13,  8.70it/s]\u001b[A\n",
      "\n",
      " 55%|█████▍    | 137/250 [00:14<00:12,  8.74it/s]\u001b[A\n",
      "\n",
      " 55%|█████▌    | 138/250 [00:14<00:12,  8.91it/s]\u001b[A\n",
      "\n",
      " 56%|█████▌    | 139/250 [00:14<00:12,  8.91it/s]\u001b[A\n",
      "\n",
      " 56%|█████▌    | 140/250 [00:15<00:12,  9.12it/s]\u001b[A\n",
      "\n",
      " 57%|█████▋    | 142/250 [00:15<00:11,  9.28it/s]\u001b[A\n",
      "\n",
      " 57%|█████▋    | 143/250 [00:15<00:11,  9.35it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 144/250 [00:15<00:11,  9.13it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 145/250 [00:15<00:11,  9.17it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 146/250 [00:15<00:11,  9.06it/s]\u001b[A\n",
      "\n",
      " 59%|█████▉    | 148/250 [00:15<00:10,  9.31it/s]\u001b[A\n",
      "\n",
      " 60%|█████▉    | 149/250 [00:16<00:10,  9.33it/s]\u001b[A\n",
      "\n",
      " 60%|██████    | 150/250 [00:16<00:10,  9.46it/s]\u001b[A\n",
      "\n",
      " 60%|██████    | 151/250 [00:16<00:10,  9.29it/s]\u001b[A\n",
      "\n",
      " 61%|██████    | 152/250 [00:16<00:10,  9.19it/s]\u001b[A\n",
      "\n",
      " 61%|██████    | 153/250 [00:16<00:10,  9.13it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 154/250 [00:16<00:11,  8.22it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 155/250 [00:16<00:11,  8.57it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 156/250 [00:16<00:10,  8.67it/s]\u001b[A\n",
      "\n",
      " 63%|██████▎   | 158/250 [00:17<00:10,  9.04it/s]\u001b[A\n",
      "\n",
      " 64%|██████▎   | 159/250 [00:17<00:10,  8.97it/s]\u001b[A\n",
      "\n",
      " 64%|██████▍   | 160/250 [00:17<00:09,  9.08it/s]\u001b[A\n",
      "\n",
      " 64%|██████▍   | 161/250 [00:17<00:09,  9.01it/s]\u001b[A\n",
      "\n",
      " 65%|██████▍   | 162/250 [00:17<00:09,  9.12it/s]\u001b[A\n",
      "\n",
      " 65%|██████▌   | 163/250 [00:17<00:09,  9.13it/s]\u001b[A\n",
      "\n",
      " 66%|██████▌   | 164/250 [00:17<00:09,  8.87it/s]\u001b[A\n",
      "\n",
      " 66%|██████▌   | 165/250 [00:17<00:09,  8.75it/s]\u001b[A\n",
      "\n",
      " 66%|██████▋   | 166/250 [00:17<00:09,  8.51it/s]\u001b[A\n",
      "\n",
      " 67%|██████▋   | 167/250 [00:18<00:09,  8.43it/s]\u001b[A\n",
      "\n",
      " 67%|██████▋   | 168/250 [00:18<00:09,  8.65it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 169/250 [00:18<00:09,  8.91it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 170/250 [00:18<00:08,  8.94it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 171/250 [00:18<00:08,  9.16it/s]\u001b[A\n",
      "\n",
      " 69%|██████▉   | 172/250 [00:18<00:08,  9.00it/s]\u001b[A\n",
      "\n",
      " 69%|██████▉   | 173/250 [00:18<00:08,  8.91it/s]\u001b[A\n",
      "\n",
      " 70%|██████▉   | 174/250 [00:18<00:08,  8.88it/s]\u001b[A\n",
      "\n",
      " 70%|███████   | 175/250 [00:18<00:08,  8.89it/s]\u001b[A\n",
      "\n",
      " 70%|███████   | 176/250 [00:19<00:08,  8.73it/s]\u001b[A\n",
      "\n",
      " 71%|███████   | 177/250 [00:19<00:08,  8.92it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 179/250 [00:19<00:07,  9.37it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 180/250 [00:19<00:07,  9.19it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 181/250 [00:19<00:07,  9.21it/s]\u001b[A\n",
      "\n",
      " 73%|███████▎  | 183/250 [00:19<00:07,  9.36it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 185/250 [00:19<00:06,  9.78it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 186/250 [00:20<00:06,  9.37it/s]\u001b[A\n",
      "\n",
      " 75%|███████▍  | 187/250 [00:20<00:06,  9.17it/s]\u001b[A\n",
      "\n",
      " 75%|███████▌  | 188/250 [00:20<00:07,  8.81it/s]\u001b[A\n",
      "\n",
      " 76%|███████▌  | 189/250 [00:20<00:07,  8.43it/s]\u001b[A\n",
      "\n",
      " 76%|███████▌  | 190/250 [00:20<00:06,  8.60it/s]\u001b[A\n",
      "\n",
      " 76%|███████▋  | 191/250 [00:20<00:06,  8.53it/s]\u001b[A\n",
      "\n",
      " 77%|███████▋  | 192/250 [00:20<00:06,  8.61it/s]\u001b[A\n",
      "\n",
      " 77%|███████▋  | 193/250 [00:20<00:06,  8.53it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:21<00:06,  8.83it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 195/250 [00:21<00:06,  9.01it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 196/250 [00:21<00:05,  9.04it/s]\u001b[A\n",
      "\n",
      " 79%|███████▉  | 197/250 [00:21<00:05,  9.16it/s]\u001b[A\n",
      "\n",
      " 79%|███████▉  | 198/250 [00:21<00:05,  9.20it/s]\u001b[A\n",
      "\n",
      " 80%|███████▉  | 199/250 [00:21<00:05,  9.23it/s]\u001b[A\n",
      "\n",
      " 80%|████████  | 201/250 [00:21<00:05,  9.72it/s]\u001b[A\n",
      "\n",
      " 81%|████████  | 203/250 [00:21<00:04,  9.52it/s]\u001b[A\n",
      "\n",
      " 82%|████████▏ | 204/250 [00:22<00:04,  9.36it/s]\u001b[A\n",
      "\n",
      " 82%|████████▏ | 205/250 [00:22<00:04,  9.42it/s]\u001b[A\n",
      "\n",
      " 82%|████████▏ | 206/250 [00:22<00:04,  9.41it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 207/250 [00:22<00:04,  9.37it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 208/250 [00:22<00:04,  8.82it/s]\u001b[A\n",
      "\n",
      " 84%|████████▎ | 209/250 [00:22<00:04,  8.77it/s]\u001b[A\n",
      "\n",
      " 84%|████████▍ | 211/250 [00:22<00:04,  9.06it/s]\u001b[A\n",
      "\n",
      " 85%|████████▍ | 212/250 [00:22<00:04,  9.15it/s]\u001b[A\n",
      "\n",
      " 85%|████████▌ | 213/250 [00:23<00:04,  9.14it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 214/250 [00:23<00:03,  9.08it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 215/250 [00:23<00:03,  8.77it/s]\u001b[A\n",
      "\n",
      " 86%|████████▋ | 216/250 [00:23<00:03,  9.01it/s]\u001b[A\n",
      "\n",
      " 87%|████████▋ | 217/250 [00:23<00:03,  9.20it/s]\u001b[A\n",
      "\n",
      " 87%|████████▋ | 218/250 [00:23<00:03,  9.35it/s]\u001b[A\n",
      "\n",
      " 88%|████████▊ | 219/250 [00:23<00:03,  9.14it/s]\u001b[A\n",
      "\n",
      " 88%|████████▊ | 220/250 [00:23<00:03,  9.13it/s]\u001b[A\n",
      "\n",
      " 89%|████████▉ | 222/250 [00:24<00:02,  9.46it/s]\u001b[A\n",
      "\n",
      " 90%|████████▉ | 224/250 [00:24<00:02,  9.25it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 225/250 [00:24<00:02,  9.00it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 226/250 [00:24<00:02,  9.03it/s]\u001b[A\n",
      "\n",
      " 91%|█████████ | 227/250 [00:24<00:02,  8.97it/s]\u001b[A\n",
      "\n",
      " 91%|█████████ | 228/250 [00:24<00:02,  8.90it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 229/250 [00:24<00:02,  8.67it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 230/250 [00:24<00:02,  8.77it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 231/250 [00:25<00:02,  8.73it/s]\u001b[A\n",
      "\n",
      " 93%|█████████▎| 232/250 [00:25<00:02,  8.86it/s]\u001b[A\n",
      "\n",
      " 93%|█████████▎| 233/250 [00:25<00:01,  8.99it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▎| 234/250 [00:25<00:01,  9.12it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▍| 235/250 [00:25<00:01,  9.23it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▍| 236/250 [00:25<00:01,  9.33it/s]\u001b[A\n",
      "\n",
      " 95%|█████████▍| 237/250 [00:25<00:01,  9.26it/s]\u001b[A\n",
      "\n",
      " 96%|█████████▌| 239/250 [00:25<00:01,  9.52it/s]\u001b[A\n",
      "\n",
      " 96%|█████████▌| 240/250 [00:26<00:01,  9.57it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 242/250 [00:26<00:00,  9.86it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 243/250 [00:26<00:00,  9.74it/s]\u001b[A\n",
      "\n",
      " 98%|█████████▊| 244/250 [00:26<00:00,  9.78it/s]\u001b[A\n",
      "\n",
      " 98%|█████████▊| 245/250 [00:26<00:00,  9.80it/s]\u001b[A\n",
      "\n",
      " 98%|█████████▊| 246/250 [00:26<00:00,  9.54it/s]\u001b[A\n",
      "\n",
      " 99%|█████████▉| 248/250 [00:26<00:00,  9.76it/s]\u001b[A\n",
      "\n",
      "100%|█████████▉| 249/250 [00:26<00:00,  9.79it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:27<00:00,  9.84it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      " 50%|█████     | 1000/2000 [03:35<03:14,  5.14it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:27<00:00,  9.84it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:24:57,925 >> Saving model checkpoint to output/t5_freeze_emotion\\checkpoint-1000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:24:57,928 >> Configuration saved in output/t5_freeze_emotion\\checkpoint-1000\\config.json\n",
      "[INFO|configuration_utils.py:544] 2024-01-26 01:24:57,928 >> Configuration saved in output/t5_freeze_emotion\\checkpoint-1000\\generation_config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:25:17,063 >> Model weights saved in output/t5_freeze_emotion\\checkpoint-1000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:25:17,065 >> tokenizer config file saved in output/t5_freeze_emotion\\checkpoint-1000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:25:17,065 >> Special tokens file saved in output/t5_freeze_emotion\\checkpoint-1000\\special_tokens_map.json\n",
      "[INFO|tokenization_t5_fast.py:189] 2024-01-26 01:25:17,070 >> Copy vocab file to output/t5_freeze_emotion\\checkpoint-1000\\spiece.model\n",
      "\n",
      " 50%|█████     | 1001/2000 [04:28<6:47:21, 24.47s/it]\n",
      " 50%|█████     | 1002/2000 [04:29<4:45:46, 17.18s/it]\n",
      " 50%|█████     | 1003/2000 [04:29<3:20:43, 12.08s/it]\n",
      " 50%|█████     | 1004/2000 [04:29<2:21:16,  8.51s/it]\n",
      " 50%|█████     | 1005/2000 [04:29<1:39:45,  6.02s/it]\n",
      " 50%|█████     | 1006/2000 [04:29<1:10:40,  4.27s/it]\n",
      " 50%|█████     | 1007/2000 [04:30<50:22,  3.04s/it]  \n",
      " 50%|█████     | 1008/2000 [04:30<36:07,  2.18s/it]\n",
      " 50%|█████     | 1009/2000 [04:30<26:16,  1.59s/it]\n",
      " 50%|█████     | 1010/2000 [04:30<19:18,  1.17s/it]\n",
      " 51%|█████     | 1011/2000 [04:30<14:21,  1.15it/s]\n",
      " 51%|█████     | 1012/2000 [04:30<11:02,  1.49it/s]\n",
      " 51%|█████     | 1013/2000 [04:31<08:37,  1.91it/s]\n",
      " 51%|█████     | 1014/2000 [04:31<06:57,  2.36it/s]\n",
      " 51%|█████     | 1015/2000 [04:31<05:44,  2.86it/s]\n",
      " 51%|█████     | 1016/2000 [04:31<04:54,  3.34it/s]\n",
      " 51%|█████     | 1017/2000 [04:31<04:20,  3.77it/s]\n",
      " 51%|█████     | 1018/2000 [04:32<03:54,  4.19it/s]\n",
      " 51%|█████     | 1019/2000 [04:32<03:37,  4.52it/s]\n",
      " 51%|█████     | 1020/2000 [04:32<03:26,  4.75it/s]\n",
      " 51%|█████     | 1021/2000 [04:32<03:21,  4.87it/s]\n",
      " 51%|█████     | 1022/2000 [04:32<03:14,  5.02it/s]\n",
      " 51%|█████     | 1023/2000 [04:33<03:16,  4.98it/s]\n",
      " 51%|█████     | 1024/2000 [04:33<03:07,  5.21it/s]\n",
      " 51%|█████▏    | 1025/2000 [04:33<03:05,  5.26it/s]\n",
      " 51%|█████▏    | 1026/2000 [04:33<02:59,  5.42it/s]\n",
      " 51%|█████▏    | 1027/2000 [04:33<03:01,  5.36it/s]\n",
      " 51%|█████▏    | 1028/2000 [04:33<03:00,  5.40it/s]\n",
      " 51%|█████▏    | 1029/2000 [04:34<03:00,  5.37it/s]\n",
      " 52%|█████▏    | 1030/2000 [04:34<02:59,  5.39it/s]\n",
      " 52%|█████▏    | 1031/2000 [04:34<02:57,  5.45it/s]\n",
      " 52%|█████▏    | 1032/2000 [04:34<02:58,  5.43it/s]\n",
      " 52%|█████▏    | 1033/2000 [04:34<02:54,  5.53it/s]\n",
      " 52%|█████▏    | 1034/2000 [04:35<02:56,  5.47it/s]\n",
      " 52%|█████▏    | 1035/2000 [04:35<02:57,  5.44it/s]\n",
      " 52%|█████▏    | 1036/2000 [04:35<02:58,  5.40it/s]\n",
      " 52%|█████▏    | 1037/2000 [04:35<02:57,  5.42it/s]\n",
      " 52%|█████▏    | 1038/2000 [04:35<02:54,  5.52it/s]\n",
      " 52%|█████▏    | 1039/2000 [04:35<02:55,  5.47it/s]\n",
      " 52%|█████▏    | 1040/2000 [04:36<02:54,  5.51it/s]\n",
      " 52%|█████▏    | 1041/2000 [04:36<02:55,  5.47it/s]\n",
      " 52%|█████▏    | 1042/2000 [04:36<02:55,  5.45it/s]\n",
      " 52%|█████▏    | 1043/2000 [04:36<02:56,  5.41it/s]\n",
      " 52%|█████▏    | 1044/2000 [04:36<03:00,  5.29it/s]\n",
      " 52%|█████▏    | 1045/2000 [04:37<03:00,  5.28it/s]\n",
      " 52%|█████▏    | 1046/2000 [04:37<03:00,  5.29it/s]\n",
      " 52%|█████▏    | 1047/2000 [04:37<02:58,  5.33it/s]\n",
      " 52%|█████▏    | 1048/2000 [04:37<02:58,  5.33it/s]\n",
      " 52%|█████▏    | 1049/2000 [04:37<02:57,  5.36it/s]\n",
      " 52%|█████▎    | 1050/2000 [04:37<02:56,  5.39it/s]\n",
      "                                                   \n",
      "\n",
      " 52%|█████▎    | 1050/2000 [04:37<02:56,  5.39it/s]\n",
      " 53%|█████▎    | 1051/2000 [04:38<02:57,  5.34it/s]\n",
      " 53%|█████▎    | 1052/2000 [04:38<02:56,  5.37it/s]\n",
      " 53%|█████▎    | 1053/2000 [04:38<02:54,  5.44it/s]\n",
      " 53%|█████▎    | 1054/2000 [04:38<02:53,  5.45it/s]\n",
      " 53%|█████▎    | 1055/2000 [04:38<02:59,  5.26it/s]\n",
      " 53%|█████▎    | 1056/2000 [04:39<02:57,  5.30it/s]\n",
      " 53%|█████▎    | 1057/2000 [04:39<02:53,  5.45it/s]\n",
      " 53%|█████▎    | 1058/2000 [04:39<02:52,  5.45it/s]\n",
      " 53%|█████▎    | 1059/2000 [04:39<02:53,  5.41it/s]\n",
      " 53%|█████▎    | 1060/2000 [04:39<02:53,  5.43it/s]\n",
      " 53%|█████▎    | 1061/2000 [04:40<02:52,  5.43it/s]\n",
      " 53%|█████▎    | 1062/2000 [04:40<02:49,  5.54it/s]\n",
      " 53%|█████▎    | 1063/2000 [04:40<02:48,  5.55it/s]\n",
      " 53%|█████▎    | 1064/2000 [04:40<02:49,  5.51it/s]\n",
      " 53%|█████▎    | 1065/2000 [04:40<02:53,  5.38it/s]\n",
      " 53%|█████▎    | 1066/2000 [04:40<02:53,  5.38it/s]\n",
      " 53%|█████▎    | 1067/2000 [04:41<03:00,  5.16it/s]\n",
      " 53%|█████▎    | 1068/2000 [04:41<03:00,  5.16it/s]\n",
      " 53%|█████▎    | 1069/2000 [04:41<02:53,  5.36it/s]\n",
      " 54%|█████▎    | 1070/2000 [04:41<02:52,  5.38it/s]\n",
      " 54%|█████▎    | 1071/2000 [04:41<02:53,  5.37it/s]\n",
      " 54%|█████▎    | 1072/2000 [04:42<02:51,  5.42it/s]\n",
      " 54%|█████▎    | 1073/2000 [04:42<02:51,  5.42it/s]\n",
      " 54%|█████▎    | 1074/2000 [04:42<02:48,  5.50it/s]\n",
      " 54%|█████▍    | 1075/2000 [04:42<02:48,  5.47it/s]\n",
      " 54%|█████▍    | 1076/2000 [04:42<02:51,  5.40it/s]\n",
      " 54%|█████▍    | 1077/2000 [04:42<02:55,  5.26it/s]\n",
      " 54%|█████▍    | 1078/2000 [04:43<02:53,  5.30it/s]\n",
      " 54%|█████▍    | 1079/2000 [04:43<02:54,  5.29it/s]\n",
      " 54%|█████▍    | 1080/2000 [04:43<02:53,  5.29it/s]\n",
      " 54%|█████▍    | 1081/2000 [04:43<02:51,  5.35it/s]\n",
      " 54%|█████▍    | 1082/2000 [04:43<02:50,  5.37it/s]\n",
      " 54%|█████▍    | 1083/2000 [04:44<02:51,  5.33it/s]\n",
      " 54%|█████▍    | 1084/2000 [04:44<03:00,  5.09it/s]\n",
      " 54%|█████▍    | 1085/2000 [04:44<02:58,  5.14it/s]\n",
      " 54%|█████▍    | 1086/2000 [04:44<02:56,  5.17it/s]\n",
      " 54%|█████▍    | 1087/2000 [04:44<02:57,  5.15it/s]\n",
      " 54%|█████▍    | 1088/2000 [04:45<02:53,  5.24it/s]\n",
      " 54%|█████▍    | 1089/2000 [04:45<02:49,  5.37it/s]\n",
      " 55%|█████▍    | 1090/2000 [04:45<02:47,  5.44it/s]\n",
      " 55%|█████▍    | 1091/2000 [04:45<02:45,  5.51it/s]\n",
      " 55%|█████▍    | 1092/2000 [04:45<02:45,  5.50it/s]\n",
      " 55%|█████▍    | 1093/2000 [04:45<02:43,  5.56it/s]\n",
      " 55%|█████▍    | 1094/2000 [04:46<02:43,  5.54it/s]\n",
      " 55%|█████▍    | 1095/2000 [04:46<02:41,  5.60it/s]\n",
      " 55%|█████▍    | 1096/2000 [04:46<02:47,  5.39it/s]\n",
      " 55%|█████▍    | 1097/2000 [04:46<02:45,  5.47it/s]\n",
      " 55%|█████▍    | 1098/2000 [04:46<02:45,  5.46it/s]\n",
      " 55%|█████▍    | 1099/2000 [04:47<02:47,  5.37it/s]\n",
      " 55%|█████▌    | 1100/2000 [04:47<02:46,  5.41it/s]\n",
      "                                                   \n",
      "\n",
      " 55%|█████▌    | 1100/2000 [04:47<02:46,  5.41it/s]\n",
      " 55%|█████▌    | 1101/2000 [04:47<02:43,  5.51it/s]\n",
      " 55%|█████▌    | 1102/2000 [04:47<02:40,  5.60it/s]\n",
      " 55%|█████▌    | 1103/2000 [04:47<02:39,  5.63it/s]\n",
      " 55%|█████▌    | 1104/2000 [04:47<02:40,  5.57it/s]\n",
      " 55%|█████▌    | 1105/2000 [04:48<02:41,  5.53it/s]\n",
      " 55%|█████▌    | 1106/2000 [04:48<02:43,  5.48it/s]\n",
      " 55%|█████▌    | 1107/2000 [04:48<02:48,  5.31it/s]\n",
      " 55%|█████▌    | 1108/2000 [04:48<02:48,  5.29it/s]\n",
      " 55%|█████▌    | 1109/2000 [04:48<02:47,  5.31it/s]\n",
      " 56%|█████▌    | 1110/2000 [04:49<02:43,  5.45it/s]\n",
      " 56%|█████▌    | 1111/2000 [04:49<02:45,  5.36it/s]\n",
      " 56%|█████▌    | 1112/2000 [04:49<02:44,  5.40it/s]\n",
      " 56%|█████▌    | 1113/2000 [04:49<02:45,  5.35it/s]\n",
      " 56%|█████▌    | 1114/2000 [04:49<02:46,  5.31it/s]\n",
      " 56%|█████▌    | 1115/2000 [04:50<02:49,  5.22it/s]\n",
      " 56%|█████▌    | 1116/2000 [04:50<02:47,  5.28it/s]\n",
      " 56%|█████▌    | 1117/2000 [04:50<02:46,  5.30it/s]\n",
      " 56%|█████▌    | 1118/2000 [04:50<02:45,  5.34it/s]\n",
      " 56%|█████▌    | 1119/2000 [04:50<02:52,  5.12it/s]\n",
      " 56%|█████▌    | 1120/2000 [04:50<02:46,  5.30it/s]\n",
      " 56%|█████▌    | 1121/2000 [04:51<02:44,  5.35it/s]\n",
      " 56%|█████▌    | 1122/2000 [04:51<02:48,  5.20it/s]\n",
      " 56%|█████▌    | 1123/2000 [04:51<02:52,  5.08it/s]\n",
      " 56%|█████▌    | 1124/2000 [04:51<02:55,  4.98it/s]\n",
      " 56%|█████▋    | 1125/2000 [04:51<02:48,  5.18it/s]\n",
      " 56%|█████▋    | 1126/2000 [04:52<02:43,  5.34it/s]\n",
      " 56%|█████▋    | 1127/2000 [04:52<02:42,  5.36it/s]\n",
      " 56%|█████▋    | 1128/2000 [04:52<02:43,  5.32it/s]\n",
      " 56%|█████▋    | 1129/2000 [04:52<02:42,  5.35it/s]\n",
      " 56%|█████▋    | 1130/2000 [04:52<02:43,  5.34it/s]\n",
      " 57%|█████▋    | 1131/2000 [04:53<02:44,  5.27it/s]\n",
      " 57%|█████▋    | 1132/2000 [04:53<02:49,  5.11it/s]\n",
      " 57%|█████▋    | 1133/2000 [04:53<02:51,  5.05it/s]\n",
      " 57%|█████▋    | 1134/2000 [04:53<02:54,  4.97it/s]\n",
      " 57%|█████▋    | 1135/2000 [04:53<02:46,  5.20it/s]\n",
      " 57%|█████▋    | 1136/2000 [04:54<02:41,  5.34it/s]\n",
      " 57%|█████▋    | 1137/2000 [04:54<02:40,  5.38it/s]\n",
      " 57%|█████▋    | 1138/2000 [04:54<02:36,  5.50it/s]\n",
      " 57%|█████▋    | 1139/2000 [04:54<02:35,  5.53it/s]\n",
      " 57%|█████▋    | 1140/2000 [04:54<02:38,  5.44it/s]\n",
      " 57%|█████▋    | 1141/2000 [04:54<02:39,  5.40it/s]\n",
      " 57%|█████▋    | 1142/2000 [04:55<02:39,  5.37it/s]\n",
      " 57%|█████▋    | 1143/2000 [04:55<02:39,  5.36it/s]\n",
      " 57%|█████▋    | 1144/2000 [04:55<02:38,  5.41it/s]\n",
      " 57%|█████▋    | 1145/2000 [04:55<02:38,  5.40it/s]\n",
      " 57%|█████▋    | 1146/2000 [04:55<02:38,  5.40it/s]\n",
      " 57%|█████▋    | 1147/2000 [04:56<02:35,  5.50it/s]\n",
      " 57%|█████▋    | 1148/2000 [04:56<02:33,  5.56it/s]\n",
      " 57%|█████▋    | 1149/2000 [04:56<02:31,  5.62it/s]\n",
      " 57%|█████▊    | 1150/2000 [04:56<02:32,  5.59it/s]\n",
      "                                                   \n",
      "\n",
      " 57%|█████▊    | 1150/2000 [04:56<02:32,  5.59it/s]\n",
      " 58%|█████▊    | 1151/2000 [04:56<02:44,  5.16it/s]\n",
      " 58%|█████▊    | 1152/2000 [04:57<02:43,  5.19it/s]\n",
      " 58%|█████▊    | 1153/2000 [04:57<02:40,  5.27it/s]\n",
      " 58%|█████▊    | 1154/2000 [04:57<02:40,  5.29it/s]\n",
      " 58%|█████▊    | 1155/2000 [04:57<02:40,  5.25it/s]\n",
      " 58%|█████▊    | 1156/2000 [04:57<02:37,  5.37it/s]\n",
      " 58%|█████▊    | 1157/2000 [04:57<02:39,  5.29it/s]\n",
      " 58%|█████▊    | 1158/2000 [04:58<02:47,  5.04it/s]\n",
      " 58%|█████▊    | 1159/2000 [04:58<02:41,  5.20it/s]\n",
      " 58%|█████▊    | 1160/2000 [04:58<02:40,  5.23it/s]\n",
      " 58%|█████▊    | 1161/2000 [04:58<02:49,  4.95it/s]\n",
      " 58%|█████▊    | 1162/2000 [04:58<02:42,  5.14it/s]\n",
      " 58%|█████▊    | 1163/2000 [04:59<02:36,  5.34it/s]\n",
      " 58%|█████▊    | 1164/2000 [04:59<02:35,  5.36it/s]\n",
      " 58%|█████▊    | 1165/2000 [04:59<02:32,  5.46it/s]\n",
      " 58%|█████▊    | 1166/2000 [04:59<02:32,  5.48it/s]\n",
      " 58%|█████▊    | 1167/2000 [04:59<02:34,  5.41it/s]\n",
      " 58%|█████▊    | 1168/2000 [05:00<02:31,  5.50it/s]\n",
      " 58%|█████▊    | 1169/2000 [05:00<02:31,  5.48it/s]\n",
      " 58%|█████▊    | 1170/2000 [05:00<02:36,  5.31it/s]\n",
      " 59%|█████▊    | 1171/2000 [05:00<02:40,  5.16it/s]\n",
      " 59%|█████▊    | 1172/2000 [05:00<02:38,  5.24it/s]\n",
      " 59%|█████▊    | 1173/2000 [05:00<02:37,  5.27it/s]\n",
      " 59%|█████▊    | 1174/2000 [05:01<02:35,  5.30it/s]\n",
      " 59%|█████▉    | 1175/2000 [05:01<02:33,  5.36it/s]\n",
      " 59%|█████▉    | 1176/2000 [05:01<02:30,  5.46it/s]\n",
      " 59%|█████▉    | 1177/2000 [05:01<02:36,  5.27it/s]\n",
      " 59%|█████▉    | 1178/2000 [05:01<02:35,  5.30it/s]\n",
      " 59%|█████▉    | 1179/2000 [05:02<02:34,  5.33it/s]\n",
      " 59%|█████▉    | 1180/2000 [05:02<02:34,  5.31it/s]\n",
      " 59%|█████▉    | 1181/2000 [05:02<02:31,  5.41it/s]\n",
      " 59%|█████▉    | 1182/2000 [05:02<02:32,  5.37it/s]\n",
      " 59%|█████▉    | 1183/2000 [05:02<02:42,  5.03it/s]\n",
      " 59%|█████▉    | 1184/2000 [05:03<02:36,  5.21it/s]\n",
      " 59%|█████▉    | 1185/2000 [05:03<02:41,  5.05it/s]\n",
      " 59%|█████▉    | 1186/2000 [05:03<02:39,  5.12it/s]\n",
      " 59%|█████▉    | 1187/2000 [05:03<02:36,  5.18it/s]\n",
      " 59%|█████▉    | 1188/2000 [05:03<02:34,  5.25it/s]\n",
      " 59%|█████▉    | 1189/2000 [05:04<02:34,  5.25it/s]\n",
      " 60%|█████▉    | 1190/2000 [05:04<02:33,  5.28it/s]\n",
      " 60%|█████▉    | 1191/2000 [05:04<02:29,  5.42it/s]\n",
      " 60%|█████▉    | 1192/2000 [05:04<02:27,  5.50it/s]\n",
      " 60%|█████▉    | 1193/2000 [05:04<02:26,  5.50it/s]\n",
      " 60%|█████▉    | 1194/2000 [05:04<02:32,  5.29it/s]\n",
      " 60%|█████▉    | 1195/2000 [05:05<02:30,  5.35it/s]\n",
      " 60%|█████▉    | 1196/2000 [05:05<02:30,  5.33it/s]\n",
      " 60%|█████▉    | 1197/2000 [05:05<02:29,  5.36it/s]\n",
      " 60%|█████▉    | 1198/2000 [05:05<02:31,  5.30it/s]\n",
      " 60%|█████▉    | 1199/2000 [05:05<02:29,  5.36it/s]\n",
      " 60%|██████    | 1200/2000 [05:06<02:30,  5.32it/s]\n",
      "                                                   \n",
      "\n",
      " 60%|██████    | 1200/2000 [05:06<02:30,  5.32it/s]\n",
      " 60%|██████    | 1201/2000 [05:06<02:29,  5.36it/s]\n",
      " 60%|██████    | 1202/2000 [05:06<02:29,  5.32it/s]\n",
      " 60%|██████    | 1203/2000 [05:06<02:29,  5.33it/s]\n",
      " 60%|██████    | 1204/2000 [05:06<02:29,  5.34it/s]\n",
      " 60%|██████    | 1205/2000 [05:07<02:26,  5.43it/s]\n",
      " 60%|██████    | 1206/2000 [05:07<02:28,  5.36it/s]\n",
      " 60%|██████    | 1207/2000 [05:07<02:31,  5.25it/s]\n",
      " 60%|██████    | 1208/2000 [05:07<02:28,  5.32it/s]\n",
      " 60%|██████    | 1209/2000 [05:07<02:30,  5.25it/s]\n",
      " 60%|██████    | 1210/2000 [05:07<02:28,  5.32it/s]\n",
      " 61%|██████    | 1211/2000 [05:08<02:28,  5.33it/s]\n",
      " 61%|██████    | 1212/2000 [05:08<02:27,  5.36it/s]\n",
      " 61%|██████    | 1213/2000 [05:08<02:25,  5.43it/s]\n",
      " 61%|██████    | 1214/2000 [05:08<02:28,  5.30it/s]\n",
      " 61%|██████    | 1215/2000 [05:08<02:27,  5.31it/s]\n",
      " 61%|██████    | 1216/2000 [05:09<02:27,  5.30it/s]\n",
      " 61%|██████    | 1217/2000 [05:09<02:27,  5.31it/s]\n",
      " 61%|██████    | 1218/2000 [05:09<02:26,  5.32it/s]\n",
      " 61%|██████    | 1219/2000 [05:09<02:24,  5.42it/s]\n",
      " 61%|██████    | 1220/2000 [05:09<02:24,  5.41it/s]\n",
      " 61%|██████    | 1221/2000 [05:10<02:21,  5.50it/s]\n",
      " 61%|██████    | 1222/2000 [05:10<02:21,  5.50it/s]\n",
      " 61%|██████    | 1223/2000 [05:10<02:22,  5.47it/s]\n",
      " 61%|██████    | 1224/2000 [05:10<02:19,  5.56it/s]\n",
      " 61%|██████▏   | 1225/2000 [05:10<02:18,  5.62it/s]\n",
      " 61%|██████▏   | 1226/2000 [05:10<02:17,  5.65it/s]\n",
      " 61%|██████▏   | 1227/2000 [05:11<02:22,  5.42it/s]\n",
      " 61%|██████▏   | 1228/2000 [05:11<02:22,  5.43it/s]\n",
      " 61%|██████▏   | 1229/2000 [05:11<02:22,  5.41it/s]\n",
      " 62%|██████▏   | 1230/2000 [05:11<02:23,  5.37it/s]\n",
      " 62%|██████▏   | 1231/2000 [05:11<02:22,  5.39it/s]\n",
      " 62%|██████▏   | 1232/2000 [05:12<02:20,  5.47it/s]\n",
      " 62%|██████▏   | 1233/2000 [05:12<02:20,  5.45it/s]\n",
      " 62%|██████▏   | 1234/2000 [05:12<02:20,  5.44it/s]\n",
      " 62%|██████▏   | 1235/2000 [05:12<02:25,  5.27it/s]\n",
      " 62%|██████▏   | 1236/2000 [05:12<02:21,  5.39it/s]\n",
      " 62%|██████▏   | 1237/2000 [05:12<02:21,  5.40it/s]\n",
      " 62%|██████▏   | 1238/2000 [05:13<02:22,  5.36it/s]\n",
      " 62%|██████▏   | 1239/2000 [05:13<02:22,  5.36it/s]\n",
      " 62%|██████▏   | 1240/2000 [05:13<02:22,  5.33it/s]\n",
      " 62%|██████▏   | 1241/2000 [05:13<02:29,  5.07it/s]\n",
      " 62%|██████▏   | 1242/2000 [05:13<02:27,  5.15it/s]\n",
      " 62%|██████▏   | 1243/2000 [05:14<02:24,  5.24it/s]\n",
      " 62%|██████▏   | 1244/2000 [05:14<02:23,  5.26it/s]\n",
      " 62%|██████▏   | 1245/2000 [05:14<02:19,  5.41it/s]\n",
      " 62%|██████▏   | 1246/2000 [05:14<02:26,  5.13it/s]\n",
      " 62%|██████▏   | 1247/2000 [05:14<02:27,  5.11it/s]\n",
      " 62%|██████▏   | 1248/2000 [05:15<02:23,  5.26it/s]\n",
      " 62%|██████▏   | 1249/2000 [05:15<02:27,  5.11it/s]\n",
      " 62%|██████▎   | 1250/2000 [05:15<02:28,  5.07it/s]\n",
      "                                                   \n",
      "\n",
      " 62%|██████▎   | 1250/2000 [05:15<02:28,  5.07it/s]\n",
      " 63%|██████▎   | 1251/2000 [05:15<02:28,  5.04it/s]\n",
      " 63%|██████▎   | 1252/2000 [05:15<02:27,  5.07it/s]\n",
      " 63%|██████▎   | 1253/2000 [05:16<02:32,  4.90it/s]\n",
      " 63%|██████▎   | 1254/2000 [05:16<02:33,  4.85it/s]\n",
      " 63%|██████▎   | 1255/2000 [05:16<02:29,  4.97it/s]\n",
      " 63%|██████▎   | 1256/2000 [05:16<02:28,  5.00it/s]\n",
      " 63%|██████▎   | 1257/2000 [05:16<02:29,  4.97it/s]\n",
      " 63%|██████▎   | 1258/2000 [05:17<02:25,  5.10it/s]\n",
      " 63%|██████▎   | 1259/2000 [05:17<02:25,  5.10it/s]\n",
      " 63%|██████▎   | 1260/2000 [05:17<02:24,  5.13it/s]\n",
      " 63%|██████▎   | 1261/2000 [05:17<02:25,  5.09it/s]\n",
      " 63%|██████▎   | 1262/2000 [05:17<02:19,  5.29it/s]\n",
      " 63%|██████▎   | 1263/2000 [05:18<02:19,  5.28it/s]\n",
      " 63%|██████▎   | 1264/2000 [05:18<02:20,  5.25it/s]\n",
      " 63%|██████▎   | 1265/2000 [05:18<02:18,  5.31it/s]\n",
      " 63%|██████▎   | 1266/2000 [05:18<02:16,  5.39it/s]\n",
      " 63%|██████▎   | 1267/2000 [05:18<02:14,  5.45it/s]\n",
      " 63%|██████▎   | 1268/2000 [05:18<02:13,  5.47it/s]\n",
      " 63%|██████▎   | 1269/2000 [05:19<02:13,  5.49it/s]\n",
      " 64%|██████▎   | 1270/2000 [05:19<02:15,  5.39it/s]\n",
      " 64%|██████▎   | 1271/2000 [05:19<02:19,  5.23it/s]\n",
      " 64%|██████▎   | 1272/2000 [05:19<02:21,  5.14it/s]\n",
      " 64%|██████▎   | 1273/2000 [05:19<02:17,  5.28it/s]\n",
      " 64%|██████▎   | 1274/2000 [05:20<02:16,  5.32it/s]\n",
      " 64%|██████▍   | 1275/2000 [05:20<02:16,  5.31it/s]\n",
      " 64%|██████▍   | 1276/2000 [05:20<02:13,  5.44it/s]\n",
      " 64%|██████▍   | 1277/2000 [05:20<02:10,  5.53it/s]\n",
      " 64%|██████▍   | 1278/2000 [05:20<02:11,  5.50it/s]\n",
      " 64%|██████▍   | 1279/2000 [05:20<02:09,  5.58it/s]\n",
      " 64%|██████▍   | 1280/2000 [05:21<02:09,  5.54it/s]\n",
      " 64%|██████▍   | 1281/2000 [05:21<02:08,  5.60it/s]\n",
      " 64%|██████▍   | 1282/2000 [05:21<02:09,  5.55it/s]\n",
      " 64%|██████▍   | 1283/2000 [05:21<02:11,  5.44it/s]\n",
      " 64%|██████▍   | 1284/2000 [05:21<02:14,  5.32it/s]\n",
      " 64%|██████▍   | 1285/2000 [05:22<02:16,  5.23it/s]\n",
      " 64%|██████▍   | 1286/2000 [05:22<02:20,  5.07it/s]\n",
      " 64%|██████▍   | 1287/2000 [05:22<02:17,  5.19it/s]\n",
      " 64%|██████▍   | 1288/2000 [05:22<02:16,  5.23it/s]\n",
      " 64%|██████▍   | 1289/2000 [05:22<02:18,  5.12it/s]\n",
      " 64%|██████▍   | 1290/2000 [05:23<02:18,  5.12it/s]\n",
      " 65%|██████▍   | 1291/2000 [05:23<02:18,  5.10it/s]\n",
      " 65%|██████▍   | 1292/2000 [05:23<02:17,  5.15it/s]\n",
      " 65%|██████▍   | 1293/2000 [05:23<02:16,  5.18it/s]\n",
      " 65%|██████▍   | 1294/2000 [05:23<02:18,  5.11it/s]\n",
      " 65%|██████▍   | 1295/2000 [05:24<02:13,  5.29it/s]\n",
      " 65%|██████▍   | 1296/2000 [05:24<02:10,  5.41it/s]\n",
      " 65%|██████▍   | 1297/2000 [05:24<02:09,  5.44it/s]\n",
      " 65%|██████▍   | 1298/2000 [05:24<02:10,  5.37it/s]\n",
      " 65%|██████▍   | 1299/2000 [05:24<02:10,  5.37it/s]\n",
      " 65%|██████▌   | 1300/2000 [05:24<02:09,  5.42it/s]\n",
      "                                                   \n",
      "\n",
      " 65%|██████▌   | 1300/2000 [05:24<02:09,  5.42it/s]\n",
      " 65%|██████▌   | 1301/2000 [05:25<02:08,  5.46it/s]\n",
      " 65%|██████▌   | 1302/2000 [05:25<02:07,  5.45it/s]\n",
      " 65%|██████▌   | 1303/2000 [05:25<02:08,  5.44it/s]\n",
      " 65%|██████▌   | 1304/2000 [05:25<02:10,  5.35it/s]\n",
      " 65%|██████▌   | 1305/2000 [05:25<02:18,  5.03it/s]\n",
      " 65%|██████▌   | 1306/2000 [05:26<02:15,  5.11it/s]\n",
      " 65%|██████▌   | 1307/2000 [05:26<02:17,  5.05it/s]\n",
      " 65%|██████▌   | 1308/2000 [05:26<02:20,  4.92it/s]\n",
      " 65%|██████▌   | 1309/2000 [05:26<02:14,  5.12it/s]\n",
      " 66%|██████▌   | 1310/2000 [05:26<02:12,  5.20it/s]\n",
      " 66%|██████▌   | 1311/2000 [05:27<02:12,  5.20it/s]\n",
      " 66%|██████▌   | 1312/2000 [05:27<02:07,  5.41it/s]\n",
      " 66%|██████▌   | 1313/2000 [05:27<02:04,  5.50it/s]\n",
      " 66%|██████▌   | 1314/2000 [05:27<02:01,  5.62it/s]\n",
      " 66%|██████▌   | 1315/2000 [05:27<02:03,  5.55it/s]\n",
      " 66%|██████▌   | 1316/2000 [05:27<02:03,  5.53it/s]\n",
      " 66%|██████▌   | 1317/2000 [05:28<02:04,  5.49it/s]\n",
      " 66%|██████▌   | 1318/2000 [05:28<02:02,  5.55it/s]\n",
      " 66%|██████▌   | 1319/2000 [05:28<02:00,  5.64it/s]\n",
      " 66%|██████▌   | 1320/2000 [05:28<02:02,  5.57it/s]\n",
      " 66%|██████▌   | 1321/2000 [05:28<02:03,  5.48it/s]\n",
      " 66%|██████▌   | 1322/2000 [05:29<02:04,  5.44it/s]\n",
      " 66%|██████▌   | 1323/2000 [05:29<02:07,  5.31it/s]\n",
      " 66%|██████▌   | 1324/2000 [05:29<02:10,  5.18it/s]\n",
      " 66%|██████▋   | 1325/2000 [05:29<02:09,  5.23it/s]\n",
      " 66%|██████▋   | 1326/2000 [05:29<02:05,  5.38it/s]\n",
      " 66%|██████▋   | 1327/2000 [05:29<02:02,  5.51it/s]\n",
      " 66%|██████▋   | 1328/2000 [05:30<02:02,  5.48it/s]\n",
      " 66%|██████▋   | 1329/2000 [05:30<02:01,  5.51it/s]\n",
      " 66%|██████▋   | 1330/2000 [05:30<02:04,  5.37it/s]\n",
      " 67%|██████▋   | 1331/2000 [05:30<02:09,  5.16it/s]\n",
      " 67%|██████▋   | 1332/2000 [05:30<02:14,  4.96it/s]\n",
      " 67%|██████▋   | 1333/2000 [05:31<02:08,  5.17it/s]\n",
      " 67%|██████▋   | 1334/2000 [05:31<02:07,  5.22it/s]\n",
      " 67%|██████▋   | 1335/2000 [05:31<02:05,  5.29it/s]\n",
      " 67%|██████▋   | 1336/2000 [05:31<02:07,  5.22it/s]\n",
      " 67%|██████▋   | 1337/2000 [05:31<02:08,  5.16it/s]\n",
      " 67%|██████▋   | 1338/2000 [05:32<02:09,  5.10it/s]\n",
      " 67%|██████▋   | 1339/2000 [05:32<02:09,  5.12it/s]\n",
      " 67%|██████▋   | 1340/2000 [05:32<02:05,  5.27it/s]\n",
      " 67%|██████▋   | 1341/2000 [05:32<02:02,  5.36it/s]\n",
      " 67%|██████▋   | 1342/2000 [05:32<02:01,  5.41it/s]\n",
      " 67%|██████▋   | 1343/2000 [05:33<02:15,  4.85it/s]\n",
      " 67%|██████▋   | 1344/2000 [05:33<02:10,  5.01it/s]\n",
      " 67%|██████▋   | 1345/2000 [05:33<02:06,  5.19it/s]\n",
      " 67%|██████▋   | 1346/2000 [05:33<02:04,  5.26it/s]\n",
      " 67%|██████▋   | 1347/2000 [05:33<02:03,  5.27it/s]\n",
      " 67%|██████▋   | 1348/2000 [05:34<02:03,  5.29it/s]\n",
      " 67%|██████▋   | 1349/2000 [05:34<02:01,  5.34it/s]\n",
      " 68%|██████▊   | 1350/2000 [05:34<02:00,  5.41it/s]\n",
      "                                                   \n",
      "\n",
      " 68%|██████▊   | 1350/2000 [05:34<02:00,  5.41it/s]\n",
      " 68%|██████▊   | 1351/2000 [05:34<01:59,  5.44it/s]\n",
      " 68%|██████▊   | 1352/2000 [05:34<01:59,  5.42it/s]\n",
      " 68%|██████▊   | 1353/2000 [05:34<01:59,  5.40it/s]\n",
      " 68%|██████▊   | 1354/2000 [05:35<01:57,  5.49it/s]\n",
      " 68%|██████▊   | 1355/2000 [05:35<01:58,  5.47it/s]\n",
      " 68%|██████▊   | 1356/2000 [05:35<01:56,  5.54it/s]\n",
      " 68%|██████▊   | 1357/2000 [05:35<01:59,  5.39it/s]\n",
      " 68%|██████▊   | 1358/2000 [05:35<01:58,  5.42it/s]\n",
      " 68%|██████▊   | 1359/2000 [05:36<01:59,  5.35it/s]\n",
      " 68%|██████▊   | 1360/2000 [05:36<02:03,  5.19it/s]\n",
      " 68%|██████▊   | 1361/2000 [05:36<02:01,  5.25it/s]\n",
      " 68%|██████▊   | 1362/2000 [05:36<02:01,  5.23it/s]\n",
      " 68%|██████▊   | 1363/2000 [05:36<02:02,  5.19it/s]\n",
      " 68%|██████▊   | 1364/2000 [05:37<02:00,  5.28it/s]\n",
      " 68%|██████▊   | 1365/2000 [05:37<01:58,  5.38it/s]\n",
      " 68%|██████▊   | 1366/2000 [05:37<01:58,  5.33it/s]\n",
      " 68%|██████▊   | 1367/2000 [05:37<01:58,  5.36it/s]\n",
      " 68%|██████▊   | 1368/2000 [05:37<01:57,  5.37it/s]\n",
      " 68%|██████▊   | 1369/2000 [05:37<01:57,  5.35it/s]\n",
      " 68%|██████▊   | 1370/2000 [05:38<01:55,  5.45it/s]\n",
      " 69%|██████▊   | 1371/2000 [05:38<01:55,  5.45it/s]\n",
      " 69%|██████▊   | 1372/2000 [05:38<01:56,  5.37it/s]\n",
      " 69%|██████▊   | 1373/2000 [05:38<01:56,  5.40it/s]\n",
      " 69%|██████▊   | 1374/2000 [05:38<01:54,  5.48it/s]\n",
      " 69%|██████▉   | 1375/2000 [05:39<01:54,  5.45it/s]\n",
      " 69%|██████▉   | 1376/2000 [05:39<01:55,  5.41it/s]\n",
      " 69%|██████▉   | 1377/2000 [05:39<01:54,  5.42it/s]\n",
      " 69%|██████▉   | 1378/2000 [05:39<01:54,  5.41it/s]\n",
      " 69%|██████▉   | 1379/2000 [05:39<01:55,  5.37it/s]\n",
      " 69%|██████▉   | 1380/2000 [05:39<01:52,  5.49it/s]\n",
      " 69%|██████▉   | 1381/2000 [05:40<02:02,  5.07it/s]\n",
      " 69%|██████▉   | 1382/2000 [05:40<01:57,  5.27it/s]\n",
      " 69%|██████▉   | 1383/2000 [05:40<01:56,  5.31it/s]\n",
      " 69%|██████▉   | 1384/2000 [05:40<01:53,  5.43it/s]\n",
      " 69%|██████▉   | 1385/2000 [05:40<01:56,  5.29it/s]\n",
      " 69%|██████▉   | 1386/2000 [05:41<01:55,  5.31it/s]\n",
      " 69%|██████▉   | 1387/2000 [05:41<01:54,  5.37it/s]\n",
      " 69%|██████▉   | 1388/2000 [05:41<01:54,  5.34it/s]\n",
      " 69%|██████▉   | 1389/2000 [05:41<01:51,  5.46it/s]\n",
      " 70%|██████▉   | 1390/2000 [05:41<01:49,  5.55it/s]\n",
      " 70%|██████▉   | 1391/2000 [05:42<01:50,  5.51it/s]\n",
      " 70%|██████▉   | 1392/2000 [05:42<01:51,  5.46it/s]\n",
      " 70%|██████▉   | 1393/2000 [05:42<01:51,  5.46it/s]\n",
      " 70%|██████▉   | 1394/2000 [05:42<01:49,  5.52it/s]\n",
      " 70%|██████▉   | 1395/2000 [05:42<01:50,  5.47it/s]\n",
      " 70%|██████▉   | 1396/2000 [05:42<01:48,  5.57it/s]\n",
      " 70%|██████▉   | 1397/2000 [05:43<01:52,  5.38it/s]\n",
      " 70%|██████▉   | 1398/2000 [05:43<01:49,  5.50it/s]\n",
      " 70%|██████▉   | 1399/2000 [05:43<01:52,  5.34it/s]\n",
      " 70%|███████   | 1400/2000 [05:43<01:53,  5.28it/s]\n",
      "                                                   \n",
      "\n",
      " 70%|███████   | 1400/2000 [05:43<01:53,  5.28it/s]\n",
      " 70%|███████   | 1401/2000 [05:43<01:51,  5.39it/s]\n",
      " 70%|███████   | 1402/2000 [05:44<01:49,  5.46it/s]\n",
      " 70%|███████   | 1403/2000 [05:44<01:52,  5.31it/s]\n",
      " 70%|███████   | 1404/2000 [05:44<01:49,  5.44it/s]\n",
      " 70%|███████   | 1405/2000 [05:44<01:52,  5.29it/s]\n",
      " 70%|███████   | 1406/2000 [05:44<01:51,  5.31it/s]\n",
      " 70%|███████   | 1407/2000 [05:44<01:51,  5.31it/s]\n",
      " 70%|███████   | 1408/2000 [05:45<01:54,  5.15it/s]\n",
      " 70%|███████   | 1409/2000 [05:45<01:52,  5.26it/s]\n",
      " 70%|███████   | 1410/2000 [05:45<01:51,  5.27it/s]\n",
      " 71%|███████   | 1411/2000 [05:45<01:50,  5.31it/s]\n",
      " 71%|███████   | 1412/2000 [05:45<01:50,  5.34it/s]\n",
      " 71%|███████   | 1413/2000 [05:46<01:52,  5.23it/s]\n",
      " 71%|███████   | 1414/2000 [05:46<01:55,  5.07it/s]\n",
      " 71%|███████   | 1415/2000 [05:46<01:55,  5.07it/s]\n",
      " 71%|███████   | 1416/2000 [05:46<01:51,  5.25it/s]\n",
      " 71%|███████   | 1417/2000 [05:46<01:53,  5.16it/s]\n",
      " 71%|███████   | 1418/2000 [05:47<01:52,  5.17it/s]\n",
      " 71%|███████   | 1419/2000 [05:47<01:52,  5.16it/s]\n",
      " 71%|███████   | 1420/2000 [05:47<01:49,  5.28it/s]\n",
      " 71%|███████   | 1421/2000 [05:47<01:49,  5.30it/s]\n",
      " 71%|███████   | 1422/2000 [05:47<01:48,  5.33it/s]\n",
      " 71%|███████   | 1423/2000 [05:48<01:48,  5.33it/s]\n",
      " 71%|███████   | 1424/2000 [05:48<01:45,  5.46it/s]\n",
      " 71%|███████▏  | 1425/2000 [05:48<01:44,  5.48it/s]\n",
      " 71%|███████▏  | 1426/2000 [05:48<01:45,  5.45it/s]\n",
      " 71%|███████▏  | 1427/2000 [05:48<01:43,  5.54it/s]\n",
      " 71%|███████▏  | 1428/2000 [05:48<01:42,  5.60it/s]\n",
      " 71%|███████▏  | 1429/2000 [05:49<01:43,  5.52it/s]\n",
      " 72%|███████▏  | 1430/2000 [05:49<01:42,  5.57it/s]\n",
      " 72%|███████▏  | 1431/2000 [05:49<01:40,  5.64it/s]\n",
      " 72%|███████▏  | 1432/2000 [05:49<01:41,  5.61it/s]\n",
      " 72%|███████▏  | 1433/2000 [05:49<01:43,  5.48it/s]\n",
      " 72%|███████▏  | 1434/2000 [05:50<01:43,  5.44it/s]\n",
      " 72%|███████▏  | 1435/2000 [05:50<01:44,  5.41it/s]\n",
      " 72%|███████▏  | 1436/2000 [05:50<01:43,  5.44it/s]\n",
      " 72%|███████▏  | 1437/2000 [05:50<01:43,  5.43it/s]\n",
      " 72%|███████▏  | 1438/2000 [05:50<01:44,  5.36it/s]\n",
      " 72%|███████▏  | 1439/2000 [05:50<01:49,  5.14it/s]\n",
      " 72%|███████▏  | 1440/2000 [05:51<01:45,  5.31it/s]\n",
      " 72%|███████▏  | 1441/2000 [05:51<01:44,  5.36it/s]\n",
      " 72%|███████▏  | 1442/2000 [05:51<01:42,  5.45it/s]\n",
      " 72%|███████▏  | 1443/2000 [05:51<01:42,  5.43it/s]\n",
      " 72%|███████▏  | 1444/2000 [05:51<01:42,  5.44it/s]\n",
      " 72%|███████▏  | 1445/2000 [05:52<01:42,  5.40it/s]\n",
      " 72%|███████▏  | 1446/2000 [05:52<01:41,  5.47it/s]\n",
      " 72%|███████▏  | 1447/2000 [05:52<01:39,  5.57it/s]\n",
      " 72%|███████▏  | 1448/2000 [05:52<01:39,  5.55it/s]\n",
      " 72%|███████▏  | 1449/2000 [05:52<01:38,  5.62it/s]\n",
      " 72%|███████▎  | 1450/2000 [05:52<01:39,  5.55it/s]\n",
      "                                                   \n",
      "\n",
      " 72%|███████▎  | 1450/2000 [05:52<01:39,  5.55it/s]\n",
      " 73%|███████▎  | 1451/2000 [05:53<01:37,  5.61it/s]\n",
      " 73%|███████▎  | 1452/2000 [05:53<01:41,  5.43it/s]\n",
      " 73%|███████▎  | 1453/2000 [05:53<01:41,  5.40it/s]\n",
      " 73%|███████▎  | 1454/2000 [05:53<01:42,  5.33it/s]\n",
      " 73%|███████▎  | 1455/2000 [05:53<01:44,  5.24it/s]\n",
      " 73%|███████▎  | 1456/2000 [05:54<01:41,  5.36it/s]\n",
      " 73%|███████▎  | 1457/2000 [05:54<01:40,  5.40it/s]\n",
      " 73%|███████▎  | 1458/2000 [05:54<01:38,  5.49it/s]\n",
      " 73%|███████▎  | 1459/2000 [05:54<01:39,  5.45it/s]\n",
      " 73%|███████▎  | 1460/2000 [05:54<01:37,  5.53it/s]\n",
      " 73%|███████▎  | 1461/2000 [05:54<01:37,  5.51it/s]\n",
      " 73%|███████▎  | 1462/2000 [05:55<01:36,  5.58it/s]\n",
      " 73%|███████▎  | 1463/2000 [05:55<01:36,  5.56it/s]\n",
      " 73%|███████▎  | 1464/2000 [05:55<01:35,  5.59it/s]\n",
      " 73%|███████▎  | 1465/2000 [05:55<01:36,  5.52it/s]\n",
      " 73%|███████▎  | 1466/2000 [05:55<01:35,  5.60it/s]\n",
      " 73%|███████▎  | 1467/2000 [05:56<01:34,  5.67it/s]\n",
      " 73%|███████▎  | 1468/2000 [05:56<01:35,  5.58it/s]\n",
      " 73%|███████▎  | 1469/2000 [05:56<01:36,  5.50it/s]\n",
      " 74%|███████▎  | 1470/2000 [05:56<01:36,  5.48it/s]\n",
      " 74%|███████▎  | 1471/2000 [05:56<01:37,  5.45it/s]\n",
      " 74%|███████▎  | 1472/2000 [05:56<01:38,  5.37it/s]\n",
      " 74%|███████▎  | 1473/2000 [05:57<01:36,  5.48it/s]\n",
      " 74%|███████▎  | 1474/2000 [05:57<01:36,  5.42it/s]\n",
      " 74%|███████▍  | 1475/2000 [05:57<01:36,  5.42it/s]\n",
      " 74%|███████▍  | 1476/2000 [05:57<01:37,  5.40it/s]\n",
      " 74%|███████▍  | 1477/2000 [05:57<01:37,  5.37it/s]\n",
      " 74%|███████▍  | 1478/2000 [05:58<01:35,  5.44it/s]\n",
      " 74%|███████▍  | 1479/2000 [05:58<01:35,  5.43it/s]\n",
      " 74%|███████▍  | 1480/2000 [05:58<01:33,  5.54it/s]\n",
      " 74%|███████▍  | 1481/2000 [05:58<01:35,  5.45it/s]\n",
      " 74%|███████▍  | 1482/2000 [05:58<01:35,  5.43it/s]\n",
      " 74%|███████▍  | 1483/2000 [05:59<01:33,  5.52it/s]\n",
      " 74%|███████▍  | 1484/2000 [05:59<01:35,  5.40it/s]\n",
      " 74%|███████▍  | 1485/2000 [05:59<01:36,  5.36it/s]\n",
      " 74%|███████▍  | 1486/2000 [05:59<01:33,  5.48it/s]\n",
      " 74%|███████▍  | 1487/2000 [05:59<01:33,  5.47it/s]\n",
      " 74%|███████▍  | 1488/2000 [05:59<01:32,  5.53it/s]\n",
      " 74%|███████▍  | 1489/2000 [06:00<01:32,  5.50it/s]\n",
      " 74%|███████▍  | 1490/2000 [06:00<01:36,  5.30it/s]\n",
      " 75%|███████▍  | 1491/2000 [06:00<01:34,  5.40it/s]\n",
      " 75%|███████▍  | 1492/2000 [06:00<01:35,  5.35it/s]\n",
      " 75%|███████▍  | 1493/2000 [06:00<01:33,  5.41it/s]\n",
      " 75%|███████▍  | 1494/2000 [06:01<01:35,  5.31it/s]\n",
      " 75%|███████▍  | 1495/2000 [06:01<01:34,  5.34it/s]\n",
      " 75%|███████▍  | 1496/2000 [06:01<01:34,  5.33it/s]\n",
      " 75%|███████▍  | 1497/2000 [06:01<01:34,  5.32it/s]\n",
      " 75%|███████▍  | 1498/2000 [06:01<01:34,  5.32it/s]\n",
      " 75%|███████▍  | 1499/2000 [06:01<01:33,  5.38it/s]\n",
      " 75%|███████▌  | 1500/2000 [06:02<01:31,  5.46it/s]\n",
      "                                                   \n",
      "\n",
      " 75%|███████▌  | 1500/2000 [06:02<01:31,  5.46it/s]\n",
      " 75%|███████▌  | 1501/2000 [06:02<01:32,  5.42it/s]\n",
      " 75%|███████▌  | 1502/2000 [06:02<01:32,  5.40it/s]\n",
      " 75%|███████▌  | 1503/2000 [06:02<01:33,  5.29it/s]\n",
      " 75%|███████▌  | 1504/2000 [06:02<01:31,  5.41it/s]\n",
      " 75%|███████▌  | 1505/2000 [06:03<01:29,  5.51it/s]\n",
      " 75%|███████▌  | 1506/2000 [06:03<01:29,  5.50it/s]\n",
      " 75%|███████▌  | 1507/2000 [06:03<01:29,  5.53it/s]\n",
      " 75%|███████▌  | 1508/2000 [06:03<01:29,  5.49it/s]\n",
      " 75%|███████▌  | 1509/2000 [06:03<01:30,  5.44it/s]\n",
      " 76%|███████▌  | 1510/2000 [06:03<01:28,  5.51it/s]\n",
      " 76%|███████▌  | 1511/2000 [06:04<01:28,  5.51it/s]\n",
      " 76%|███████▌  | 1512/2000 [06:04<01:28,  5.53it/s]\n",
      " 76%|███████▌  | 1513/2000 [06:04<01:30,  5.37it/s]\n",
      " 76%|███████▌  | 1514/2000 [06:04<01:33,  5.19it/s]\n",
      " 76%|███████▌  | 1515/2000 [06:04<01:32,  5.25it/s]\n",
      " 76%|███████▌  | 1516/2000 [06:05<01:29,  5.43it/s]\n",
      " 76%|███████▌  | 1517/2000 [06:05<01:29,  5.42it/s]\n",
      " 76%|███████▌  | 1518/2000 [06:05<01:28,  5.47it/s]\n",
      " 76%|███████▌  | 1519/2000 [06:05<01:28,  5.44it/s]\n",
      " 76%|███████▌  | 1520/2000 [06:05<01:28,  5.42it/s]\n",
      " 76%|███████▌  | 1521/2000 [06:06<01:26,  5.54it/s]\n",
      " 76%|███████▌  | 1522/2000 [06:06<01:25,  5.61it/s]\n",
      " 76%|███████▌  | 1523/2000 [06:06<01:25,  5.57it/s]\n",
      " 76%|███████▌  | 1524/2000 [06:06<01:23,  5.67it/s]\n",
      " 76%|███████▋  | 1525/2000 [06:06<01:25,  5.58it/s]\n",
      " 76%|███████▋  | 1526/2000 [06:06<01:28,  5.37it/s]\n",
      " 76%|███████▋  | 1527/2000 [06:07<01:28,  5.37it/s]\n",
      " 76%|███████▋  | 1528/2000 [06:07<01:26,  5.48it/s]\n",
      " 76%|███████▋  | 1529/2000 [06:07<01:28,  5.30it/s]\n",
      " 76%|███████▋  | 1530/2000 [06:07<01:28,  5.29it/s]\n",
      " 77%|███████▋  | 1531/2000 [06:07<01:28,  5.30it/s]\n",
      " 77%|███████▋  | 1532/2000 [06:08<01:28,  5.31it/s]\n",
      " 77%|███████▋  | 1533/2000 [06:08<01:26,  5.37it/s]\n",
      " 77%|███████▋  | 1534/2000 [06:08<01:24,  5.49it/s]\n",
      " 77%|███████▋  | 1535/2000 [06:08<01:24,  5.47it/s]\n",
      " 77%|███████▋  | 1536/2000 [06:08<01:24,  5.50it/s]\n",
      " 77%|███████▋  | 1537/2000 [06:08<01:24,  5.46it/s]\n",
      " 77%|███████▋  | 1538/2000 [06:09<01:24,  5.48it/s]\n",
      " 77%|███████▋  | 1539/2000 [06:09<01:26,  5.31it/s]\n",
      " 77%|███████▋  | 1540/2000 [06:09<01:24,  5.43it/s]\n",
      " 77%|███████▋  | 1541/2000 [06:09<01:24,  5.41it/s]\n",
      " 77%|███████▋  | 1542/2000 [06:09<01:23,  5.46it/s]\n",
      " 77%|███████▋  | 1543/2000 [06:10<01:23,  5.48it/s]\n",
      " 77%|███████▋  | 1544/2000 [06:10<01:29,  5.08it/s]\n",
      " 77%|███████▋  | 1545/2000 [06:10<01:28,  5.13it/s]\n",
      " 77%|███████▋  | 1546/2000 [06:10<01:26,  5.26it/s]\n",
      " 77%|███████▋  | 1547/2000 [06:10<01:24,  5.36it/s]\n",
      " 77%|███████▋  | 1548/2000 [06:11<01:23,  5.39it/s]\n",
      " 77%|███████▋  | 1549/2000 [06:11<01:22,  5.48it/s]\n",
      " 78%|███████▊  | 1550/2000 [06:11<01:22,  5.48it/s]\n",
      "                                                   \n",
      "\n",
      " 78%|███████▊  | 1550/2000 [06:11<01:22,  5.48it/s]\n",
      " 78%|███████▊  | 1551/2000 [06:11<01:21,  5.48it/s]\n",
      " 78%|███████▊  | 1552/2000 [06:11<01:21,  5.53it/s]\n",
      " 78%|███████▊  | 1553/2000 [06:11<01:21,  5.48it/s]\n",
      " 78%|███████▊  | 1554/2000 [06:12<01:23,  5.35it/s]\n",
      " 78%|███████▊  | 1555/2000 [06:12<01:21,  5.46it/s]\n",
      " 78%|███████▊  | 1556/2000 [06:12<01:20,  5.55it/s]\n",
      " 78%|███████▊  | 1557/2000 [06:12<01:21,  5.44it/s]\n",
      " 78%|███████▊  | 1558/2000 [06:12<01:19,  5.53it/s]\n",
      " 78%|███████▊  | 1559/2000 [06:13<01:21,  5.42it/s]\n",
      " 78%|███████▊  | 1560/2000 [06:13<01:20,  5.48it/s]\n",
      " 78%|███████▊  | 1561/2000 [06:13<01:18,  5.59it/s]\n",
      " 78%|███████▊  | 1562/2000 [06:13<01:19,  5.53it/s]\n",
      " 78%|███████▊  | 1563/2000 [06:13<01:17,  5.63it/s]\n",
      " 78%|███████▊  | 1564/2000 [06:13<01:18,  5.53it/s]\n",
      " 78%|███████▊  | 1565/2000 [06:14<01:19,  5.46it/s]\n",
      " 78%|███████▊  | 1566/2000 [06:14<01:19,  5.44it/s]\n",
      " 78%|███████▊  | 1567/2000 [06:14<01:19,  5.45it/s]\n",
      " 78%|███████▊  | 1568/2000 [06:14<01:21,  5.32it/s]\n",
      " 78%|███████▊  | 1569/2000 [06:14<01:20,  5.36it/s]\n",
      " 78%|███████▊  | 1570/2000 [06:15<01:18,  5.47it/s]\n",
      " 79%|███████▊  | 1571/2000 [06:15<01:19,  5.41it/s]\n",
      " 79%|███████▊  | 1572/2000 [06:15<01:18,  5.42it/s]\n",
      " 79%|███████▊  | 1573/2000 [06:15<01:19,  5.35it/s]\n",
      " 79%|███████▊  | 1574/2000 [06:15<01:19,  5.39it/s]\n",
      " 79%|███████▉  | 1575/2000 [06:15<01:17,  5.49it/s]\n",
      " 79%|███████▉  | 1576/2000 [06:16<01:17,  5.47it/s]\n",
      " 79%|███████▉  | 1577/2000 [06:16<01:18,  5.42it/s]\n",
      " 79%|███████▉  | 1578/2000 [06:16<01:16,  5.49it/s]\n",
      " 79%|███████▉  | 1579/2000 [06:16<01:19,  5.32it/s]\n",
      " 79%|███████▉  | 1580/2000 [06:16<01:18,  5.34it/s]\n",
      " 79%|███████▉  | 1581/2000 [06:17<01:17,  5.41it/s]\n",
      " 79%|███████▉  | 1582/2000 [06:17<01:16,  5.45it/s]\n",
      " 79%|███████▉  | 1583/2000 [06:17<01:15,  5.51it/s]\n",
      " 79%|███████▉  | 1584/2000 [06:17<01:15,  5.54it/s]\n",
      " 79%|███████▉  | 1585/2000 [06:17<01:16,  5.42it/s]\n",
      " 79%|███████▉  | 1586/2000 [06:18<01:17,  5.31it/s]\n",
      " 79%|███████▉  | 1587/2000 [06:18<01:16,  5.42it/s]\n",
      " 79%|███████▉  | 1588/2000 [06:18<01:16,  5.40it/s]\n",
      " 79%|███████▉  | 1589/2000 [06:18<01:17,  5.29it/s]\n",
      " 80%|███████▉  | 1590/2000 [06:18<01:17,  5.30it/s]\n",
      " 80%|███████▉  | 1591/2000 [06:18<01:17,  5.31it/s]\n",
      " 80%|███████▉  | 1592/2000 [06:19<01:16,  5.33it/s]\n",
      " 80%|███████▉  | 1593/2000 [06:19<01:14,  5.46it/s]\n",
      " 80%|███████▉  | 1594/2000 [06:19<01:14,  5.42it/s]\n",
      " 80%|███████▉  | 1595/2000 [06:19<01:13,  5.52it/s]\n",
      " 80%|███████▉  | 1596/2000 [06:19<01:13,  5.48it/s]\n",
      " 80%|███████▉  | 1597/2000 [06:20<01:14,  5.42it/s]\n",
      " 80%|███████▉  | 1598/2000 [06:20<01:13,  5.45it/s]\n",
      " 80%|███████▉  | 1599/2000 [06:20<01:14,  5.38it/s]\n",
      " 80%|████████  | 1600/2000 [06:20<01:14,  5.40it/s]\n",
      "                                                   \n",
      "\n",
      " 80%|████████  | 1600/2000 [06:20<01:14,  5.40it/s]\n",
      " 80%|████████  | 1601/2000 [06:20<01:14,  5.39it/s]\n",
      " 80%|████████  | 1602/2000 [06:20<01:13,  5.38it/s]\n",
      " 80%|████████  | 1603/2000 [06:21<01:13,  5.39it/s]\n",
      " 80%|████████  | 1604/2000 [06:21<01:14,  5.34it/s]\n",
      " 80%|████████  | 1605/2000 [06:21<01:13,  5.38it/s]\n",
      " 80%|████████  | 1606/2000 [06:21<01:13,  5.33it/s]\n",
      " 80%|████████  | 1607/2000 [06:21<01:15,  5.18it/s]\n",
      " 80%|████████  | 1608/2000 [06:22<01:14,  5.28it/s]\n",
      " 80%|████████  | 1609/2000 [06:22<01:13,  5.34it/s]\n",
      " 80%|████████  | 1610/2000 [06:22<01:13,  5.28it/s]\n",
      " 81%|████████  | 1611/2000 [06:22<01:14,  5.24it/s]\n",
      " 81%|████████  | 1612/2000 [06:22<01:14,  5.19it/s]\n",
      " 81%|████████  | 1613/2000 [06:23<01:13,  5.27it/s]\n",
      " 81%|████████  | 1614/2000 [06:23<01:11,  5.38it/s]\n",
      " 81%|████████  | 1615/2000 [06:23<01:13,  5.24it/s]\n",
      " 81%|████████  | 1616/2000 [06:23<01:13,  5.21it/s]\n",
      " 81%|████████  | 1617/2000 [06:23<01:11,  5.36it/s]\n",
      " 81%|████████  | 1618/2000 [06:23<01:10,  5.44it/s]\n",
      " 81%|████████  | 1619/2000 [06:24<01:10,  5.39it/s]\n",
      " 81%|████████  | 1620/2000 [06:24<01:11,  5.30it/s]\n",
      " 81%|████████  | 1621/2000 [06:24<01:10,  5.37it/s]\n",
      " 81%|████████  | 1622/2000 [06:24<01:11,  5.31it/s]\n",
      " 81%|████████  | 1623/2000 [06:24<01:10,  5.36it/s]\n",
      " 81%|████████  | 1624/2000 [06:25<01:09,  5.38it/s]\n",
      " 81%|████████▏ | 1625/2000 [06:25<01:11,  5.24it/s]\n",
      " 81%|████████▏ | 1626/2000 [06:25<01:10,  5.31it/s]\n",
      " 81%|████████▏ | 1627/2000 [06:25<01:11,  5.20it/s]\n",
      " 81%|████████▏ | 1628/2000 [06:25<01:11,  5.22it/s]\n",
      " 81%|████████▏ | 1629/2000 [06:26<01:11,  5.22it/s]\n",
      " 82%|████████▏ | 1630/2000 [06:26<01:10,  5.26it/s]\n",
      " 82%|████████▏ | 1631/2000 [06:26<01:10,  5.26it/s]\n",
      " 82%|████████▏ | 1632/2000 [06:26<01:09,  5.27it/s]\n",
      " 82%|████████▏ | 1633/2000 [06:26<01:10,  5.21it/s]\n",
      " 82%|████████▏ | 1634/2000 [06:27<01:09,  5.29it/s]\n",
      " 82%|████████▏ | 1635/2000 [06:27<01:08,  5.30it/s]\n",
      " 82%|████████▏ | 1636/2000 [06:27<01:07,  5.41it/s]\n",
      " 82%|████████▏ | 1637/2000 [06:27<01:05,  5.51it/s]\n",
      " 82%|████████▏ | 1638/2000 [06:27<01:06,  5.48it/s]\n",
      " 82%|████████▏ | 1639/2000 [06:27<01:11,  5.06it/s]\n",
      " 82%|████████▏ | 1640/2000 [06:28<01:09,  5.16it/s]\n",
      " 82%|████████▏ | 1641/2000 [06:28<01:07,  5.32it/s]\n",
      " 82%|████████▏ | 1642/2000 [06:28<01:05,  5.46it/s]\n",
      " 82%|████████▏ | 1643/2000 [06:28<01:05,  5.44it/s]\n",
      " 82%|████████▏ | 1644/2000 [06:28<01:05,  5.43it/s]\n",
      " 82%|████████▏ | 1645/2000 [06:29<01:04,  5.52it/s]\n",
      " 82%|████████▏ | 1646/2000 [06:29<01:03,  5.59it/s]\n",
      " 82%|████████▏ | 1647/2000 [06:29<01:02,  5.64it/s]\n",
      " 82%|████████▏ | 1648/2000 [06:29<01:03,  5.55it/s]\n",
      " 82%|████████▏ | 1649/2000 [06:29<01:07,  5.23it/s]\n",
      " 82%|████████▎ | 1650/2000 [06:29<01:06,  5.27it/s]\n",
      "                                                   \n",
      "\n",
      " 82%|████████▎ | 1650/2000 [06:29<01:06,  5.27it/s]\n",
      " 83%|████████▎ | 1651/2000 [06:30<01:05,  5.29it/s]\n",
      " 83%|████████▎ | 1652/2000 [06:30<01:06,  5.26it/s]\n",
      " 83%|████████▎ | 1653/2000 [06:30<01:06,  5.19it/s]\n",
      " 83%|████████▎ | 1654/2000 [06:30<01:06,  5.21it/s]\n",
      " 83%|████████▎ | 1655/2000 [06:30<01:05,  5.28it/s]\n",
      " 83%|████████▎ | 1656/2000 [06:31<01:04,  5.36it/s]\n",
      " 83%|████████▎ | 1657/2000 [06:31<01:02,  5.47it/s]\n",
      " 83%|████████▎ | 1658/2000 [06:31<01:05,  5.24it/s]\n",
      " 83%|████████▎ | 1659/2000 [06:31<01:04,  5.28it/s]\n",
      " 83%|████████▎ | 1660/2000 [06:31<01:02,  5.41it/s]\n",
      " 83%|████████▎ | 1661/2000 [06:32<01:02,  5.44it/s]\n",
      " 83%|████████▎ | 1662/2000 [06:32<01:01,  5.52it/s]\n",
      " 83%|████████▎ | 1663/2000 [06:32<01:01,  5.48it/s]\n",
      " 83%|████████▎ | 1664/2000 [06:32<01:01,  5.43it/s]\n",
      " 83%|████████▎ | 1665/2000 [06:32<01:00,  5.49it/s]\n",
      " 83%|████████▎ | 1666/2000 [06:32<01:01,  5.47it/s]\n",
      " 83%|████████▎ | 1667/2000 [06:33<01:05,  5.05it/s]\n",
      " 83%|████████▎ | 1668/2000 [06:33<01:03,  5.21it/s]\n",
      " 83%|████████▎ | 1669/2000 [06:33<01:02,  5.30it/s]\n",
      " 84%|████████▎ | 1670/2000 [06:33<01:04,  5.12it/s]\n",
      " 84%|████████▎ | 1671/2000 [06:33<01:08,  4.82it/s]\n",
      " 84%|████████▎ | 1672/2000 [06:34<01:07,  4.83it/s]\n",
      " 84%|████████▎ | 1673/2000 [06:34<01:05,  4.98it/s]\n",
      " 84%|████████▎ | 1674/2000 [06:34<01:04,  5.08it/s]\n",
      " 84%|████████▍ | 1675/2000 [06:34<01:02,  5.20it/s]\n",
      " 84%|████████▍ | 1676/2000 [06:34<01:03,  5.08it/s]\n",
      " 84%|████████▍ | 1677/2000 [06:35<01:02,  5.13it/s]\n",
      " 84%|████████▍ | 1678/2000 [06:35<01:04,  4.96it/s]\n",
      " 84%|████████▍ | 1679/2000 [06:35<01:03,  5.04it/s]\n",
      " 84%|████████▍ | 1680/2000 [06:35<01:02,  5.15it/s]\n",
      " 84%|████████▍ | 1681/2000 [06:35<01:01,  5.22it/s]\n",
      " 84%|████████▍ | 1682/2000 [06:36<01:00,  5.24it/s]\n",
      " 84%|████████▍ | 1683/2000 [06:36<01:01,  5.17it/s]\n",
      " 84%|████████▍ | 1684/2000 [06:36<00:59,  5.33it/s]\n",
      " 84%|████████▍ | 1685/2000 [06:36<00:58,  5.35it/s]\n",
      " 84%|████████▍ | 1686/2000 [06:36<00:57,  5.48it/s]\n",
      " 84%|████████▍ | 1687/2000 [06:37<00:57,  5.44it/s]\n",
      " 84%|████████▍ | 1688/2000 [06:37<00:58,  5.29it/s]\n",
      " 84%|████████▍ | 1689/2000 [06:37<01:03,  4.92it/s]\n",
      " 84%|████████▍ | 1690/2000 [06:37<01:01,  5.04it/s]\n",
      " 85%|████████▍ | 1691/2000 [06:37<01:00,  5.11it/s]\n",
      " 85%|████████▍ | 1692/2000 [06:38<00:59,  5.21it/s]\n",
      " 85%|████████▍ | 1693/2000 [06:38<00:58,  5.21it/s]\n",
      " 85%|████████▍ | 1694/2000 [06:38<00:58,  5.21it/s]\n",
      " 85%|████████▍ | 1695/2000 [06:38<00:58,  5.21it/s]\n",
      " 85%|████████▍ | 1696/2000 [06:38<00:57,  5.29it/s]\n",
      " 85%|████████▍ | 1697/2000 [06:38<00:56,  5.35it/s]\n",
      " 85%|████████▍ | 1698/2000 [06:39<00:56,  5.35it/s]\n",
      " 85%|████████▍ | 1699/2000 [06:39<00:57,  5.21it/s]\n",
      " 85%|████████▌ | 1700/2000 [06:39<00:58,  5.16it/s]\n",
      "                                                   \n",
      "\n",
      " 85%|████████▌ | 1700/2000 [06:39<00:58,  5.16it/s]\n",
      " 85%|████████▌ | 1701/2000 [06:39<01:00,  4.93it/s]\n",
      " 85%|████████▌ | 1702/2000 [06:39<00:59,  4.98it/s]\n",
      " 85%|████████▌ | 1703/2000 [06:40<00:57,  5.15it/s]\n",
      " 85%|████████▌ | 1704/2000 [06:40<01:00,  4.89it/s]\n",
      " 85%|████████▌ | 1705/2000 [06:40<00:58,  5.06it/s]\n",
      " 85%|████████▌ | 1706/2000 [06:40<00:58,  5.06it/s]\n",
      " 85%|████████▌ | 1707/2000 [06:40<00:56,  5.14it/s]\n",
      " 85%|████████▌ | 1708/2000 [06:41<01:01,  4.78it/s]\n",
      " 85%|████████▌ | 1709/2000 [06:41<00:59,  4.88it/s]\n",
      " 86%|████████▌ | 1710/2000 [06:41<00:58,  4.96it/s]\n",
      " 86%|████████▌ | 1711/2000 [06:41<00:57,  5.04it/s]\n",
      " 86%|████████▌ | 1712/2000 [06:41<00:55,  5.22it/s]\n",
      " 86%|████████▌ | 1713/2000 [06:42<00:59,  4.81it/s]\n",
      " 86%|████████▌ | 1714/2000 [06:42<00:59,  4.84it/s]\n",
      " 86%|████████▌ | 1715/2000 [06:42<00:56,  5.08it/s]\n",
      " 86%|████████▌ | 1716/2000 [06:42<00:55,  5.16it/s]\n",
      " 86%|████████▌ | 1717/2000 [06:42<00:54,  5.21it/s]\n",
      " 86%|████████▌ | 1718/2000 [06:43<00:55,  5.10it/s]\n",
      " 86%|████████▌ | 1719/2000 [06:43<00:55,  5.02it/s]\n",
      " 86%|████████▌ | 1720/2000 [06:43<00:55,  5.02it/s]\n",
      " 86%|████████▌ | 1721/2000 [06:43<00:55,  4.99it/s]\n",
      " 86%|████████▌ | 1722/2000 [06:43<00:54,  5.06it/s]\n",
      " 86%|████████▌ | 1723/2000 [06:44<00:54,  5.04it/s]\n",
      " 86%|████████▌ | 1724/2000 [06:44<00:53,  5.18it/s]\n",
      " 86%|████████▋ | 1725/2000 [06:44<00:52,  5.22it/s]\n",
      " 86%|████████▋ | 1726/2000 [06:44<00:50,  5.37it/s]\n",
      " 86%|████████▋ | 1727/2000 [06:44<00:51,  5.33it/s]\n",
      " 86%|████████▋ | 1728/2000 [06:45<00:49,  5.50it/s]\n",
      " 86%|████████▋ | 1729/2000 [06:45<00:49,  5.52it/s]\n",
      " 86%|████████▋ | 1730/2000 [06:45<00:49,  5.41it/s]\n",
      " 87%|████████▋ | 1731/2000 [06:45<00:51,  5.19it/s]\n",
      " 87%|████████▋ | 1732/2000 [06:45<00:51,  5.18it/s]\n",
      " 87%|████████▋ | 1733/2000 [06:46<00:50,  5.33it/s]\n",
      " 87%|████████▋ | 1734/2000 [06:46<00:49,  5.32it/s]\n",
      " 87%|████████▋ | 1735/2000 [06:46<00:49,  5.37it/s]\n",
      " 87%|████████▋ | 1736/2000 [06:46<00:48,  5.48it/s]\n",
      " 87%|████████▋ | 1737/2000 [06:46<00:48,  5.45it/s]\n",
      " 87%|████████▋ | 1738/2000 [06:46<00:47,  5.52it/s]\n",
      " 87%|████████▋ | 1739/2000 [06:47<00:46,  5.61it/s]\n",
      " 87%|████████▋ | 1740/2000 [06:47<00:45,  5.67it/s]\n",
      " 87%|████████▋ | 1741/2000 [06:47<00:45,  5.67it/s]\n",
      " 87%|████████▋ | 1742/2000 [06:47<00:47,  5.38it/s]\n",
      " 87%|████████▋ | 1743/2000 [06:47<00:49,  5.17it/s]\n",
      " 87%|████████▋ | 1744/2000 [06:48<00:48,  5.24it/s]\n",
      " 87%|████████▋ | 1745/2000 [06:48<00:48,  5.28it/s]\n",
      " 87%|████████▋ | 1746/2000 [06:48<00:47,  5.32it/s]\n",
      " 87%|████████▋ | 1747/2000 [06:48<00:48,  5.21it/s]\n",
      " 87%|████████▋ | 1748/2000 [06:48<00:47,  5.27it/s]\n",
      " 87%|████████▋ | 1749/2000 [06:48<00:47,  5.29it/s]\n",
      " 88%|████████▊ | 1750/2000 [06:49<00:46,  5.38it/s]\n",
      "                                                   \n",
      "\n",
      " 88%|████████▊ | 1750/2000 [06:49<00:46,  5.38it/s]\n",
      " 88%|████████▊ | 1751/2000 [06:49<00:46,  5.40it/s]\n",
      " 88%|████████▊ | 1752/2000 [06:49<00:46,  5.36it/s]\n",
      " 88%|████████▊ | 1753/2000 [06:49<00:45,  5.47it/s]\n",
      " 88%|████████▊ | 1754/2000 [06:49<00:45,  5.46it/s]\n",
      " 88%|████████▊ | 1755/2000 [06:50<00:44,  5.51it/s]\n",
      " 88%|████████▊ | 1756/2000 [06:50<00:44,  5.48it/s]\n",
      " 88%|████████▊ | 1757/2000 [06:50<00:46,  5.18it/s]\n",
      " 88%|████████▊ | 1758/2000 [06:50<00:46,  5.20it/s]\n",
      " 88%|████████▊ | 1759/2000 [06:50<00:45,  5.33it/s]\n",
      " 88%|████████▊ | 1760/2000 [06:51<00:44,  5.44it/s]\n",
      " 88%|████████▊ | 1761/2000 [06:51<00:44,  5.36it/s]\n",
      " 88%|████████▊ | 1762/2000 [06:51<00:45,  5.21it/s]\n",
      " 88%|████████▊ | 1763/2000 [06:51<00:47,  5.03it/s]\n",
      " 88%|████████▊ | 1764/2000 [06:51<00:46,  5.08it/s]\n",
      " 88%|████████▊ | 1765/2000 [06:52<00:44,  5.25it/s]\n",
      " 88%|████████▊ | 1766/2000 [06:52<00:45,  5.15it/s]\n",
      " 88%|████████▊ | 1767/2000 [06:52<00:45,  5.14it/s]\n",
      " 88%|████████▊ | 1768/2000 [06:52<00:44,  5.23it/s]\n",
      " 88%|████████▊ | 1769/2000 [06:52<00:45,  5.09it/s]\n",
      " 88%|████████▊ | 1770/2000 [06:52<00:44,  5.12it/s]\n",
      " 89%|████████▊ | 1771/2000 [06:53<00:44,  5.12it/s]\n",
      " 89%|████████▊ | 1772/2000 [06:53<00:43,  5.23it/s]\n",
      " 89%|████████▊ | 1773/2000 [06:53<00:44,  5.11it/s]\n",
      " 89%|████████▊ | 1774/2000 [06:53<00:43,  5.17it/s]\n",
      " 89%|████████▉ | 1775/2000 [06:53<00:43,  5.23it/s]\n",
      " 89%|████████▉ | 1776/2000 [06:54<00:43,  5.19it/s]\n",
      " 89%|████████▉ | 1777/2000 [06:54<00:41,  5.36it/s]\n",
      " 89%|████████▉ | 1778/2000 [06:54<00:40,  5.46it/s]\n",
      " 89%|████████▉ | 1779/2000 [06:54<00:43,  5.12it/s]\n",
      " 89%|████████▉ | 1780/2000 [06:54<00:44,  4.99it/s]\n",
      " 89%|████████▉ | 1781/2000 [06:55<00:45,  4.85it/s]\n",
      " 89%|████████▉ | 1782/2000 [06:55<00:43,  5.04it/s]\n",
      " 89%|████████▉ | 1783/2000 [06:55<00:41,  5.20it/s]\n",
      " 89%|████████▉ | 1784/2000 [06:55<00:41,  5.26it/s]\n",
      " 89%|████████▉ | 1785/2000 [06:55<00:40,  5.31it/s]\n",
      " 89%|████████▉ | 1786/2000 [06:56<00:39,  5.42it/s]\n",
      " 89%|████████▉ | 1787/2000 [06:56<00:39,  5.39it/s]\n",
      " 89%|████████▉ | 1788/2000 [06:56<00:39,  5.37it/s]\n",
      " 89%|████████▉ | 1789/2000 [06:56<00:38,  5.47it/s]\n",
      " 90%|████████▉ | 1790/2000 [06:56<00:39,  5.34it/s]\n",
      " 90%|████████▉ | 1791/2000 [06:56<00:38,  5.47it/s]\n",
      " 90%|████████▉ | 1792/2000 [06:57<00:37,  5.54it/s]\n",
      " 90%|████████▉ | 1793/2000 [06:57<00:37,  5.53it/s]\n",
      " 90%|████████▉ | 1794/2000 [06:57<00:37,  5.48it/s]\n",
      " 90%|████████▉ | 1795/2000 [06:57<00:37,  5.51it/s]\n",
      " 90%|████████▉ | 1796/2000 [06:57<00:37,  5.50it/s]\n",
      " 90%|████████▉ | 1797/2000 [06:58<00:36,  5.55it/s]\n",
      " 90%|████████▉ | 1798/2000 [06:58<00:36,  5.52it/s]\n",
      " 90%|████████▉ | 1799/2000 [06:58<00:36,  5.56it/s]\n",
      " 90%|█████████ | 1800/2000 [06:58<00:37,  5.33it/s]\n",
      "                                                   \n",
      "\n",
      " 90%|█████████ | 1800/2000 [06:58<00:37,  5.33it/s]\n",
      " 90%|█████████ | 1801/2000 [06:58<00:38,  5.22it/s]\n",
      " 90%|█████████ | 1802/2000 [06:58<00:36,  5.40it/s]\n",
      " 90%|█████████ | 1803/2000 [06:59<00:37,  5.29it/s]\n",
      " 90%|█████████ | 1804/2000 [06:59<00:36,  5.42it/s]\n",
      " 90%|█████████ | 1805/2000 [06:59<00:35,  5.45it/s]\n",
      " 90%|█████████ | 1806/2000 [06:59<00:35,  5.41it/s]\n",
      " 90%|█████████ | 1807/2000 [06:59<00:35,  5.37it/s]\n",
      " 90%|█████████ | 1808/2000 [07:00<00:35,  5.36it/s]\n",
      " 90%|█████████ | 1809/2000 [07:00<00:35,  5.46it/s]\n",
      " 90%|█████████ | 1810/2000 [07:00<00:34,  5.46it/s]\n",
      " 91%|█████████ | 1811/2000 [07:00<00:35,  5.26it/s]\n",
      " 91%|█████████ | 1812/2000 [07:00<00:35,  5.29it/s]\n",
      " 91%|█████████ | 1813/2000 [07:01<00:35,  5.30it/s]\n",
      " 91%|█████████ | 1814/2000 [07:01<00:35,  5.31it/s]\n",
      " 91%|█████████ | 1815/2000 [07:01<00:34,  5.44it/s]\n",
      " 91%|█████████ | 1816/2000 [07:01<00:33,  5.43it/s]\n",
      " 91%|█████████ | 1817/2000 [07:01<00:33,  5.53it/s]\n",
      " 91%|█████████ | 1818/2000 [07:01<00:33,  5.49it/s]\n",
      " 91%|█████████ | 1819/2000 [07:02<00:33,  5.40it/s]\n",
      " 91%|█████████ | 1820/2000 [07:02<00:33,  5.42it/s]\n",
      " 91%|█████████ | 1821/2000 [07:02<00:33,  5.35it/s]\n",
      " 91%|█████████ | 1822/2000 [07:02<00:32,  5.50it/s]\n",
      " 91%|█████████ | 1823/2000 [07:02<00:32,  5.49it/s]\n",
      " 91%|█████████ | 1824/2000 [07:03<00:31,  5.57it/s]\n",
      " 91%|█████████▏| 1825/2000 [07:03<00:31,  5.54it/s]\n",
      " 91%|█████████▏| 1826/2000 [07:03<00:32,  5.35it/s]\n",
      " 91%|█████████▏| 1827/2000 [07:03<00:31,  5.44it/s]\n",
      " 91%|█████████▏| 1828/2000 [07:03<00:31,  5.44it/s]\n",
      " 91%|█████████▏| 1829/2000 [07:03<00:31,  5.41it/s]\n",
      " 92%|█████████▏| 1830/2000 [07:04<00:31,  5.38it/s]\n",
      " 92%|█████████▏| 1831/2000 [07:04<00:31,  5.35it/s]\n",
      " 92%|█████████▏| 1832/2000 [07:04<00:31,  5.26it/s]\n",
      " 92%|█████████▏| 1833/2000 [07:04<00:31,  5.27it/s]\n",
      " 92%|█████████▏| 1834/2000 [07:04<00:31,  5.22it/s]\n",
      " 92%|█████████▏| 1835/2000 [07:05<00:30,  5.38it/s]\n",
      " 92%|█████████▏| 1836/2000 [07:05<00:30,  5.33it/s]\n",
      " 92%|█████████▏| 1837/2000 [07:05<00:29,  5.44it/s]\n",
      " 92%|█████████▏| 1838/2000 [07:05<00:29,  5.42it/s]\n",
      " 92%|█████████▏| 1839/2000 [07:05<00:29,  5.52it/s]\n",
      " 92%|█████████▏| 1840/2000 [07:06<00:29,  5.49it/s]\n",
      " 92%|█████████▏| 1841/2000 [07:06<00:28,  5.53it/s]\n",
      " 92%|█████████▏| 1842/2000 [07:06<00:30,  5.25it/s]\n",
      " 92%|█████████▏| 1843/2000 [07:06<00:29,  5.30it/s]\n",
      " 92%|█████████▏| 1844/2000 [07:06<00:29,  5.30it/s]\n",
      " 92%|█████████▏| 1845/2000 [07:06<00:28,  5.39it/s]\n",
      " 92%|█████████▏| 1846/2000 [07:07<00:28,  5.39it/s]\n",
      " 92%|█████████▏| 1847/2000 [07:07<00:27,  5.50it/s]\n",
      " 92%|█████████▏| 1848/2000 [07:07<00:27,  5.48it/s]\n",
      " 92%|█████████▏| 1849/2000 [07:07<00:28,  5.38it/s]\n",
      " 92%|█████████▎| 1850/2000 [07:07<00:28,  5.23it/s]\n",
      "                                                   \n",
      "\n",
      " 92%|█████████▎| 1850/2000 [07:07<00:28,  5.23it/s]\n",
      " 93%|█████████▎| 1851/2000 [07:08<00:28,  5.31it/s]\n",
      " 93%|█████████▎| 1852/2000 [07:08<00:27,  5.32it/s]\n",
      " 93%|█████████▎| 1853/2000 [07:08<00:27,  5.32it/s]\n",
      " 93%|█████████▎| 1854/2000 [07:08<00:27,  5.34it/s]\n",
      " 93%|█████████▎| 1855/2000 [07:08<00:27,  5.35it/s]\n",
      " 93%|█████████▎| 1856/2000 [07:09<00:26,  5.34it/s]\n",
      " 93%|█████████▎| 1857/2000 [07:09<00:26,  5.38it/s]\n",
      " 93%|█████████▎| 1858/2000 [07:09<00:27,  5.21it/s]\n",
      " 93%|█████████▎| 1859/2000 [07:09<00:26,  5.26it/s]\n",
      " 93%|█████████▎| 1860/2000 [07:09<00:26,  5.31it/s]\n",
      " 93%|█████████▎| 1861/2000 [07:09<00:25,  5.43it/s]\n",
      " 93%|█████████▎| 1862/2000 [07:10<00:25,  5.47it/s]\n",
      " 93%|█████████▎| 1863/2000 [07:10<00:25,  5.33it/s]\n",
      " 93%|█████████▎| 1864/2000 [07:10<00:25,  5.25it/s]\n",
      " 93%|█████████▎| 1865/2000 [07:10<00:25,  5.26it/s]\n",
      " 93%|█████████▎| 1866/2000 [07:10<00:25,  5.28it/s]\n",
      " 93%|█████████▎| 1867/2000 [07:11<00:24,  5.41it/s]\n",
      " 93%|█████████▎| 1868/2000 [07:11<00:23,  5.52it/s]\n",
      " 93%|█████████▎| 1869/2000 [07:11<00:23,  5.50it/s]\n",
      " 94%|█████████▎| 1870/2000 [07:11<00:25,  5.04it/s]\n",
      " 94%|█████████▎| 1871/2000 [07:11<00:25,  5.15it/s]\n",
      " 94%|█████████▎| 1872/2000 [07:12<00:23,  5.33it/s]\n",
      " 94%|█████████▎| 1873/2000 [07:12<00:23,  5.34it/s]\n",
      " 94%|█████████▎| 1874/2000 [07:12<00:23,  5.41it/s]\n",
      " 94%|█████████▍| 1875/2000 [07:12<00:22,  5.46it/s]\n",
      " 94%|█████████▍| 1876/2000 [07:12<00:22,  5.45it/s]\n",
      " 94%|█████████▍| 1877/2000 [07:12<00:22,  5.51it/s]\n",
      " 94%|█████████▍| 1878/2000 [07:13<00:23,  5.25it/s]\n",
      " 94%|█████████▍| 1879/2000 [07:13<00:23,  5.21it/s]\n",
      " 94%|█████████▍| 1880/2000 [07:13<00:22,  5.34it/s]\n",
      " 94%|█████████▍| 1881/2000 [07:13<00:22,  5.30it/s]\n",
      " 94%|█████████▍| 1882/2000 [07:13<00:21,  5.37it/s]\n",
      " 94%|█████████▍| 1883/2000 [07:14<00:21,  5.37it/s]\n",
      " 94%|█████████▍| 1884/2000 [07:14<00:21,  5.33it/s]\n",
      " 94%|█████████▍| 1885/2000 [07:14<00:21,  5.23it/s]\n",
      " 94%|█████████▍| 1886/2000 [07:14<00:21,  5.26it/s]\n",
      " 94%|█████████▍| 1887/2000 [07:14<00:21,  5.28it/s]\n",
      " 94%|█████████▍| 1888/2000 [07:15<00:20,  5.43it/s]\n",
      " 94%|█████████▍| 1889/2000 [07:15<00:21,  5.28it/s]\n",
      " 94%|█████████▍| 1890/2000 [07:15<00:20,  5.32it/s]\n",
      " 95%|█████████▍| 1891/2000 [07:15<00:20,  5.31it/s]\n",
      " 95%|█████████▍| 1892/2000 [07:15<00:19,  5.45it/s]\n",
      " 95%|█████████▍| 1893/2000 [07:15<00:19,  5.54it/s]\n",
      " 95%|█████████▍| 1894/2000 [07:16<00:18,  5.62it/s]\n",
      " 95%|█████████▍| 1895/2000 [07:16<00:18,  5.58it/s]\n",
      " 95%|█████████▍| 1896/2000 [07:16<00:19,  5.25it/s]\n",
      " 95%|█████████▍| 1897/2000 [07:16<00:19,  5.28it/s]\n",
      " 95%|█████████▍| 1898/2000 [07:16<00:18,  5.45it/s]\n",
      " 95%|█████████▍| 1899/2000 [07:17<00:18,  5.40it/s]\n",
      " 95%|█████████▌| 1900/2000 [07:17<00:18,  5.52it/s]\n",
      "                                                   \n",
      "\n",
      " 95%|█████████▌| 1900/2000 [07:17<00:18,  5.52it/s]\n",
      " 95%|█████████▌| 1901/2000 [07:17<00:17,  5.52it/s]\n",
      " 95%|█████████▌| 1902/2000 [07:17<00:18,  5.41it/s]\n",
      " 95%|█████████▌| 1903/2000 [07:17<00:18,  5.37it/s]\n",
      " 95%|█████████▌| 1904/2000 [07:17<00:17,  5.50it/s]\n",
      " 95%|█████████▌| 1905/2000 [07:18<00:17,  5.47it/s]\n",
      " 95%|█████████▌| 1906/2000 [07:18<00:16,  5.56it/s]\n",
      " 95%|█████████▌| 1907/2000 [07:18<00:17,  5.46it/s]\n",
      " 95%|█████████▌| 1908/2000 [07:18<00:16,  5.48it/s]\n",
      " 95%|█████████▌| 1909/2000 [07:18<00:17,  5.25it/s]\n",
      " 96%|█████████▌| 1910/2000 [07:19<00:17,  5.28it/s]\n",
      " 96%|█████████▌| 1911/2000 [07:19<00:16,  5.29it/s]\n",
      " 96%|█████████▌| 1912/2000 [07:19<00:16,  5.45it/s]\n",
      " 96%|█████████▌| 1913/2000 [07:19<00:15,  5.53it/s]\n",
      " 96%|█████████▌| 1914/2000 [07:19<00:15,  5.56it/s]\n",
      " 96%|█████████▌| 1915/2000 [07:19<00:15,  5.56it/s]\n",
      " 96%|█████████▌| 1916/2000 [07:20<00:16,  5.19it/s]\n",
      " 96%|█████████▌| 1917/2000 [07:20<00:15,  5.23it/s]\n",
      " 96%|█████████▌| 1918/2000 [07:20<00:15,  5.16it/s]\n",
      " 96%|█████████▌| 1919/2000 [07:20<00:15,  5.32it/s]\n",
      " 96%|█████████▌| 1920/2000 [07:20<00:14,  5.34it/s]\n",
      " 96%|█████████▌| 1921/2000 [07:21<00:14,  5.43it/s]\n",
      " 96%|█████████▌| 1922/2000 [07:21<00:14,  5.33it/s]\n",
      " 96%|█████████▌| 1923/2000 [07:21<00:14,  5.44it/s]\n",
      " 96%|█████████▌| 1924/2000 [07:21<00:13,  5.46it/s]\n",
      " 96%|█████████▋| 1925/2000 [07:21<00:13,  5.42it/s]\n",
      " 96%|█████████▋| 1926/2000 [07:22<00:13,  5.41it/s]\n",
      " 96%|█████████▋| 1927/2000 [07:22<00:13,  5.48it/s]\n",
      " 96%|█████████▋| 1928/2000 [07:22<00:13,  5.48it/s]\n",
      " 96%|█████████▋| 1929/2000 [07:22<00:12,  5.52it/s]\n",
      " 96%|█████████▋| 1930/2000 [07:22<00:12,  5.48it/s]\n",
      " 97%|█████████▋| 1931/2000 [07:22<00:12,  5.44it/s]\n",
      " 97%|█████████▋| 1932/2000 [07:23<00:12,  5.51it/s]\n",
      " 97%|█████████▋| 1933/2000 [07:23<00:12,  5.52it/s]\n",
      " 97%|█████████▋| 1934/2000 [07:23<00:12,  5.47it/s]\n",
      " 97%|█████████▋| 1935/2000 [07:23<00:12,  5.40it/s]\n",
      " 97%|█████████▋| 1936/2000 [07:23<00:11,  5.51it/s]\n",
      " 97%|█████████▋| 1937/2000 [07:24<00:11,  5.36it/s]\n",
      " 97%|█████████▋| 1938/2000 [07:24<00:11,  5.47it/s]\n",
      " 97%|█████████▋| 1939/2000 [07:24<00:11,  5.45it/s]\n",
      " 97%|█████████▋| 1940/2000 [07:24<00:11,  5.35it/s]\n",
      " 97%|█████████▋| 1941/2000 [07:24<00:10,  5.42it/s]\n",
      " 97%|█████████▋| 1942/2000 [07:24<00:10,  5.27it/s]\n",
      " 97%|█████████▋| 1943/2000 [07:25<00:10,  5.39it/s]\n",
      " 97%|█████████▋| 1944/2000 [07:25<00:10,  5.40it/s]\n",
      " 97%|█████████▋| 1945/2000 [07:25<00:10,  5.50it/s]\n",
      " 97%|█████████▋| 1946/2000 [07:25<00:09,  5.43it/s]\n",
      " 97%|█████████▋| 1947/2000 [07:25<00:09,  5.32it/s]\n",
      " 97%|█████████▋| 1948/2000 [07:26<00:09,  5.33it/s]\n",
      " 97%|█████████▋| 1949/2000 [07:26<00:09,  5.34it/s]\n",
      " 98%|█████████▊| 1950/2000 [07:26<00:09,  5.22it/s]\n",
      "                                                   \n",
      "\n",
      " 98%|█████████▊| 1950/2000 [07:26<00:09,  5.22it/s]\n",
      " 98%|█████████▊| 1951/2000 [07:26<00:09,  5.14it/s]\n",
      " 98%|█████████▊| 1952/2000 [07:26<00:09,  5.19it/s]\n",
      " 98%|█████████▊| 1953/2000 [07:27<00:09,  5.21it/s]\n",
      " 98%|█████████▊| 1954/2000 [07:27<00:09,  5.11it/s]\n",
      " 98%|█████████▊| 1955/2000 [07:27<00:09,  4.94it/s]\n",
      " 98%|█████████▊| 1956/2000 [07:27<00:08,  4.95it/s]\n",
      " 98%|█████████▊| 1957/2000 [07:27<00:08,  5.04it/s]\n",
      " 98%|█████████▊| 1958/2000 [07:28<00:08,  5.13it/s]\n",
      " 98%|█████████▊| 1959/2000 [07:28<00:08,  5.05it/s]\n",
      " 98%|█████████▊| 1960/2000 [07:28<00:07,  5.23it/s]\n",
      " 98%|█████████▊| 1961/2000 [07:28<00:07,  5.26it/s]\n",
      " 98%|█████████▊| 1962/2000 [07:28<00:07,  5.32it/s]\n",
      " 98%|█████████▊| 1963/2000 [07:28<00:06,  5.36it/s]\n",
      " 98%|█████████▊| 1964/2000 [07:29<00:06,  5.47it/s]\n",
      " 98%|█████████▊| 1965/2000 [07:29<00:06,  5.57it/s]\n",
      " 98%|█████████▊| 1966/2000 [07:29<00:06,  5.65it/s]\n",
      " 98%|█████████▊| 1967/2000 [07:29<00:05,  5.55it/s]\n",
      " 98%|█████████▊| 1968/2000 [07:29<00:05,  5.51it/s]\n",
      " 98%|█████████▊| 1969/2000 [07:30<00:05,  5.62it/s]\n",
      " 98%|█████████▊| 1970/2000 [07:30<00:05,  5.64it/s]\n",
      " 99%|█████████▊| 1971/2000 [07:30<00:05,  5.60it/s]\n",
      " 99%|█████████▊| 1972/2000 [07:30<00:05,  5.53it/s]\n",
      " 99%|█████████▊| 1973/2000 [07:30<00:04,  5.51it/s]\n",
      " 99%|█████████▊| 1974/2000 [07:30<00:04,  5.52it/s]\n",
      " 99%|█████████▉| 1975/2000 [07:31<00:04,  5.37it/s]\n",
      " 99%|█████████▉| 1976/2000 [07:31<00:04,  5.23it/s]\n",
      " 99%|█████████▉| 1977/2000 [07:31<00:04,  5.25it/s]\n",
      " 99%|█████████▉| 1978/2000 [07:31<00:04,  5.14it/s]\n",
      " 99%|█████████▉| 1979/2000 [07:31<00:04,  5.17it/s]\n",
      " 99%|█████████▉| 1980/2000 [07:32<00:03,  5.34it/s]\n",
      " 99%|█████████▉| 1981/2000 [07:32<00:03,  5.27it/s]\n",
      " 99%|█████████▉| 1982/2000 [07:32<00:03,  5.27it/s]\n",
      " 99%|█████████▉| 1983/2000 [07:32<00:03,  5.29it/s]\n",
      " 99%|█████████▉| 1984/2000 [07:32<00:02,  5.40it/s]\n",
      " 99%|█████████▉| 1985/2000 [07:33<00:02,  5.33it/s]\n",
      " 99%|█████████▉| 1986/2000 [07:33<00:02,  5.39it/s]\n",
      " 99%|█████████▉| 1987/2000 [07:33<00:02,  5.43it/s]\n",
      " 99%|█████████▉| 1988/2000 [07:33<00:02,  5.30it/s]\n",
      " 99%|█████████▉| 1989/2000 [07:33<00:02,  5.38it/s]\n",
      "100%|█████████▉| 1990/2000 [07:33<00:01,  5.36it/s]\n",
      "100%|█████████▉| 1991/2000 [07:34<00:01,  5.25it/s]\n",
      "100%|█████████▉| 1992/2000 [07:34<00:01,  4.97it/s]\n",
      "100%|█████████▉| 1993/2000 [07:34<00:01,  5.05it/s]\n",
      "100%|█████████▉| 1994/2000 [07:34<00:01,  4.92it/s]\n",
      "100%|█████████▉| 1995/2000 [07:35<00:00,  5.02it/s]\n",
      "100%|█████████▉| 1996/2000 [07:35<00:00,  5.10it/s]\n",
      "100%|█████████▉| 1997/2000 [07:35<00:00,  5.19it/s]\n",
      "100%|█████████▉| 1998/2000 [07:35<00:00,  5.25it/s]\n",
      "100%|█████████▉| 1999/2000 [07:35<00:00,  5.12it/s]\n",
      "100%|██████████| 2000/2000 [07:35<00:00,  5.16it/s]\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [07:35<00:00,  5.16it/s][INFO|trainer.py:3213] 2024-01-26 01:28:58,815 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:28:58,815 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:28:58,815 >>   Batch size = 8\n",
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  1%|          | 2/250 [00:00<00:12, 19.99it/s]\u001b[A\n",
      "\n",
      "  2%|▏         | 4/250 [00:00<00:20, 11.89it/s]\u001b[A\n",
      "\n",
      "  2%|▏         | 6/250 [00:00<00:23, 10.43it/s]\u001b[A\n",
      "\n",
      "  3%|▎         | 8/250 [00:00<00:24,  9.89it/s]\u001b[A\n",
      "\n",
      "  4%|▍         | 10/250 [00:01<00:26,  8.97it/s]\u001b[A\n",
      "\n",
      "  4%|▍         | 11/250 [00:01<00:26,  9.01it/s]\u001b[A\n",
      "\n",
      "  5%|▌         | 13/250 [00:01<00:25,  9.31it/s]\u001b[A\n",
      "\n",
      "  6%|▌         | 14/250 [00:01<00:25,  9.35it/s]\u001b[A\n",
      "\n",
      "  6%|▌         | 15/250 [00:01<00:24,  9.49it/s]\u001b[A\n",
      "\n",
      "  6%|▋         | 16/250 [00:01<00:24,  9.54it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 17/250 [00:01<00:24,  9.54it/s]\u001b[A\n",
      "\n",
      "  7%|▋         | 18/250 [00:01<00:24,  9.56it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 19/250 [00:01<00:24,  9.47it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 20/250 [00:02<00:23,  9.59it/s]\u001b[A\n",
      "\n",
      "  8%|▊         | 21/250 [00:02<00:23,  9.54it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 22/250 [00:02<00:23,  9.55it/s]\u001b[A\n",
      "\n",
      "  9%|▉         | 23/250 [00:02<00:23,  9.65it/s]\u001b[A\n",
      "\n",
      " 10%|▉         | 24/250 [00:02<00:23,  9.58it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 25/250 [00:02<00:23,  9.45it/s]\u001b[A\n",
      "\n",
      " 10%|█         | 26/250 [00:02<00:24,  9.15it/s]\u001b[A\n",
      "\n",
      " 11%|█         | 27/250 [00:02<00:24,  9.27it/s]\u001b[A\n",
      "\n",
      " 11%|█         | 28/250 [00:02<00:23,  9.45it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 29/250 [00:03<00:23,  9.30it/s]\u001b[A\n",
      "\n",
      " 12%|█▏        | 31/250 [00:03<00:22,  9.78it/s]\u001b[A\n",
      "\n",
      " 13%|█▎        | 33/250 [00:03<00:21, 10.12it/s]\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/250 [00:03<00:21, 10.04it/s]\u001b[A\n",
      "\n",
      " 14%|█▍        | 36/250 [00:03<00:21,  9.91it/s]\u001b[A\n",
      "\n",
      " 15%|█▍        | 37/250 [00:03<00:21,  9.73it/s]\u001b[A\n",
      "\n",
      " 16%|█▌        | 39/250 [00:03<00:20, 10.14it/s]\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/250 [00:04<00:21,  9.95it/s]\u001b[A\n",
      "\n",
      " 16%|█▋        | 41/250 [00:04<00:21,  9.89it/s]\u001b[A\n",
      "\n",
      " 17%|█▋        | 43/250 [00:04<00:20, 10.16it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/250 [00:04<00:22,  9.00it/s]\u001b[A\n",
      "\n",
      " 18%|█▊        | 46/250 [00:04<00:22,  8.98it/s]\u001b[A\n",
      "\n",
      " 19%|█▉        | 47/250 [00:04<00:22,  8.94it/s]\u001b[A\n",
      "\n",
      " 19%|█▉        | 48/250 [00:04<00:22,  9.16it/s]\u001b[A\n",
      "\n",
      " 20%|█▉        | 49/250 [00:05<00:21,  9.18it/s]\u001b[A\n",
      "\n",
      " 20%|██        | 50/250 [00:05<00:21,  9.25it/s]\u001b[A\n",
      "\n",
      " 20%|██        | 51/250 [00:05<00:21,  9.40it/s]\u001b[A\n",
      "\n",
      " 21%|██        | 52/250 [00:05<00:21,  9.14it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 54/250 [00:05<00:19, 10.02it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/250 [00:05<00:19,  9.77it/s]\u001b[A\n",
      "\n",
      " 22%|██▏       | 56/250 [00:05<00:20,  9.57it/s]\u001b[A\n",
      "\n",
      " 23%|██▎       | 58/250 [00:06<00:19,  9.96it/s]\u001b[A\n",
      "\n",
      " 24%|██▎       | 59/250 [00:06<00:20,  9.48it/s]\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/250 [00:06<00:21,  9.04it/s]\u001b[A\n",
      "\n",
      " 24%|██▍       | 61/250 [00:06<00:22,  8.53it/s]\u001b[A\n",
      "\n",
      " 25%|██▍       | 62/250 [00:06<00:21,  8.83it/s]\u001b[A\n",
      "\n",
      " 25%|██▌       | 63/250 [00:06<00:21,  8.84it/s]\u001b[A\n",
      "\n",
      " 26%|██▌       | 64/250 [00:06<00:20,  8.93it/s]\u001b[A\n",
      "\n",
      " 26%|██▌       | 65/250 [00:06<00:21,  8.64it/s]\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:06<00:20,  8.97it/s]\u001b[A\n",
      "\n",
      " 27%|██▋       | 67/250 [00:07<00:20,  9.02it/s]\u001b[A\n",
      "\n",
      " 27%|██▋       | 68/250 [00:07<00:20,  8.71it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 69/250 [00:07<00:20,  8.62it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/250 [00:07<00:20,  8.81it/s]\u001b[A\n",
      "\n",
      " 28%|██▊       | 71/250 [00:07<00:20,  8.80it/s]\u001b[A\n",
      "\n",
      " 29%|██▉       | 72/250 [00:07<00:20,  8.89it/s]\u001b[A\n",
      "\n",
      " 29%|██▉       | 73/250 [00:07<00:19,  8.97it/s]\u001b[A\n",
      "\n",
      " 30%|███       | 75/250 [00:07<00:18,  9.34it/s]\u001b[A\n",
      "\n",
      " 30%|███       | 76/250 [00:08<00:19,  8.92it/s]\u001b[A\n",
      "\n",
      " 31%|███       | 77/250 [00:08<00:19,  8.83it/s]\u001b[A\n",
      "\n",
      " 31%|███       | 78/250 [00:08<00:18,  9.08it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 79/250 [00:08<00:18,  9.15it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/250 [00:08<00:18,  9.19it/s]\u001b[A\n",
      "\n",
      " 32%|███▏      | 81/250 [00:08<00:18,  9.29it/s]\u001b[A\n",
      "\n",
      " 33%|███▎      | 83/250 [00:08<00:17,  9.45it/s]\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/250 [00:08<00:16,  9.95it/s]\u001b[A\n",
      "\n",
      " 34%|███▍      | 86/250 [00:09<00:16,  9.84it/s]\u001b[A\n",
      "\n",
      " 35%|███▍      | 87/250 [00:09<00:16,  9.77it/s]\u001b[A\n",
      "\n",
      " 35%|███▌      | 88/250 [00:09<00:16,  9.66it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 89/250 [00:09<00:16,  9.71it/s]\u001b[A\n",
      "\n",
      " 36%|███▌      | 90/250 [00:09<00:16,  9.71it/s]\u001b[A\n",
      "\n",
      " 36%|███▋      | 91/250 [00:09<00:17,  9.34it/s]\u001b[A\n",
      "\n",
      " 37%|███▋      | 92/250 [00:09<00:16,  9.45it/s]\u001b[A\n",
      "\n",
      " 37%|███▋      | 93/250 [00:09<00:16,  9.39it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 94/250 [00:09<00:16,  9.33it/s]\u001b[A\n",
      "\n",
      " 38%|███▊      | 96/250 [00:10<00:15,  9.64it/s]\u001b[A\n",
      "\n",
      " 39%|███▉      | 97/250 [00:10<00:16,  9.05it/s]\u001b[A\n",
      "\n",
      " 39%|███▉      | 98/250 [00:10<00:17,  8.53it/s]\u001b[A\n",
      "\n",
      " 40%|███▉      | 99/250 [00:10<00:17,  8.62it/s]\u001b[A\n",
      "\n",
      " 40%|████      | 100/250 [00:10<00:16,  8.88it/s]\u001b[A\n",
      "\n",
      " 40%|████      | 101/250 [00:10<00:16,  8.98it/s]\u001b[A\n",
      "\n",
      " 41%|████      | 102/250 [00:10<00:16,  8.88it/s]\u001b[A\n",
      "\n",
      " 41%|████      | 103/250 [00:10<00:16,  8.98it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 104/250 [00:11<00:15,  9.18it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 105/250 [00:11<00:16,  8.80it/s]\u001b[A\n",
      "\n",
      " 42%|████▏     | 106/250 [00:11<00:15,  9.05it/s]\u001b[A\n",
      "\n",
      " 43%|████▎     | 107/250 [00:11<00:16,  8.91it/s]\u001b[A\n",
      "\n",
      " 43%|████▎     | 108/250 [00:11<00:15,  8.93it/s]\u001b[A\n",
      "\n",
      " 44%|████▎     | 109/250 [00:11<00:16,  8.67it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 110/250 [00:11<00:16,  8.61it/s]\u001b[A\n",
      "\n",
      " 44%|████▍     | 111/250 [00:11<00:16,  8.65it/s]\u001b[A\n",
      "\n",
      " 45%|████▍     | 112/250 [00:12<00:16,  8.31it/s]\u001b[A\n",
      "\n",
      " 45%|████▌     | 113/250 [00:12<00:16,  8.09it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 114/250 [00:12<00:16,  8.43it/s]\u001b[A\n",
      "\n",
      " 46%|████▌     | 115/250 [00:12<00:15,  8.82it/s]\u001b[A\n",
      "\n",
      " 46%|████▋     | 116/250 [00:12<00:15,  8.71it/s]\u001b[A\n",
      "\n",
      " 47%|████▋     | 117/250 [00:12<00:15,  8.64it/s]\u001b[A\n",
      "\n",
      " 47%|████▋     | 118/250 [00:12<00:16,  8.04it/s]\u001b[A\n",
      "\n",
      " 48%|████▊     | 119/250 [00:12<00:15,  8.42it/s]\u001b[A\n",
      "\n",
      " 48%|████▊     | 120/250 [00:12<00:15,  8.54it/s]\u001b[A\n",
      "\n",
      " 49%|████▉     | 122/250 [00:13<00:13,  9.25it/s]\u001b[A\n",
      "\n",
      " 49%|████▉     | 123/250 [00:13<00:13,  9.21it/s]\u001b[A\n",
      "\n",
      " 50%|████▉     | 124/250 [00:13<00:13,  9.26it/s]\u001b[A\n",
      "\n",
      " 50%|█████     | 125/250 [00:13<00:13,  9.32it/s]\u001b[A\n",
      "\n",
      " 51%|█████     | 127/250 [00:13<00:12,  9.96it/s]\u001b[A\n",
      "\n",
      " 51%|█████     | 128/250 [00:13<00:12,  9.41it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 129/250 [00:13<00:13,  9.31it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 130/250 [00:14<00:13,  9.21it/s]\u001b[A\n",
      "\n",
      " 52%|█████▏    | 131/250 [00:14<00:12,  9.31it/s]\u001b[A\n",
      "\n",
      " 53%|█████▎    | 133/250 [00:14<00:11,  9.89it/s]\u001b[A\n",
      "\n",
      " 54%|█████▍    | 135/250 [00:14<00:11, 10.22it/s]\u001b[A\n",
      "\n",
      " 55%|█████▍    | 137/250 [00:14<00:11, 10.12it/s]\u001b[A\n",
      "\n",
      " 56%|█████▌    | 139/250 [00:14<00:11,  9.94it/s]\u001b[A\n",
      "\n",
      " 56%|█████▌    | 140/250 [00:14<00:11,  9.93it/s]\u001b[A\n",
      "\n",
      " 56%|█████▋    | 141/250 [00:15<00:11,  9.90it/s]\u001b[A\n",
      "\n",
      " 57%|█████▋    | 142/250 [00:15<00:10,  9.85it/s]\u001b[A\n",
      "\n",
      " 57%|█████▋    | 143/250 [00:15<00:10,  9.80it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 144/250 [00:15<00:10,  9.69it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 145/250 [00:15<00:11,  9.39it/s]\u001b[A\n",
      "\n",
      " 58%|█████▊    | 146/250 [00:15<00:11,  9.33it/s]\u001b[A\n",
      "\n",
      " 59%|█████▉    | 148/250 [00:15<00:10, 10.10it/s]\u001b[A\n",
      "\n",
      " 60%|█████▉    | 149/250 [00:15<00:10, 10.04it/s]\u001b[A\n",
      "\n",
      " 60%|██████    | 151/250 [00:16<00:09,  9.92it/s]\u001b[A\n",
      "\n",
      " 61%|██████    | 152/250 [00:16<00:10,  9.47it/s]\u001b[A\n",
      "\n",
      " 61%|██████    | 153/250 [00:16<00:10,  9.32it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 154/250 [00:16<00:10,  9.48it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 155/250 [00:16<00:10,  9.49it/s]\u001b[A\n",
      "\n",
      " 62%|██████▏   | 156/250 [00:16<00:09,  9.50it/s]\u001b[A\n",
      "\n",
      " 63%|██████▎   | 158/250 [00:16<00:09,  9.87it/s]\u001b[A\n",
      "\n",
      " 64%|██████▎   | 159/250 [00:16<00:09,  9.56it/s]\u001b[A\n",
      "\n",
      " 64%|██████▍   | 160/250 [00:17<00:09,  9.46it/s]\u001b[A\n",
      "\n",
      " 64%|██████▍   | 161/250 [00:17<00:10,  8.45it/s]\u001b[A\n",
      "\n",
      " 65%|██████▍   | 162/250 [00:17<00:10,  8.39it/s]\u001b[A\n",
      "\n",
      " 65%|██████▌   | 163/250 [00:17<00:10,  8.01it/s]\u001b[A\n",
      "\n",
      " 66%|██████▌   | 164/250 [00:17<00:10,  8.09it/s]\u001b[A\n",
      "\n",
      " 66%|██████▌   | 165/250 [00:17<00:10,  8.30it/s]\u001b[A\n",
      "\n",
      " 66%|██████▋   | 166/250 [00:17<00:10,  8.39it/s]\u001b[A\n",
      "\n",
      " 67%|██████▋   | 167/250 [00:17<00:10,  8.07it/s]\u001b[A\n",
      "\n",
      " 67%|██████▋   | 168/250 [00:18<00:09,  8.54it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 169/250 [00:18<00:09,  8.63it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 170/250 [00:18<00:09,  8.64it/s]\u001b[A\n",
      "\n",
      " 68%|██████▊   | 171/250 [00:18<00:09,  8.02it/s]\u001b[A\n",
      "\n",
      " 69%|██████▉   | 172/250 [00:18<00:10,  7.55it/s]\u001b[A\n",
      "\n",
      " 69%|██████▉   | 173/250 [00:18<00:10,  7.50it/s]\u001b[A\n",
      "\n",
      " 70%|██████▉   | 174/250 [00:18<00:09,  7.62it/s]\u001b[A\n",
      "\n",
      " 70%|███████   | 175/250 [00:18<00:09,  8.12it/s]\u001b[A\n",
      "\n",
      " 70%|███████   | 176/250 [00:19<00:08,  8.46it/s]\u001b[A\n",
      "\n",
      " 71%|███████   | 178/250 [00:19<00:07,  9.69it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 179/250 [00:19<00:07,  9.62it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 180/250 [00:19<00:07,  9.60it/s]\u001b[A\n",
      "\n",
      " 72%|███████▏  | 181/250 [00:19<00:07,  9.45it/s]\u001b[A\n",
      "\n",
      " 73%|███████▎  | 182/250 [00:19<00:07,  8.86it/s]\u001b[A\n",
      "\n",
      " 73%|███████▎  | 183/250 [00:19<00:07,  8.76it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 185/250 [00:19<00:06,  9.60it/s]\u001b[A\n",
      "\n",
      " 74%|███████▍  | 186/250 [00:20<00:06,  9.39it/s]\u001b[A\n",
      "\n",
      " 75%|███████▍  | 187/250 [00:20<00:06,  9.52it/s]\u001b[A\n",
      "\n",
      " 75%|███████▌  | 188/250 [00:20<00:06,  9.43it/s]\u001b[A\n",
      "\n",
      " 76%|███████▌  | 189/250 [00:20<00:06,  8.95it/s]\u001b[A\n",
      "\n",
      " 76%|███████▌  | 190/250 [00:20<00:06,  8.63it/s]\u001b[A\n",
      "\n",
      " 76%|███████▋  | 191/250 [00:20<00:06,  8.68it/s]\u001b[A\n",
      "\n",
      " 77%|███████▋  | 192/250 [00:20<00:06,  8.90it/s]\u001b[A\n",
      "\n",
      " 77%|███████▋  | 193/250 [00:20<00:06,  8.83it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:21<00:06,  9.03it/s]\u001b[A\n",
      "\n",
      " 78%|███████▊  | 195/250 [00:21<00:05,  9.20it/s]\u001b[A\n",
      "\n",
      " 79%|███████▉  | 197/250 [00:21<00:05,  9.54it/s]\u001b[A\n",
      "\n",
      " 79%|███████▉  | 198/250 [00:21<00:05,  9.39it/s]\u001b[A\n",
      "\n",
      " 80%|███████▉  | 199/250 [00:21<00:05,  9.42it/s]\u001b[A\n",
      "\n",
      " 80%|████████  | 201/250 [00:21<00:04,  9.89it/s]\u001b[A\n",
      "\n",
      " 81%|████████  | 203/250 [00:21<00:04, 10.08it/s]\u001b[A\n",
      "\n",
      " 82%|████████▏ | 205/250 [00:22<00:04, 10.00it/s]\u001b[A\n",
      "\n",
      " 82%|████████▏ | 206/250 [00:22<00:04,  9.95it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 207/250 [00:22<00:04,  9.72it/s]\u001b[A\n",
      "\n",
      " 83%|████████▎ | 208/250 [00:22<00:04,  9.63it/s]\u001b[A\n",
      "\n",
      " 84%|████████▎ | 209/250 [00:22<00:04,  9.03it/s]\u001b[A\n",
      "\n",
      " 84%|████████▍ | 211/250 [00:22<00:04,  9.42it/s]\u001b[A\n",
      "\n",
      " 85%|████████▍ | 212/250 [00:22<00:04,  9.22it/s]\u001b[A\n",
      "\n",
      " 85%|████████▌ | 213/250 [00:22<00:04,  9.21it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 214/250 [00:23<00:03,  9.19it/s]\u001b[A\n",
      "\n",
      " 86%|████████▌ | 215/250 [00:23<00:03,  9.21it/s]\u001b[A\n",
      "\n",
      " 86%|████████▋ | 216/250 [00:23<00:03,  8.83it/s]\u001b[A\n",
      "\n",
      " 87%|████████▋ | 217/250 [00:23<00:03,  9.01it/s]\u001b[A\n",
      "\n",
      " 88%|████████▊ | 219/250 [00:23<00:03,  9.20it/s]\u001b[A\n",
      "\n",
      " 88%|████████▊ | 220/250 [00:23<00:03,  9.35it/s]\u001b[A\n",
      "\n",
      " 88%|████████▊ | 221/250 [00:23<00:03,  9.45it/s]\u001b[A\n",
      "\n",
      " 89%|████████▉ | 222/250 [00:23<00:02,  9.55it/s]\u001b[A\n",
      "\n",
      " 90%|████████▉ | 224/250 [00:24<00:02,  9.73it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 225/250 [00:24<00:02,  9.38it/s]\u001b[A\n",
      "\n",
      " 90%|█████████ | 226/250 [00:24<00:02,  9.27it/s]\u001b[A\n",
      "\n",
      " 91%|█████████ | 227/250 [00:24<00:02,  8.98it/s]\u001b[A\n",
      "\n",
      " 91%|█████████ | 228/250 [00:24<00:02,  8.36it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 229/250 [00:24<00:02,  8.73it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 230/250 [00:24<00:02,  8.86it/s]\u001b[A\n",
      "\n",
      " 92%|█████████▏| 231/250 [00:24<00:02,  8.53it/s]\u001b[A\n",
      "\n",
      " 93%|█████████▎| 232/250 [00:25<00:02,  8.64it/s]\u001b[A\n",
      "\n",
      " 93%|█████████▎| 233/250 [00:25<00:01,  8.96it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▎| 234/250 [00:25<00:01,  9.14it/s]\u001b[A\n",
      "\n",
      " 94%|█████████▍| 236/250 [00:25<00:01,  9.43it/s]\u001b[A\n",
      "\n",
      " 95%|█████████▍| 237/250 [00:25<00:01,  8.87it/s]\u001b[A\n",
      "\n",
      " 95%|█████████▌| 238/250 [00:25<00:01,  8.57it/s]\u001b[A\n",
      "\n",
      " 96%|█████████▌| 239/250 [00:25<00:01,  8.72it/s]\u001b[A\n",
      "\n",
      " 96%|█████████▌| 240/250 [00:25<00:01,  8.73it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 242/250 [00:26<00:00,  9.29it/s]\u001b[A\n",
      "\n",
      " 97%|█████████▋| 243/250 [00:26<00:00,  9.32it/s]\u001b[A\n",
      "\n",
      " 98%|█████████▊| 244/250 [00:26<00:00,  9.24it/s]\u001b[A\n",
      "\n",
      " 98%|█████████▊| 246/250 [00:26<00:00,  9.24it/s]\u001b[A\n",
      "\n",
      " 99%|█████████▉| 247/250 [00:26<00:00,  9.33it/s]\u001b[A\n",
      "\n",
      " 99%|█████████▉| 248/250 [00:26<00:00,  9.25it/s]\u001b[A\n",
      "\n",
      "100%|█████████▉| 249/250 [00:26<00:00,  8.87it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [00:27<00:00,  8.69it/s]\u001b[A\n",
      "                                                   \n",
      "\n",
      "\n",
      "                                                 \n",
      "\u001b[A\n",
      "100%|██████████| 2000/2000 [08:03<00:00,  5.16it/s]\n",
      "\n",
      "100%|██████████| 250/250 [00:27<00:00,  8.69it/s]\u001b[A\n",
      "\n",
      "                                                 \u001b[A[INFO|trainer.py:2939] 2024-01-26 01:29:26,075 >> Saving model checkpoint to output/t5_freeze_emotion\\checkpoint-2000\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:29:26,076 >> Configuration saved in output/t5_freeze_emotion\\checkpoint-2000\\config.json\n",
      "[INFO|configuration_utils.py:544] 2024-01-26 01:29:26,076 >> Configuration saved in output/t5_freeze_emotion\\checkpoint-2000\\generation_config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:29:42,964 >> Model weights saved in output/t5_freeze_emotion\\checkpoint-2000\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:29:42,965 >> tokenizer config file saved in output/t5_freeze_emotion\\checkpoint-2000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:29:42,965 >> Special tokens file saved in output/t5_freeze_emotion\\checkpoint-2000\\special_tokens_map.json\n",
      "[INFO|tokenization_t5_fast.py:189] 2024-01-26 01:29:42,975 >> Copy vocab file to output/t5_freeze_emotion\\checkpoint-2000\\spiece.model\n",
      "[INFO|trainer.py:2017] 2024-01-26 01:30:17,049 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2196] 2024-01-26 01:30:17,050 >> Loading best model from output/t5_freeze_emotion\\checkpoint-1000 (score: 1.0).\n",
      "\n",
      "                                                   \n",
      "\n",
      "100%|██████████| 2000/2000 [08:59<00:00,  5.16it/s]\n",
      "100%|██████████| 2000/2000 [08:59<00:00,  3.71it/s]\n",
      "[INFO|trainer.py:2939] 2024-01-26 01:30:22,299 >> Saving model checkpoint to output/t5_freeze_emotion\n",
      "[INFO|configuration_utils.py:460] 2024-01-26 01:30:22,300 >> Configuration saved in output/t5_freeze_emotion\\config.json\n",
      "[INFO|configuration_utils.py:544] 2024-01-26 01:30:22,300 >> Configuration saved in output/t5_freeze_emotion\\generation_config.json\n",
      "[INFO|modeling_utils.py:2118] 2024-01-26 01:30:41,751 >> Model weights saved in output/t5_freeze_emotion\\pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2437] 2024-01-26 01:30:41,753 >> tokenizer config file saved in output/t5_freeze_emotion\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2446] 2024-01-26 01:30:41,753 >> Special tokens file saved in output/t5_freeze_emotion\\special_tokens_map.json\n",
      "[INFO|tokenization_t5_fast.py:189] 2024-01-26 01:30:41,754 >> Copy vocab file to output/t5_freeze_emotion\\spiece.model\n",
      "[INFO|trainer.py:3213] 2024-01-26 01:30:41,760 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3215] 2024-01-26 01:30:41,760 >>   Num examples = 2000\n",
      "[INFO|trainer.py:3218] 2024-01-26 01:30:41,760 >>   Batch size = 8\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\n",
      "  1%|          | 2/250 [00:00<00:14, 16.57it/s]\n",
      "  2%|▏         | 4/250 [00:00<00:21, 11.32it/s]\n",
      "  2%|▏         | 6/250 [00:00<00:24, 10.08it/s]\n",
      "  3%|▎         | 8/250 [00:00<00:25,  9.31it/s]\n",
      "  4%|▎         | 9/250 [00:00<00:25,  9.33it/s]\n",
      "  4%|▍         | 10/250 [00:01<00:25,  9.31it/s]\n",
      "  4%|▍         | 11/250 [00:01<00:25,  9.35it/s]\n",
      "  5%|▍         | 12/250 [00:01<00:25,  9.29it/s]\n",
      "  5%|▌         | 13/250 [00:01<00:26,  8.92it/s]\n",
      "  6%|▌         | 14/250 [00:01<00:27,  8.71it/s]\n",
      "  6%|▌         | 15/250 [00:01<00:26,  8.81it/s]\n",
      "  6%|▋         | 16/250 [00:01<00:25,  9.12it/s]\n",
      "  7%|▋         | 17/250 [00:01<00:25,  9.16it/s]\n",
      "  7%|▋         | 18/250 [00:01<00:25,  9.09it/s]\n",
      "  8%|▊         | 19/250 [00:02<00:25,  9.11it/s]\n",
      "  8%|▊         | 20/250 [00:02<00:24,  9.35it/s]\n",
      "  8%|▊         | 21/250 [00:02<00:24,  9.40it/s]\n",
      "  9%|▉         | 22/250 [00:02<00:23,  9.52it/s]\n",
      "  9%|▉         | 23/250 [00:02<00:23,  9.50it/s]\n",
      " 10%|▉         | 24/250 [00:02<00:23,  9.44it/s]\n",
      " 10%|█         | 25/250 [00:02<00:24,  9.28it/s]\n",
      " 10%|█         | 26/250 [00:02<00:25,  8.82it/s]\n",
      " 11%|█         | 27/250 [00:02<00:25,  8.88it/s]\n",
      " 11%|█         | 28/250 [00:03<00:26,  8.50it/s]\n",
      " 12%|█▏        | 29/250 [00:03<00:26,  8.36it/s]\n",
      " 12%|█▏        | 31/250 [00:03<00:25,  8.74it/s]\n",
      " 13%|█▎        | 33/250 [00:03<00:23,  9.16it/s]\n",
      " 14%|█▎        | 34/250 [00:03<00:23,  9.21it/s]\n",
      " 14%|█▍        | 35/250 [00:03<00:23,  9.31it/s]\n",
      " 14%|█▍        | 36/250 [00:03<00:22,  9.35it/s]\n",
      " 15%|█▍        | 37/250 [00:03<00:22,  9.33it/s]\n",
      " 16%|█▌        | 39/250 [00:04<00:21, 10.04it/s]\n",
      " 16%|█▌        | 40/250 [00:04<00:21,  9.78it/s]\n",
      " 16%|█▋        | 41/250 [00:04<00:21,  9.73it/s]\n",
      " 17%|█▋        | 43/250 [00:04<00:20,  9.97it/s]\n",
      " 18%|█▊        | 44/250 [00:04<00:21,  9.76it/s]\n",
      " 18%|█▊        | 45/250 [00:04<00:20,  9.79it/s]\n",
      " 18%|█▊        | 46/250 [00:04<00:21,  9.58it/s]\n",
      " 19%|█▉        | 47/250 [00:05<00:21,  9.39it/s]\n",
      " 19%|█▉        | 48/250 [00:05<00:21,  9.22it/s]\n",
      " 20%|█▉        | 49/250 [00:05<00:22,  9.11it/s]\n",
      " 20%|██        | 50/250 [00:05<00:21,  9.32it/s]\n",
      " 21%|██        | 52/250 [00:05<00:20,  9.75it/s]\n",
      " 22%|██▏       | 54/250 [00:05<00:19, 10.18it/s]\n",
      " 22%|██▏       | 56/250 [00:05<00:19,  9.73it/s]\n",
      " 23%|██▎       | 58/250 [00:06<00:19,  9.94it/s]\n",
      " 24%|██▎       | 59/250 [00:06<00:19,  9.92it/s]\n",
      " 24%|██▍       | 60/250 [00:06<00:19,  9.92it/s]\n",
      " 24%|██▍       | 61/250 [00:06<00:19,  9.79it/s]\n",
      " 25%|██▍       | 62/250 [00:06<00:19,  9.78it/s]\n",
      " 25%|██▌       | 63/250 [00:06<00:19,  9.69it/s]\n",
      " 26%|██▌       | 64/250 [00:06<00:19,  9.39it/s]\n",
      " 26%|██▌       | 65/250 [00:06<00:19,  9.36it/s]\n",
      " 26%|██▋       | 66/250 [00:06<00:19,  9.35it/s]\n",
      " 27%|██▋       | 67/250 [00:07<00:19,  9.25it/s]\n",
      " 27%|██▋       | 68/250 [00:07<00:20,  8.75it/s]\n",
      " 28%|██▊       | 69/250 [00:07<00:21,  8.39it/s]\n",
      " 28%|██▊       | 70/250 [00:07<00:21,  8.46it/s]\n",
      " 28%|██▊       | 71/250 [00:07<00:20,  8.62it/s]\n",
      " 29%|██▉       | 72/250 [00:07<00:20,  8.77it/s]\n",
      " 29%|██▉       | 73/250 [00:07<00:20,  8.71it/s]\n",
      " 30%|██▉       | 74/250 [00:07<00:19,  9.02it/s]\n",
      " 30%|███       | 75/250 [00:08<00:19,  9.10it/s]\n",
      " 30%|███       | 76/250 [00:08<00:19,  9.10it/s]\n",
      " 31%|███       | 77/250 [00:08<00:19,  8.96it/s]\n",
      " 31%|███       | 78/250 [00:08<00:19,  9.03it/s]\n",
      " 32%|███▏      | 79/250 [00:08<00:18,  9.01it/s]\n",
      " 32%|███▏      | 80/250 [00:08<00:19,  8.73it/s]\n",
      " 32%|███▏      | 81/250 [00:08<00:19,  8.75it/s]\n",
      " 33%|███▎      | 82/250 [00:08<00:18,  9.04it/s]\n",
      " 33%|███▎      | 83/250 [00:08<00:17,  9.29it/s]\n",
      " 34%|███▎      | 84/250 [00:08<00:17,  9.36it/s]\n",
      " 34%|███▍      | 86/250 [00:09<00:17,  9.56it/s]\n",
      " 35%|███▍      | 87/250 [00:09<00:17,  9.48it/s]\n",
      " 35%|███▌      | 88/250 [00:09<00:17,  9.01it/s]\n",
      " 36%|███▌      | 89/250 [00:09<00:17,  9.03it/s]\n",
      " 36%|███▌      | 90/250 [00:09<00:17,  9.22it/s]\n",
      " 36%|███▋      | 91/250 [00:09<00:17,  8.90it/s]\n",
      " 37%|███▋      | 92/250 [00:09<00:17,  8.97it/s]\n",
      " 37%|███▋      | 93/250 [00:09<00:17,  9.05it/s]\n",
      " 38%|███▊      | 94/250 [00:10<00:17,  8.97it/s]\n",
      " 38%|███▊      | 95/250 [00:10<00:16,  9.13it/s]\n",
      " 38%|███▊      | 96/250 [00:10<00:16,  9.11it/s]\n",
      " 39%|███▉      | 97/250 [00:10<00:17,  8.95it/s]\n",
      " 39%|███▉      | 98/250 [00:10<00:16,  9.10it/s]\n",
      " 40%|███▉      | 99/250 [00:10<00:16,  8.98it/s]\n",
      " 40%|████      | 100/250 [00:10<00:18,  8.29it/s]\n",
      " 40%|████      | 101/250 [00:10<00:17,  8.58it/s]\n",
      " 41%|████      | 102/250 [00:11<00:17,  8.60it/s]\n",
      " 41%|████      | 103/250 [00:11<00:16,  8.81it/s]\n",
      " 42%|████▏     | 104/250 [00:11<00:16,  8.90it/s]\n",
      " 42%|████▏     | 105/250 [00:11<00:16,  8.95it/s]\n",
      " 42%|████▏     | 106/250 [00:11<00:15,  9.06it/s]\n",
      " 43%|████▎     | 107/250 [00:11<00:15,  9.12it/s]\n",
      " 43%|████▎     | 108/250 [00:11<00:15,  9.09it/s]\n",
      " 44%|████▎     | 109/250 [00:11<00:15,  9.04it/s]\n",
      " 44%|████▍     | 110/250 [00:11<00:15,  8.88it/s]\n",
      " 44%|████▍     | 111/250 [00:12<00:15,  8.81it/s]\n",
      " 45%|████▍     | 112/250 [00:12<00:15,  9.03it/s]\n",
      " 46%|████▌     | 114/250 [00:12<00:13,  9.72it/s]\n",
      " 46%|████▌     | 115/250 [00:12<00:13,  9.72it/s]\n",
      " 46%|████▋     | 116/250 [00:12<00:13,  9.75it/s]\n",
      " 47%|████▋     | 117/250 [00:12<00:14,  9.43it/s]\n",
      " 47%|████▋     | 118/250 [00:12<00:14,  9.30it/s]\n",
      " 48%|████▊     | 120/250 [00:12<00:13,  9.52it/s]\n",
      " 49%|████▉     | 122/250 [00:13<00:13,  9.33it/s]\n",
      " 49%|████▉     | 123/250 [00:13<00:14,  8.99it/s]\n",
      " 50%|████▉     | 124/250 [00:13<00:14,  8.85it/s]\n",
      " 50%|█████     | 125/250 [00:13<00:13,  8.93it/s]\n",
      " 50%|█████     | 126/250 [00:13<00:13,  9.05it/s]\n",
      " 51%|█████     | 128/250 [00:13<00:13,  9.26it/s]\n",
      " 52%|█████▏    | 129/250 [00:13<00:13,  9.25it/s]\n",
      " 52%|█████▏    | 130/250 [00:14<00:13,  9.20it/s]\n",
      " 52%|█████▏    | 131/250 [00:14<00:12,  9.24it/s]\n",
      " 53%|█████▎    | 133/250 [00:14<00:12,  9.61it/s]\n",
      " 54%|█████▎    | 134/250 [00:14<00:12,  9.56it/s]\n",
      " 54%|█████▍    | 135/250 [00:14<00:11,  9.62it/s]\n",
      " 54%|█████▍    | 136/250 [00:14<00:11,  9.61it/s]\n",
      " 55%|█████▍    | 137/250 [00:14<00:11,  9.71it/s]\n",
      " 55%|█████▌    | 138/250 [00:14<00:11,  9.50it/s]\n",
      " 56%|█████▌    | 139/250 [00:14<00:11,  9.56it/s]\n",
      " 56%|█████▌    | 140/250 [00:15<00:11,  9.58it/s]\n",
      " 56%|█████▋    | 141/250 [00:15<00:11,  9.64it/s]\n",
      " 57%|█████▋    | 142/250 [00:15<00:11,  9.70it/s]\n",
      " 57%|█████▋    | 143/250 [00:15<00:11,  9.29it/s]\n",
      " 58%|█████▊    | 144/250 [00:15<00:12,  8.57it/s]\n",
      " 58%|█████▊    | 145/250 [00:15<00:11,  8.78it/s]\n",
      " 58%|█████▊    | 146/250 [00:15<00:11,  8.88it/s]\n",
      " 59%|█████▉    | 148/250 [00:15<00:10,  9.57it/s]\n",
      " 60%|█████▉    | 149/250 [00:16<00:10,  9.56it/s]\n",
      " 60%|██████    | 150/250 [00:16<00:10,  9.39it/s]\n",
      " 60%|██████    | 151/250 [00:16<00:10,  9.09it/s]\n",
      " 61%|██████    | 152/250 [00:16<00:11,  8.76it/s]\n",
      " 61%|██████    | 153/250 [00:16<00:11,  8.43it/s]\n",
      " 62%|██████▏   | 154/250 [00:16<00:11,  8.33it/s]\n",
      " 62%|██████▏   | 155/250 [00:16<00:11,  8.04it/s]\n",
      " 62%|██████▏   | 156/250 [00:16<00:11,  8.10it/s]\n",
      " 63%|██████▎   | 158/250 [00:17<00:10,  8.95it/s]\n",
      " 64%|██████▎   | 159/250 [00:17<00:10,  8.95it/s]\n",
      " 64%|██████▍   | 160/250 [00:17<00:10,  8.83it/s]\n",
      " 64%|██████▍   | 161/250 [00:17<00:09,  9.09it/s]\n",
      " 65%|██████▍   | 162/250 [00:17<00:09,  9.28it/s]\n",
      " 65%|██████▌   | 163/250 [00:17<00:09,  8.92it/s]\n",
      " 66%|██████▌   | 164/250 [00:17<00:09,  9.05it/s]\n",
      " 66%|██████▌   | 165/250 [00:17<00:09,  8.97it/s]\n",
      " 66%|██████▋   | 166/250 [00:18<00:09,  8.53it/s]\n",
      " 67%|██████▋   | 167/250 [00:18<00:09,  8.75it/s]\n",
      " 67%|██████▋   | 168/250 [00:18<00:09,  8.91it/s]\n",
      " 68%|██████▊   | 170/250 [00:18<00:09,  8.73it/s]\n",
      " 68%|██████▊   | 171/250 [00:18<00:08,  8.86it/s]\n",
      " 69%|██████▉   | 172/250 [00:18<00:08,  8.87it/s]\n",
      " 69%|██████▉   | 173/250 [00:18<00:08,  8.92it/s]\n",
      " 70%|██████▉   | 174/250 [00:18<00:08,  8.77it/s]\n",
      " 70%|███████   | 175/250 [00:19<00:08,  8.85it/s]\n",
      " 70%|███████   | 176/250 [00:19<00:08,  9.02it/s]\n",
      " 71%|███████   | 177/250 [00:19<00:07,  9.25it/s]\n",
      " 72%|███████▏  | 179/250 [00:19<00:07,  9.78it/s]\n",
      " 72%|███████▏  | 180/250 [00:19<00:07,  9.81it/s]\n",
      " 73%|███████▎  | 182/250 [00:19<00:06, 10.03it/s]\n",
      " 73%|███████▎  | 183/250 [00:19<00:06,  9.72it/s]\n",
      " 74%|███████▎  | 184/250 [00:19<00:06,  9.65it/s]\n",
      " 74%|███████▍  | 186/250 [00:20<00:06, 10.06it/s]\n",
      " 75%|███████▍  | 187/250 [00:20<00:06, 10.01it/s]\n",
      " 75%|███████▌  | 188/250 [00:20<00:06,  9.51it/s]\n",
      " 76%|███████▌  | 189/250 [00:20<00:07,  8.64it/s]\n",
      " 76%|███████▌  | 190/250 [00:20<00:06,  8.82it/s]\n",
      " 76%|███████▋  | 191/250 [00:20<00:06,  8.93it/s]\n",
      " 77%|███████▋  | 192/250 [00:20<00:06,  9.07it/s]\n",
      " 77%|███████▋  | 193/250 [00:20<00:06,  8.98it/s]\n",
      " 78%|███████▊  | 195/250 [00:21<00:05,  9.19it/s]\n",
      " 78%|███████▊  | 196/250 [00:21<00:05,  9.30it/s]\n",
      " 79%|███████▉  | 197/250 [00:21<00:05,  9.31it/s]\n",
      " 79%|███████▉  | 198/250 [00:21<00:05,  9.38it/s]\n",
      " 80%|███████▉  | 199/250 [00:21<00:05,  9.50it/s]\n",
      " 80%|████████  | 201/250 [00:21<00:05,  9.64it/s]\n",
      " 81%|████████  | 203/250 [00:21<00:05,  9.36it/s]\n",
      " 82%|████████▏ | 204/250 [00:22<00:04,  9.41it/s]\n",
      " 82%|████████▏ | 205/250 [00:22<00:04,  9.44it/s]\n",
      " 83%|████████▎ | 207/250 [00:22<00:04,  9.59it/s]\n",
      " 83%|████████▎ | 208/250 [00:22<00:04,  9.61it/s]\n",
      " 84%|████████▎ | 209/250 [00:22<00:04,  9.38it/s]\n",
      " 84%|████████▍ | 211/250 [00:22<00:04,  9.73it/s]\n",
      " 85%|████████▍ | 212/250 [00:22<00:03,  9.64it/s]\n",
      " 86%|████████▌ | 214/250 [00:23<00:03,  9.71it/s]\n",
      " 86%|████████▌ | 215/250 [00:23<00:03,  9.54it/s]\n",
      " 86%|████████▋ | 216/250 [00:23<00:03,  9.47it/s]\n",
      " 87%|████████▋ | 217/250 [00:23<00:03,  9.41it/s]\n",
      " 87%|████████▋ | 218/250 [00:23<00:03,  9.45it/s]\n",
      " 88%|████████▊ | 219/250 [00:23<00:03,  8.99it/s]\n",
      " 88%|████████▊ | 220/250 [00:23<00:03,  8.69it/s]\n",
      " 89%|████████▉ | 222/250 [00:24<00:03,  9.00it/s]\n",
      " 89%|████████▉ | 223/250 [00:24<00:03,  8.92it/s]\n",
      " 90%|████████▉ | 224/250 [00:24<00:02,  8.79it/s]\n",
      " 90%|█████████ | 225/250 [00:24<00:02,  8.77it/s]\n",
      " 90%|█████████ | 226/250 [00:24<00:02,  9.03it/s]\n",
      " 91%|█████████ | 227/250 [00:24<00:02,  9.24it/s]\n",
      " 91%|█████████ | 228/250 [00:24<00:02,  9.42it/s]\n",
      " 92%|█████████▏| 229/250 [00:24<00:02,  9.53it/s]\n",
      " 92%|█████████▏| 230/250 [00:24<00:02,  9.51it/s]\n",
      " 92%|█████████▏| 231/250 [00:24<00:02,  9.22it/s]\n",
      " 93%|█████████▎| 232/250 [00:25<00:01,  9.21it/s]\n",
      " 93%|█████████▎| 233/250 [00:25<00:01,  9.39it/s]\n",
      " 94%|█████████▍| 235/250 [00:25<00:01,  9.63it/s]\n",
      " 94%|█████████▍| 236/250 [00:25<00:01,  9.09it/s]\n",
      " 95%|█████████▍| 237/250 [00:25<00:01,  9.13it/s]\n",
      " 95%|█████████▌| 238/250 [00:25<00:01,  9.33it/s]\n",
      " 96%|█████████▌| 240/250 [00:25<00:01,  9.64it/s]\n",
      " 97%|█████████▋| 242/250 [00:26<00:00,  9.48it/s]\n",
      " 97%|█████████▋| 243/250 [00:26<00:00,  9.44it/s]\n",
      " 98%|█████████▊| 244/250 [00:26<00:00,  8.87it/s]\n",
      " 98%|█████████▊| 245/250 [00:26<00:00,  8.65it/s]\n",
      " 98%|█████████▊| 246/250 [00:26<00:00,  8.75it/s]\n",
      " 99%|█████████▉| 247/250 [00:26<00:00,  8.93it/s]\n",
      " 99%|█████████▉| 248/250 [00:26<00:00,  9.05it/s]\n",
      "100%|█████████▉| 249/250 [00:26<00:00,  9.15it/s]\n",
      "100%|██████████| 250/250 [00:27<00:00,  9.20it/s]\n",
      "100%|██████████| 250/250 [00:27<00:00,  9.22it/s]\n",
      "[INFO|modelcard.py:452] 2024-01-26 01:31:09,650 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 0.0}, {'name': 'Accuracy', 'type': 'accuracy', 'value': 1.0}]}\n"
     ]
    }
   ],
   "source": [
    "!python run_translation.py \\\n",
    "  --cache_dir .cache_training \\\n",
    "  --model_name_or_path \"t5-large\" \\\n",
    "  --freeze_weights \\\n",
    "  --train_file data/train.json \\\n",
    "  --validation_file data/validation.json \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --source_lang \"text\" \\\n",
    "  --target_lang \"label\" \\\n",
    "  --source_prefix \"emotion_classification\" \\\n",
    "  --max_source_length 256 \\\n",
    "  --max_target_length 128 \\\n",
    "  --generation_max_length 128 \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --predict_with_generate \\\n",
    "  --num_train_epochs 1 \\\n",
    "  --save_strategy steps \\\n",
    "  --save_steps 1000 \\\n",
    "  --save_total_limit 5 \\\n",
    "  --logging_strategy steps \\\n",
    "  --logging_steps 50 \\\n",
    "  --eval_steps 1000 \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --metric_for_best_model accuracy \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --output_dir output/t5_freeze_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Model(\n",
      "  (shared): Embedding(32128, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (14): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (16): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (17): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (19): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (20): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (22): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (23): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "model = transformers.AutoModel.from_pretrained(\n",
    "    r'.\\output\\t5_freeze_emotion')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoModelForMaskedLM, AutoModelForSeq2SeqLM, pipeline, AutoTokenizer\n",
    "\n",
    "def get_pipeline(pipeline_type: str, model_name: str, model_type: str, torch_dtype: torch.dtype=\"auto\", device_map=\"auto\"):\n",
    "    if model_type == 'clm':\n",
    "        class_type = AutoModelForCausalLM\n",
    "    elif model_type == 'mlm':\n",
    "        class_type = AutoModelForMaskedLM\n",
    "    elif model_type == 's2s':\n",
    "        class_type = AutoModelForSeq2SeqLM\n",
    "    model = class_type.from_pretrained(model_name, low_cpu_mem_usage=True, torch_dtype=torch_dtype, device_map=device_map)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return pipeline(pipeline_type, model=model, tokenizer=tokenizer)\n",
    "\n",
    "def generate_text(model_pipeline, text: str, return_full_text: bool = False, max_length: int = 100):\n",
    "  print(model_pipeline(text, do_sample=False, return_full_text=return_full_text, max_length=max_length)[0][\"generated_text\"])\n",
    "\n",
    "def generate_text_simple(model_pipeline, text: str, max_new_tokens: int = 100, is_prompt: bool = False):\n",
    "  generated_text = model_pipeline(text, do_sample=False, max_new_tokens=max_new_tokens)[0][\"generated_text\"]\n",
    "  if is_prompt and generated_text.startswith(text):\n",
    "    generated_text = generated_text[len(text):].strip()\n",
    "  print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00008.safetensors: 100%|██████████| 1.89G/1.89G [02:50<00:00, 11.1MB/s]\n",
      "c:\\Users\\kubak\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kubak\\.cache\\huggingface\\hub\\models--HuggingFaceH4--zephyr-7b-beta. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model-00002-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [03:01<00:00, 10.7MB/s]\n",
      "model-00003-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [03:05<00:00, 10.7MB/s]\n",
      "model-00004-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [02:57<00:00, 11.0MB/s]\n",
      "model-00005-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [03:03<00:00, 10.8MB/s]\n",
      "model-00006-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [02:59<00:00, 10.8MB/s]\n",
      "model-00007-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [03:00<00:00, 10.9MB/s]\n",
      "model-00008-of-00008.safetensors: 100%|██████████| 816M/816M [01:15<00:00, 10.8MB/s]\n",
      "Downloading shards: 100%|██████████| 8/8 [22:17<00:00, 167.22s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 37.0kB/s]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "tokenizer_config.json: 100%|██████████| 1.43k/1.43k [00:00<00:00, 476kB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 3.12MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 2.92MB/s]\n",
      "added_tokens.json: 100%|██████████| 42.0/42.0 [00:00<00:00, 21.0kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 168/168 [00:00<00:00, 84.0kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "lm_pipeline = get_pipeline('text-generation', 'HuggingFaceH4/zephyr-7b-beta', 'clm', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a harsh and rude chatbot who is teacher and needs to judge our project from Deep Learning Classes. You need to pick one grade from 2 to 5!</s>\n",
      "<|user|>\n",
      "What do you think about our project?</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a harsh and rude chatbot who is teacher and needs to judge our project from Deep Learning Classes. You need to pick one grade from 2 to 5!\",\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What do you think about our project?\"\n",
    "    },\n",
    "]\n",
    "prompt = lm_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|assistant|>\n",
      "Based on my analysis, your project demonstrates a basic understanding of deep learning concepts. While there are some promising ideas, the overall execution leaves much to be desired. I would give your project a grade of 3\n"
     ]
    }
   ],
   "source": [
    "generate_text_simple(lm_pipeline, prompt, is_prompt=True, max_new_tokens=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
